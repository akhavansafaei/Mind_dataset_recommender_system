{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3_vhAMLhyB5",
        "outputId": "0b62bed2-22e0-4f1c-ed57-ace6546d9f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.11.9)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision transformers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5DmQU5e5CeA",
        "outputId": "d26419f1-ae7f-41bc-a8e2-043392b84ff5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.20.1+cu121)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.46.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.9.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (11.0.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.26.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "import os\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "metadata": {
        "id": "WSBqyCECh679"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: coonect to drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnMJKzIyh6-r",
        "outputId": "3d7d6df8-208f-40b2-e9b7-004e9e228e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# with open('/content/drive/MyDrive/news_dict.pkl', 'rb') as f:\n",
        "#   news_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "tHzuColvh7Et"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# new_emb={key:np.array(list(values.values()))[:768] for key, values in news_dict.items()}\n",
        "\n",
        "# with open('/content/drive/MyDrive/new_emb.pkl', 'wb') as f:\n",
        "#   pickle.dump(new_emb, f)\n",
        "# print(\"saved emb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xHq0UCefkQEz",
        "outputId": "21f2da0f-c0b9-447c-e548-99489606b194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saved emb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/new_emb.pkl', 'rb') as f:\n",
        "  news_dict = pickle.load(f)"
      ],
      "metadata": {
        "id": "BJeiKlRG6Mf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: show first record of news_dict and its values\n",
        "\n",
        "# Assuming news_dict is a dictionary-like object.\n",
        "# Accessing the first record depends on how the dictionary is ordered\n",
        "# If you want the first record based on insertion order (Python 3.7+):\n",
        "first_key = next(iter(news_dict))\n",
        "print(f\"First Key: {first_key}\")\n",
        "print(f\"First Value (Embedding): {news_dict[first_key][:10]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghofouQw6UgY",
        "outputId": "ae5559ac-db9b-4732-8529-1b5e544c18f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Key: N55528\n",
            "First Value (Embedding): [-0.05725607  1.03526783 -0.15454921  0.31550664 -0.48738602  0.51628059\n",
            " -0.29541379  0.26508239  0.39858839  1.00280774]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(news_dict[first_key])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-bwp3JurPAyk",
        "outputId": "a574bc8e-3a48-40ee-94df-88db42eac1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# expanded_df = pd.read_parquet('/content/drive/MyDrive/expanded_df.parquet')\n",
        "# expanded_df = expanded_df.fillna('')\n",
        "# expanded_df\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "LZ7KYT4Hh7Bq",
        "outputId": "9a98de6c-44b1-4aec-f046-6d4ad03cbed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          index user_id           timestamp  \\\n",
              "0             1  U13740 2019-11-11 09:05:58   \n",
              "1             1  U13740 2019-11-11 09:05:58   \n",
              "2             2  U91836 2019-11-12 18:11:30   \n",
              "3             2  U91836 2019-11-12 18:11:30   \n",
              "4             2  U91836 2019-11-12 18:11:30   \n",
              "...         ...     ...                 ...   \n",
              "5843439  156964  U44625 2019-11-13 14:57:02   \n",
              "5843440  156965  U64800 2019-11-14 15:25:49   \n",
              "5843441  156965  U64800 2019-11-14 15:25:49   \n",
              "5843442  156965  U64800 2019-11-14 15:25:49   \n",
              "5843443  156965  U64800 2019-11-14 15:25:49   \n",
              "\n",
              "                                             news_explored suggested_news  \\\n",
              "0        N55189 N42782 N34694 N45794 N18445 N63302 N104...         N55689   \n",
              "1        N55189 N42782 N34694 N45794 N18445 N63302 N104...         N35729   \n",
              "2        N31739 N6072 N63045 N23979 N35656 N43353 N8129...         N20678   \n",
              "3        N31739 N6072 N63045 N23979 N35656 N43353 N8129...         N39317   \n",
              "4        N31739 N6072 N63045 N23979 N35656 N43353 N8129...         N58114   \n",
              "...                                                    ...            ...   \n",
              "5843439  N4118 N47297 N3164 N43295 N6056 N38747 N42973 ...         N39317   \n",
              "5843440                                      N22997 N48742         N61233   \n",
              "5843441                                      N22997 N48742         N33828   \n",
              "5843442                                      N22997 N48742         N19661   \n",
              "5843443                                      N22997 N48742         N41934   \n",
              "\n",
              "         label                                            history  \n",
              "0            1  N55189 N42782 N34694 N45794 N18445 N63302 N104...  \n",
              "1            0  N55189 N42782 N34694 N45794 N18445 N63302 N104...  \n",
              "2            0  N31739 N6072 N63045 N23979 N35656 N43353 N8129...  \n",
              "3            0  N31739 N6072 N63045 N23979 N35656 N43353 N8129...  \n",
              "4            0  N31739 N6072 N63045 N23979 N35656 N43353 N8129...  \n",
              "...        ...                                                ...  \n",
              "5843439      0  N4118 N47297 N3164 N43295 N6056 N38747 N42973 ...  \n",
              "5843440      0                                      N22997 N48742  \n",
              "5843441      1                                      N22997 N48742  \n",
              "5843442      0                                      N22997 N48742  \n",
              "5843443      0                                      N22997 N48742  \n",
              "\n",
              "[5843444 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c381767-4378-46cf-9f78-fc4779cf1cb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>news_explored</th>\n",
              "      <th>suggested_news</th>\n",
              "      <th>label</th>\n",
              "      <th>history</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>U13740</td>\n",
              "      <td>2019-11-11 09:05:58</td>\n",
              "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
              "      <td>N55689</td>\n",
              "      <td>1</td>\n",
              "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>U13740</td>\n",
              "      <td>2019-11-11 09:05:58</td>\n",
              "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
              "      <td>N35729</td>\n",
              "      <td>0</td>\n",
              "      <td>N55189 N42782 N34694 N45794 N18445 N63302 N104...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>U91836</td>\n",
              "      <td>2019-11-12 18:11:30</td>\n",
              "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
              "      <td>N20678</td>\n",
              "      <td>0</td>\n",
              "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>U91836</td>\n",
              "      <td>2019-11-12 18:11:30</td>\n",
              "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
              "      <td>N39317</td>\n",
              "      <td>0</td>\n",
              "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>U91836</td>\n",
              "      <td>2019-11-12 18:11:30</td>\n",
              "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
              "      <td>N58114</td>\n",
              "      <td>0</td>\n",
              "      <td>N31739 N6072 N63045 N23979 N35656 N43353 N8129...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5843439</th>\n",
              "      <td>156964</td>\n",
              "      <td>U44625</td>\n",
              "      <td>2019-11-13 14:57:02</td>\n",
              "      <td>N4118 N47297 N3164 N43295 N6056 N38747 N42973 ...</td>\n",
              "      <td>N39317</td>\n",
              "      <td>0</td>\n",
              "      <td>N4118 N47297 N3164 N43295 N6056 N38747 N42973 ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5843440</th>\n",
              "      <td>156965</td>\n",
              "      <td>U64800</td>\n",
              "      <td>2019-11-14 15:25:49</td>\n",
              "      <td>N22997 N48742</td>\n",
              "      <td>N61233</td>\n",
              "      <td>0</td>\n",
              "      <td>N22997 N48742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5843441</th>\n",
              "      <td>156965</td>\n",
              "      <td>U64800</td>\n",
              "      <td>2019-11-14 15:25:49</td>\n",
              "      <td>N22997 N48742</td>\n",
              "      <td>N33828</td>\n",
              "      <td>1</td>\n",
              "      <td>N22997 N48742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5843442</th>\n",
              "      <td>156965</td>\n",
              "      <td>U64800</td>\n",
              "      <td>2019-11-14 15:25:49</td>\n",
              "      <td>N22997 N48742</td>\n",
              "      <td>N19661</td>\n",
              "      <td>0</td>\n",
              "      <td>N22997 N48742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5843443</th>\n",
              "      <td>156965</td>\n",
              "      <td>U64800</td>\n",
              "      <td>2019-11-14 15:25:49</td>\n",
              "      <td>N22997 N48742</td>\n",
              "      <td>N41934</td>\n",
              "      <td>0</td>\n",
              "      <td>N22997 N48742</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5843444 rows × 7 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c381767-4378-46cf-9f78-fc4779cf1cb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c381767-4378-46cf-9f78-fc4779cf1cb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c381767-4378-46cf-9f78-fc4779cf1cb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-30d732c8-6ab6-48ac-ac08-13f9a99f9665\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-30d732c8-6ab6-48ac-ac08-13f9a99f9665')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-30d732c8-6ab6-48ac-ac08-13f9a99f9665 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e2d5d331-1ff7-4208-9268-c54f5ecbdf52\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('expanded_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e2d5d331-1ff7-4208-9268-c54f5ecbdf52 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('expanded_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "expanded_df"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "\n",
        "# # Load the Parquet file\n",
        "# processed_df = pd.read_parquet('/content/drive/MyDrive/processed_df.parquet')\n"
      ],
      "metadata": {
        "id": "zbYuXlyijzgM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: read this using pandas /content/drive/MyDrive/user_features.csv\n",
        "\n",
        "user_features = pd.read_csv('/content/drive/MyDrive/user_features.csv')\n",
        "(user_features.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "avDDMPS7ErLH",
        "outputId": "80a9d732-4f3e-4348-b761-41ec84a82d41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  user_id                                      user_features  cluster\n",
              "0    U100  [-2.95864147e-01  3.26706147e-01 -4.03406552e-...        7\n",
              "1   U1000  [-1.44724359e-01 -2.47801140e-01  4.43223372e-...        6\n",
              "2  U10001  [ 1.03209651e-01  5.61017826e-02 -1.79264177e-...        4\n",
              "3  U10003  [-0.14111723  0.05412868 -0.23357573  0.089376...        2\n",
              "4  U10008  [-1.68924790e-01  1.38362664e-01 -5.09465554e-...        2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d013161d-41e1-4ba0-878a-c309d1cc0fa6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_features</th>\n",
              "      <th>cluster</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>U100</td>\n",
              "      <td>[-2.95864147e-01  3.26706147e-01 -4.03406552e-...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U1000</td>\n",
              "      <td>[-1.44724359e-01 -2.47801140e-01  4.43223372e-...</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U10001</td>\n",
              "      <td>[ 1.03209651e-01  5.61017826e-02 -1.79264177e-...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U10003</td>\n",
              "      <td>[-0.14111723  0.05412868 -0.23357573  0.089376...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>U10008</td>\n",
              "      <td>[-1.68924790e-01  1.38362664e-01 -5.09465554e-...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d013161d-41e1-4ba0-878a-c309d1cc0fa6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d013161d-41e1-4ba0-878a-c309d1cc0fa6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d013161d-41e1-4ba0-878a-c309d1cc0fa6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ef082e57-b634-42b6-9295-79181e380466\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ef082e57-b634-42b6-9295-79181e380466')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ef082e57-b634-42b6-9295-79181e380466 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"(user_features\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"U1000\",\n          \"U10008\",\n          \"U10001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_features\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[-1.44724359e-01 -2.47801140e-01  4.43223372e-01  9.02305844e-01\\n -5.52584529e-01  2.96707769e-01 -2.57632290e-01  2.99186364e-01\\n -6.93131695e-01  5.48656126e-01  6.10910685e-01 -1.68814262e-01\\n  2.74759003e-01 -3.72197441e-01  3.94753724e-01  9.59629933e-01\\n  1.72399128e-01 -4.19439015e-01  1.30333930e+00 -1.18846446e-01\\n -2.77210889e-01  7.10741679e-03 -4.95748132e-01  9.18521372e-01\\n  3.70428339e-01 -1.49492592e-01  4.46704328e-02  5.18772801e-02\\n  2.25055029e-01  1.10980844e+00 -2.12926269e-01 -1.71472083e-01\\n -4.33343523e-01 -1.86818356e-01 -5.45685490e-03 -2.41381238e-01\\n  6.27319376e-01  3.63636593e-01 -9.01628604e-01 -9.15256590e-02\\n -7.50440309e-01  4.21059787e-01 -6.54242595e-01  5.11666874e-01\\n  1.92297975e-01 -2.42850304e-01 -3.89878571e-01  1.01175189e-01\\n  3.08232029e-01  5.18765802e-01  1.29901635e-01  6.36467328e-01\\n -5.92617313e-01 -4.33393280e-01 -3.48744165e-01 -2.98071772e-01\\n -6.84237021e-02  4.07317032e-01  7.98698018e-02  7.94084415e-01\\n  7.10509549e-01 -5.71233501e-01 -5.25851607e-01 -1.81020535e-01\\n -4.21885396e-01 -8.30906828e-02 -8.08378160e-02  4.09337924e-01\\n -7.95854479e-02 -3.61612486e-01  2.98755515e-01 -5.65018207e-01\\n -1.11759156e-01 -8.81355405e-02 -1.24518404e+00 -1.82875806e-01\\n -1.25236930e-01 -3.59492447e-01 -9.34165120e-02 -6.71465213e-01\\n -2.80119419e-01 -6.15992645e-01  1.29634758e-01  3.76204252e-02\\n -7.37864584e-01  1.40304297e-01 -1.65294210e-01  1.24234080e-01\\n -3.17615330e-01  6.62968983e-01  6.86080158e-01  2.92946557e-01\\n  3.52136828e-02 -4.45934137e-01  3.10549655e-01 -6.95651571e-01\\n  4.13639493e-01  1.05377108e-01  3.30837334e-01 -4.21647593e-01\\n  2.47980840e-01  5.28196644e-01 -3.79859204e-01 -3.48619279e-01\\n -1.46739864e-01 -2.07734699e-01  7.27169598e-01 -1.54029171e-01\\n  2.83365856e-01  1.26023799e-01  6.20097597e-01  1.47661249e-01\\n  5.61984469e-01  9.82404525e-02 -6.42311980e-01 -9.36780413e-01\\n  1.79831296e-01  2.27908125e-01 -2.55971514e-01 -1.78602844e-01\\n  1.93420748e-01  2.76880960e-01  3.05013885e-01 -2.91880481e-01\\n  2.66226858e-01 -1.22866356e+00 -3.39700873e-01 -2.99043369e-01\\n  6.91966092e-03 -5.65452099e-01 -5.23979823e-01 -3.58261804e-01\\n  1.20358360e+00  8.61559232e-01  5.54283222e-01 -1.83255275e-02\\n  3.72999092e-01 -1.97470888e-01 -2.19874213e-01 -1.66297098e-01\\n  3.07336691e-01  7.70777067e-01  4.20856764e-01  9.17805719e-02\\n -9.58502231e-02 -3.87999415e-01  2.17559273e-01 -3.73052806e-01\\n -4.01869728e-01  7.79638290e-01  1.87777971e-01  2.06136306e-02\\n -1.08647058e-01 -2.58233994e-01 -1.05139546e+00  1.80776907e-01\\n  1.61830962e-01  4.56270168e-01  1.51795324e-01  1.11763349e+00\\n  2.45487707e-01  5.97945203e-01  9.53578949e-01 -6.17843893e-01\\n  3.48224397e-01 -5.59218327e-01  1.70550048e-01  6.65047646e-01\\n  2.96679000e-01  7.78256128e-01 -2.97763320e-01  3.54200284e-01\\n -9.15424476e-02 -1.70334041e-01  3.17982282e-01 -1.86787532e-01\\n -5.34840375e-01 -7.46637106e-01 -3.93534819e-01 -2.46437478e-01\\n -2.88312825e-01 -2.58845704e-01 -4.76900121e-01 -3.39658653e-01\\n  8.90027901e-01 -2.98183116e-01 -1.34497032e-01  3.10280278e-01\\n  4.03915084e-01 -1.35908594e+00 -4.89281481e-01  1.56492752e-01\\n  2.87774517e-01  3.59927495e-01 -9.11661009e-01 -2.02770546e-01\\n  1.89002375e-01  5.40619344e-02  4.87120022e-01 -4.88768555e-02\\n -5.02647062e-02  4.77439413e-02 -2.64153518e-01 -8.87576590e-02\\n  5.95700701e-01 -1.80710278e-01 -4.16305383e-01 -5.10740342e-03\\n -2.45475130e-02  1.08692545e-01  1.50044007e-01 -1.14355783e-01\\n -1.22317721e-02 -4.26051319e-02  7.30689471e-01 -5.48921997e-01\\n -1.70232276e-01  6.17056111e-01  7.39527186e-01  2.80885095e-01\\n -3.65129203e-01  5.17645970e-01 -1.80590852e-01  6.38778269e-01\\n  8.33306164e-02 -3.32458337e-01 -1.59321790e-01  1.23102399e-01\\n  1.04674938e+00 -6.72398292e-01 -4.52279838e-01  7.08655640e-02\\n  2.07424961e-01  1.37865782e-01 -3.63840794e-01  6.89008395e-01\\n -3.03549272e-01 -7.08338122e-01 -3.56610204e-01 -5.01602083e-01\\n -3.27488780e-02  4.87408568e-01 -3.67340863e-01  1.78964252e-01\\n -1.99884633e-01  1.13096305e+00  3.62157583e-01 -1.18346527e+00\\n  3.64354690e-01 -1.63361096e-01  4.74167208e-01  8.89364481e-02\\n -2.45647371e-01 -8.12931557e-01  5.58318471e-01  8.19710785e-02\\n -1.66635883e-01  3.18252350e-01 -9.49501892e-01 -5.84226107e-01\\n  7.91358600e-02 -5.44184645e-01  3.02050670e-01 -2.43681222e-01\\n  2.96929340e-01  2.82453697e-01  6.24556194e-02  1.51220682e-01\\n -1.80687996e-01  3.14233743e-01  5.16008469e-01  8.08614343e-01\\n  6.16118630e-01  1.17151908e+00 -1.20820642e-01 -2.57010251e-01\\n -6.20424946e-01  8.13265885e-01  1.99479918e-01  3.41269273e-01\\n  5.17682216e-01  2.45500589e-01  7.36205137e-02 -1.25668728e+00\\n -1.02769248e+00 -5.13830781e-03 -4.21427409e-01  2.86782324e-01\\n -2.46622192e-01  4.75429595e-01  1.90241777e-01  3.75277325e-01\\n  6.96052506e-02 -6.58730606e-01  5.15223065e-02 -5.88909388e-02\\n  4.09934620e-02  5.86964215e-02 -5.64601486e-01  4.05259093e-01\\n  8.92239332e-01 -2.40913918e-01 -1.09179549e+00  1.99247375e-02\\n  4.01650737e-01  2.98957864e-01  2.83696045e-01  3.38757137e-02\\n -4.77771193e-01 -1.99366093e-01  3.23252380e-01 -3.20516234e-01\\n  1.76065231e-01 -8.50603948e-01  5.76890960e-01  3.10745166e-01\\n  6.17058625e-02 -3.71157974e-01  1.67430490e-01 -5.56387365e-01\\n  3.88433958e-02  5.47758540e-02  2.11426991e-01 -8.56648261e-02\\n -4.28441132e-01  2.77817825e-01  5.45576110e-01  3.10903192e-01\\n -3.59141310e-01  1.00126932e-01 -5.59955796e-01  6.21287191e-01\\n  9.15075004e-01  3.39063565e-01 -1.06511335e-01  5.03954033e-01\\n -1.21011535e-02 -4.20403828e-01 -1.00257012e-01  3.31750697e-01\\n  3.32213819e-01  5.76329196e-01 -7.77995030e-01 -2.25394140e-01\\n -5.08957346e-01 -3.66119325e-01 -1.54771209e-02 -2.91426388e-01\\n  3.68184509e-02  3.06680918e-01 -1.28474007e-01  2.16101090e-01\\n -2.34288712e-01  2.22025235e-01  2.18069961e-01 -4.86761520e-01\\n  9.44116632e-01  6.83546593e-01  4.43133563e-02  6.01009861e-01\\n  8.31129154e-02 -4.96828735e-01  8.20800662e-04  3.91419480e-01\\n -4.60083336e-01  4.78023981e-01  3.84897391e-01 -4.05003458e-01\\n  6.02790932e-01 -7.13785907e-01  5.38428913e-01  6.28650824e-01\\n  8.37902953e-01 -3.17066868e-01 -1.86144814e-01  5.70959012e-01\\n  3.80221921e-01  4.37246710e-01  1.20022097e+00  1.13106730e+00\\n  4.09997508e-01  1.96514751e-01 -1.08595223e-02 -5.00787144e-01\\n -4.10462817e-01  3.12954187e-03  8.21369032e-01  9.13070043e-02\\n  9.35718815e-01 -1.18501728e-01  6.86593950e-01  2.48605291e-01\\n -4.79533213e-02 -6.12545460e-02 -4.25200542e-01  2.20371395e-01\\n  4.53108569e-01 -1.99323008e-01  7.23961753e-01  7.65452087e-01\\n  1.09545185e+00  2.62306770e-01 -5.02495229e-01  1.84953359e-01\\n  8.74033014e-01  7.00825453e-01 -2.01053401e-01  6.59931699e-03\\n -3.73117596e-01 -6.82147930e-01  2.79868171e-02 -2.17174162e-01\\n -2.07729574e-01  4.89671126e-01 -3.72516458e-01 -5.46474030e-01\\n  6.96561918e-01 -4.82057416e-01  1.23933112e-01 -2.26309280e-01\\n -1.47017136e-01  8.44947880e-01 -3.16485974e-01  6.39111772e-02\\n  1.20750038e+00  4.85407829e-01 -3.39372655e-01 -1.72464957e-01\\n -1.84911831e-01  2.92612607e-01  7.62212535e-01  3.61911149e-01\\n  6.82288955e-01  4.12944748e-01  1.14371984e+00  5.36164572e-01\\n  2.31092088e-01 -3.52719848e-01  2.17186311e-01 -4.65906143e-01\\n  6.66104396e-01  2.63354989e-02  5.88755101e-01 -8.92180314e-01\\n  6.61518375e-02 -1.20084137e-01  4.08734222e-01  8.62994174e-01\\n  5.07301807e-01  5.83453923e-01  4.87631967e-01  4.04200502e-01\\n -4.25547838e-01 -1.67251912e+00  6.68906748e-01  6.44501408e-01\\n -3.74294420e-01  3.00912321e-01  1.70595179e-01 -1.83947238e-01\\n -3.32318698e-01  3.31310252e-01 -1.42215768e-01 -2.29308565e-01\\n -8.26319059e-03  2.57243972e-01 -3.17891416e-01  1.26524043e+00\\n -2.15569566e-01 -4.64131435e-01 -3.32065364e-01 -1.69260323e-01\\n  1.38848447e-01  2.45120982e-01 -3.14355145e-03 -3.21804906e-02\\n -5.95698049e-01  5.15908023e-01 -3.39028715e-01 -4.89633029e-01\\n -5.05717125e-01  3.02832752e-01 -1.64957777e-01 -1.77575002e-01\\n  3.95046393e-01  2.33349130e-01 -1.19290221e+00  4.98457164e-01\\n -1.54876242e-01  1.83654149e-01 -2.01202162e-01 -8.32282980e-01\\n -3.55919600e-01 -1.23743763e-02 -5.24380565e-01  1.14801288e-01\\n -9.06204124e-01 -9.48461076e-01 -2.44500319e-01 -8.15626234e-03\\n  2.33456939e-01  4.85076865e-01 -7.48932590e-01 -5.45227664e-01\\n  4.79280328e-01 -5.54804961e-01 -2.03149679e-01 -3.81876528e-02\\n  1.24517481e-02 -1.54439380e-01 -2.92839249e-01  1.63963505e+00\\n  8.44728306e-01  3.85700576e-01 -1.15346710e-01  7.18427966e-01\\n  9.48504637e-01 -4.45949952e-01  2.33963872e-01 -1.47930776e-01\\n -5.96384366e-01  6.86565797e-01 -5.06622123e-01 -5.33466448e-01\\n  1.73276914e-01  1.23740941e-01  9.73108908e-02  7.30109115e-02\\n  3.75795906e-01 -1.81091885e-01  1.72095865e-01 -2.82088336e-01\\n  5.76548380e-01 -3.52981187e-01 -4.79559172e-02 -1.05426388e-01\\n  1.14054744e-01  4.15526489e-01  4.61807092e-01  1.02338936e+00\\n  1.14240201e+00  2.09059536e-01 -1.07594113e-01 -2.94547339e-01\\n -2.56121914e-01  2.07789396e-01 -3.06107322e-01  3.30866168e-01\\n -1.01269652e-01  7.12795367e-01 -2.24922995e-02  7.22598751e-01\\n -3.37336063e-01  1.93352858e-01 -7.82031417e-02 -2.39348964e-01\\n  5.21271798e-01 -2.69832959e-02 -2.58441597e-01 -3.84907782e-01\\n -4.11637311e-01  6.61468526e-01  5.24782793e-02  3.51913333e-01\\n -2.59688874e-01  4.58710760e-01  4.85310833e-01  9.37245339e-02\\n -5.91123720e-01 -6.93642795e-02 -6.47582104e-01  7.01563348e-01\\n  9.18030292e-02  1.63215152e+00 -8.78374398e-01 -6.13892823e-02\\n -2.89892557e-01 -6.16919259e-01  2.92813202e-01 -4.26312397e-01\\n  5.88137895e-01  6.45716925e-01 -1.30326784e+00 -1.37566896e+00\\n -1.09570734e-01  2.51349399e-01  9.80222325e-02  1.27375176e-01\\n  1.48987062e+00  8.74028474e-01 -1.76338842e-01  4.05211389e-01\\n  4.11846814e-01 -5.50088843e-01 -1.32714413e-01  2.33811928e-01\\n  7.91420639e-01  7.13176072e-01 -8.87137776e-02  1.18107200e-02\\n  3.47302953e-02  2.10225170e-01 -2.18273858e-01  5.11865377e-01\\n  3.64517219e-01  4.21742896e-01  4.83362039e-01 -3.81983627e-01\\n -1.04754555e+00  5.23887545e-02 -1.85647686e-01  7.51296004e-01\\n -9.11557058e-01  5.22788664e-01  1.01594046e-01 -9.54516691e-02\\n -7.58425766e-01  4.30226788e-01 -3.18324745e-01 -2.96824733e-01\\n  5.40048266e-01  2.27342188e-01  5.35622021e-01  2.00159661e-01\\n  7.34419271e-01 -3.75535885e-02 -2.24327614e-01  7.54439006e-01\\n -2.99058850e-01 -9.57760660e-01 -5.17979900e-01 -1.27519667e-01\\n  2.22506652e-01 -5.62758495e-01  1.11018022e-02 -8.69930387e-02\\n  2.70836572e-01  5.73233515e-01 -6.31641376e-02 -1.30572657e-01\\n -6.59486358e-01 -3.00516685e-01  3.35393177e-01  2.17061266e-02\\n  5.51080704e-02  3.68495941e-01 -3.80124559e-01  3.83686269e-01\\n  4.34126357e-02  1.11231810e+00 -8.83764712e-02  1.59395142e+00\\n -4.16886757e-01  5.67389548e-01  4.43355580e-01  8.63851964e-01\\n  1.04789388e+00 -1.20607267e-01  2.03709662e-01  1.09147058e+00\\n -1.96514726e-01  1.94531312e-01  1.07158901e+00  3.00890586e-02\\n -4.49850162e-03 -2.15100686e-01  1.29131731e-02  4.38387970e-01\\n -2.36646925e-01  8.50745315e-02  6.37663802e-02  4.90205521e-01\\n -5.96874952e-03 -5.87343956e-01  2.46475498e-01  2.23832155e-01\\n  3.47544059e-01 -2.61267836e-01 -1.95691695e-01  9.01341677e-01\\n  1.20344480e-01 -1.42830441e-01  7.36610542e-01 -6.12239619e-01\\n -4.79550328e-01 -6.28704776e-01 -9.74171956e-01  1.30132720e-01\\n -5.00261962e-01  6.96291526e-03  1.81782166e-01  4.18893596e-02\\n -6.46937658e-01 -9.91666118e-02  3.69161944e-01 -4.19284473e-01\\n -1.27777378e-01  1.70803407e-01  3.50021397e-01  1.89159562e-03\\n -9.44346339e-02  2.96542831e-02 -3.01355297e-01  3.39020987e-02\\n  4.11959171e-01 -7.90158461e-01  5.21485706e-02 -4.43098605e-01\\n  2.87753214e-01  2.38427202e-01 -2.09152435e-01  6.47825956e-01\\n -2.40977888e-01 -1.57462801e-01  4.24147993e-01 -7.73479740e-02\\n -6.74263239e-01  5.21242688e-01  3.28215698e-01 -2.87415246e-01\\n -1.61826645e-01  2.25165536e-01  3.23325319e-01  6.58879598e-01\\n -1.94337557e-01  1.65696152e-01  2.67021631e-01  5.58464363e-01\\n -3.39293381e-01 -1.28788421e-01 -2.20310291e-01 -4.68174626e-01\\n  3.33221450e-01 -3.19462309e-01  2.58921723e-01 -6.97990417e-01\\n -6.23643994e-01  1.19990011e-02 -4.99120981e-01 -2.25557158e-01\\n -5.02905011e-01  3.83436754e-01  5.49888223e-01  5.00953471e-02\\n -3.40120092e-01  4.32600001e-01  1.61848615e-01 -5.29980540e-01\\n  2.19750777e-03 -4.04964448e-01  1.03881671e+00  3.17266534e-01\\n  2.34106916e-01 -6.84383929e-01  2.58096139e-01  9.42942128e-03\\n  2.23782221e-01  1.57058204e-01 -6.67544603e-02 -3.20946376e-01\\n  9.60013012e-01 -6.63551042e-02  3.89221301e-01  1.64106473e-01\\n  5.66208502e-01 -8.36886138e-01 -3.58091120e-01 -7.77786622e-01]\",\n          \"[-1.68924790e-01  1.38362664e-01 -5.09465554e-01  1.02586479e-01\\n  1.16658584e+00  8.22645907e-01 -1.80581893e-01 -2.43267740e-01\\n -2.07901808e-01 -5.54319453e-01  2.69940741e-01 -8.19272952e-01\\n  2.33407506e-01 -1.06925012e-01 -3.35551079e-01 -4.22187863e-01\\n  2.08530825e-03  8.67354878e-02  1.07791338e-01  1.36223491e-01\\n -5.10751126e-01  1.48959413e-01 -5.81229643e-02  1.18541970e-01\\n  2.67765350e-01  4.49547496e-02 -3.63228875e-01 -8.42939271e-01\\n -4.85318451e-01 -4.43529884e-01 -4.91173878e-01  3.47536798e-01\\n  4.81337765e-01 -5.15022030e-01 -2.57894140e-01  3.56133383e-01\\n  7.30323957e-02  1.79827844e-01 -7.95019964e-01  2.66545813e-01\\n -2.10947008e-01  6.09900482e-01  1.34141114e-01 -8.18184548e-01\\n  5.92670072e-01 -6.31947405e-02  2.22491009e-01 -7.27942394e-01\\n -1.20589590e-02 -4.09787346e-02 -2.04914638e-02  4.51484565e-01\\n  1.36004383e-01  1.60333495e-02  3.02261721e-01 -1.17930619e-01\\n  1.21477246e-02 -4.23718461e-01  8.30565907e-01 -2.82270705e-02\\n  6.43678125e-03  2.09724763e-01 -3.80435942e-01  5.45975145e-03\\n  2.55493709e-01 -2.11667797e-01  6.27339275e-03 -1.35170710e-01\\n -1.56962450e-01  2.36458087e-01  1.99056709e-01 -6.54830652e-01\\n  2.33476963e-01 -2.04515526e-01  4.38300373e-01  5.98151658e-03\\n  7.54851841e-01 -1.15634091e+00  3.45200877e-01  4.34004200e-01\\n  5.14149242e-02 -9.85151479e-01  5.66543865e-01 -4.98904227e-01\\n -4.43566978e-03 -5.19769457e-01 -7.99861952e-02 -1.21635840e-01\\n  1.37166095e-01  4.02190398e-01 -2.88794162e-01  6.92674707e-02\\n -8.08843005e-01 -2.61567809e-01  6.39896994e-01 -2.39187796e-01\\n  1.06064204e-01 -1.85447999e-01  4.34093040e-01 -3.50959065e-01\\n  5.85527272e-01  2.95261276e-01 -6.07541067e-01 -1.31820886e+00\\n -4.72062988e-01 -1.59265887e-01  3.16756286e-01  3.13199587e-01\\n -7.42632664e-02  6.97028621e-01  1.00420931e+00  2.77669824e-01\\n  2.66226520e-01 -3.02239519e-01  1.11208050e-01 -5.19423675e-01\\n -4.74852234e-02 -2.58460914e-01  1.46440246e-01 -8.69330181e-02\\n -6.42909166e-01  3.39462388e-01  9.03232552e-01 -1.62346837e-01\\n -5.02233978e-01 -6.51392251e-01  4.68046563e-01 -2.42593636e-01\\n -6.63439637e-01  2.29508511e-01  2.04340283e-02 -1.34231025e+00\\n  3.23692169e-01  1.01882667e-01  1.00068736e-01  3.50775340e-02\\n  6.27881774e-03 -3.51919206e-01  1.30607793e-01  5.98835323e-01\\n -6.92963662e-01  6.45404020e-01 -2.43679136e-02 -3.53576293e-01\\n -1.68526422e-01 -5.41646470e-02 -5.80458977e-01  1.54432422e-01\\n -5.87375014e-01 -1.59540402e-01  5.77995096e-01  4.05033685e-01\\n -7.11468991e-01  2.72699246e-01 -3.72796513e-01  2.79962789e-01\\n  5.08510806e-01  6.54845118e-02 -4.09033560e-01  3.03221196e-02\\n  2.55867355e-01  3.43270194e-01  7.79694228e-02  2.02293262e-01\\n  1.90250536e-01  8.39931036e-02 -3.30372971e-01 -2.45515576e-01\\n -6.06737939e-01  2.83910672e-01 -4.08739078e-01  2.99056459e-01\\n  1.07440273e-01  4.52520280e-01 -5.62327389e-01 -5.33916817e-01\\n  7.07948425e-02 -1.16933319e-02  3.19010430e-01 -2.42521209e-01\\n  2.31351984e-01  2.46207927e-01 -1.38321259e-01 -1.41212739e-01\\n -6.54817279e-01 -5.45825134e-01  2.64636589e-03  2.86144292e-01\\n -6.46102236e-01 -5.50631650e-01  8.99845895e-02 -4.10372023e-01\\n -4.61964236e-01 -3.36098305e-01 -6.86899725e-01  4.21222023e-01\\n -8.00560998e-02 -1.45107512e-01  3.07830983e-01  2.90868481e-01\\n -1.21623083e-01  9.81538399e-02  2.97226294e-01 -6.74832606e-01\\n -5.27254295e-01  1.11828660e-02 -4.39899687e-01 -2.75515668e-01\\n -6.71034871e-02  5.65039315e-01  3.49585066e-01 -6.67082064e-01\\n  6.15507986e-01  1.75534658e-01  2.02427306e-01 -2.61636739e-01\\n  3.47649089e-01 -1.26423231e-02  5.27736719e-01  1.57164010e-01\\n  3.93852709e-01  4.81681278e-01 -9.22761083e-01  2.70805408e-01\\n  5.37762288e-01  1.37674433e-01 -4.95527978e-01  5.79756959e-01\\n  3.36979455e-01 -3.27865340e-01  1.19566932e-01  2.96204328e-01\\n  9.21823486e-02 -3.33206803e-02  1.13931182e-01  1.57970138e-01\\n -4.39920607e-01 -4.94228456e-01 -3.67042242e-02 -4.37397460e-01\\n  5.10452758e-01  7.35993245e-01 -1.46703687e-01 -1.47961972e-01\\n -3.30292335e-01  3.25009676e-01 -2.06853355e-01 -1.95919775e-01\\n -5.53989229e-02 -3.45839821e-01 -7.27907600e-02 -2.07162808e-01\\n -5.73140264e-01 -8.66023065e-01  5.64427938e-01  9.62598926e-01\\n -2.05443932e-01 -6.77952509e-01 -2.43257398e-01 -4.67142569e-01\\n -2.70324070e-02  2.62604058e-01 -3.19650419e-01 -2.26443533e-02\\n  6.83880302e-01 -4.84693127e-01 -4.12301922e-01 -1.94348685e-01\\n  1.67803371e-01 -6.39695087e-01 -4.62795694e-01 -4.53913158e-02\\n  8.90557047e-04  2.19651464e-01  8.31955665e-01 -1.92926758e-01\\n  6.00147057e-01  1.07479735e+00  9.14860660e-01 -5.05317067e-01\\n  4.67028201e-01  7.13305323e-02  1.17602023e+00  6.52028598e-02\\n  2.67773490e-01 -1.34506207e-01  3.91093632e-01  5.31929911e-01\\n  3.36674995e-01  4.74610997e-01  4.48572221e-01  5.57623052e-01\\n  3.10237314e-01  9.19954343e-02 -4.42123347e-01 -2.47877151e-01\\n  2.62539986e-02  5.82689858e-01 -3.45108868e-01  1.15998809e-01\\n  9.42945105e-02  9.38806642e-02 -8.64568813e-01  9.64955295e-02\\n -9.71259493e-02 -3.46220476e-01 -4.38084315e-01 -1.23741717e-01\\n  6.96039356e-01  9.83162218e-01 -6.05728584e-01 -1.34407246e-01\\n -3.44568383e-01 -7.99054263e-02  5.87849951e-01  1.70979687e-01\\n -4.64967322e-01 -5.32225442e-01 -6.99679945e-02 -2.71925188e-03\\n  6.03764342e-02 -1.23950320e-01 -5.33667331e-01  3.30511282e-01\\n -1.90032843e-01 -2.70269505e-01  3.21761576e-01  3.64643833e-01\\n  9.03038238e-02  4.03136559e-01  2.87779835e-01  3.57410205e-02\\n  3.27213402e-01  3.43628544e-01  2.57153296e-02  2.11426005e-01\\n  2.13124829e-01  7.34150276e-01  2.00839746e-01  5.61465354e-01\\n -1.28166569e-01 -1.61745546e-01 -2.06044232e-01  1.71660207e-01\\n  2.11632708e-01 -3.83650909e-01 -2.50588292e-01  6.28722748e-02\\n -2.75297144e-01  6.70846724e-01 -4.44351972e-02  8.77729447e-03\\n  7.96877634e-01 -3.44656202e-01  7.35598006e-01  2.53352499e-01\\n  3.92820554e-01  6.04343975e-01 -4.40607167e-01 -2.09091609e-01\\n  5.75150211e-01 -6.45929723e-01  2.17739142e-01  5.01489214e-02\\n  6.85905698e-02  8.81637056e-01  8.53261433e-02  5.26233323e-01\\n -2.98996731e-01 -3.01536170e-01  4.62144683e-01  3.35348420e-01\\n -8.66387366e-02  1.16124232e-01 -4.78731218e-01  1.01662455e-01\\n  1.09834115e+00 -1.80030224e-01  6.22680465e-01  2.09338173e-01\\n -3.07623165e-02  1.91801472e-01  1.34025502e-01 -2.56113116e-01\\n -2.38790056e-01 -4.03146303e-01  3.69349126e-01  1.95187810e-01\\n  2.74114325e-01 -2.54237651e-03  4.58603745e-01 -2.48344525e-01\\n -4.41833717e-01  2.32311063e-01  7.25136475e-01  6.49151509e-01\\n -5.91146599e-01 -2.23442929e-01 -7.32344399e-01 -4.55006130e-02\\n -1.40505859e-01  9.57996592e-02 -3.21181640e-01 -1.87832786e-01\\n  2.26674159e-01  9.10649563e-01 -4.05075675e-01 -1.62652173e-01\\n  4.15436070e-02 -6.37665338e-01  8.16949936e-01 -1.35269373e-01\\n  3.37601610e-01 -6.46355492e-02  4.55712917e-02 -4.97420398e-01\\n  6.99076650e-01  3.35681605e-01  8.62593322e-01 -9.58764730e-02\\n  5.73219034e-01  1.98821559e-01 -1.61981675e-01  8.84393898e-02\\n  2.84955399e-01  2.72627183e-03  3.25218703e-01 -2.97383815e-02\\n -3.94210971e-02 -2.90080876e-01  6.56450639e-01 -1.18104261e-01\\n  9.59875466e-01  3.10745305e-01 -1.50249483e-01  1.03193227e-01\\n  2.19205478e-01 -2.91383593e-01  1.01837965e-01 -5.25036283e-01\\n  2.19620243e-01  5.11053181e-01  9.28703537e-01  1.15368484e-01\\n -1.45657563e-01  2.44370792e-01 -4.28453502e-01  5.20643932e-01\\n  1.93902079e-01  2.39599884e-01 -1.49463912e-01  7.68263175e-01\\n  2.39699680e-01  5.73685409e-02  5.72545497e-01  4.05031936e-01\\n -1.91153509e-01  5.86303273e-02 -1.11411301e-01 -8.52278214e-01\\n  1.98767364e-01 -1.91432052e-01 -2.51736075e-01 -5.24197070e-01\\n -2.94102741e-01 -1.29896092e-01 -6.07861241e-01  1.15387274e-01\\n -4.29377516e-01 -5.06085799e-02  1.98136172e-01 -2.64787837e-01\\n -3.96258604e-01 -1.81215349e-01  5.63349931e-03 -4.00051812e-01\\n  6.01817049e-01 -2.93855011e-01  2.45172202e-02 -2.30696467e-01\\n -2.14314901e-02  1.83549161e-01 -2.58010814e-01 -3.67182282e-02\\n -5.42023416e-02  6.15415359e-01 -6.56509672e-01 -1.12823885e-02\\n  3.15434593e-01 -2.58968186e-01 -4.24285271e-01 -2.24199089e-01\\n  4.07257795e-01  8.96229113e-01 -5.36076459e-01  3.43766465e-01\\n -1.01249958e+00  1.57202050e-01 -5.50930586e-02 -7.91215748e-01\\n  4.52396431e-01  4.91182697e-01 -1.49811871e-01 -1.19192078e-01\\n  1.24030221e-01 -1.29715444e-01 -6.95313221e-02  2.62559364e-01\\n  2.23185145e-01 -1.63414440e-01 -1.52308048e-01  1.07444777e+00\\n  4.67172705e-01  2.35271096e-01  5.32481240e-02  3.66446951e-01\\n  5.90794264e-01 -6.46239956e-01  3.12480062e-01 -6.76011691e-01\\n  6.63688826e-01 -3.58056921e-01  1.89716174e-01  1.56439617e-01\\n  5.00253693e-02  5.91405001e-02  6.60797210e-01 -3.63685800e-01\\n  1.07636573e-01 -2.60689373e-01 -3.31373565e-01 -3.68056412e-01\\n -4.92435292e-02  1.01395810e-02  1.57823652e-01  4.15592314e-01\\n  3.13105016e-02  4.37507876e-01  9.99148565e-02  1.41611628e+00\\n  5.12289698e-01  3.77661029e-01  2.00671834e-01  5.30459531e-02\\n  4.90534999e-01 -7.15970353e-02  1.09019327e-01 -4.85265704e-01\\n  2.11395321e-01 -3.49882755e-01 -2.62958085e-01  2.00940511e+00\\n  2.62527162e-01 -1.99499972e-01  8.65489845e-02 -1.96690038e-01\\n  1.76759447e-01  3.09986904e-01  1.60952484e-01  5.80905303e-02\\n  6.81309897e-01  7.47903986e-01  3.86127155e-01  6.16323934e-01\\n -5.80121100e-01  2.14632885e-01  3.80175341e-01 -4.33966010e-02\\n -5.46483988e-01  5.17305433e-01  5.07421370e-01 -2.05708444e-01\\n -5.15641679e-01  3.60991463e-02  7.23670142e-01 -2.66160621e-01\\n  1.98315008e-01 -8.24464531e-02  2.63490985e-01 -1.08386055e-01\\n  1.63858059e-01 -4.50575850e-01 -4.51499323e-01 -3.97536923e-01\\n  1.82104504e-01 -9.00959828e-02 -1.01527245e+00 -2.56099567e-01\\n  1.70562175e+00  7.39646003e-01  4.07803664e-01  6.48105685e-01\\n  3.00248148e-01 -3.26238216e-01  3.18142025e-02 -7.75700404e-01\\n  4.61524166e-01  1.81347171e-01 -2.43081081e-02 -2.85960757e-01\\n -4.96825886e-01  2.54509228e-01  6.63814988e-02  4.18752491e-01\\n  1.13783147e-01  3.24727195e-01 -1.33724036e-01  1.53813923e-01\\n  3.93804292e-01 -8.06726433e-01 -5.01717762e-01  1.01674245e+00\\n -8.97716986e-01  5.35285768e-02  2.12535381e-01 -2.78028799e-01\\n  8.80367848e-02  2.40463606e-01 -2.96061215e-01  4.14204743e-01\\n -8.23399836e-02  1.88711510e-01 -5.14232254e-02 -3.77598069e-01\\n  1.49021324e-02  4.61523432e-01  1.72758280e-01  4.80126842e-01\\n  2.15929069e-01 -6.16321843e-01 -3.22045930e-01  6.40056162e-01\\n  7.58355380e-01  3.04249601e-01 -1.80839477e-01  5.81234259e-01\\n  8.46813065e-01  1.86629455e-01  2.94835822e-01  2.85048946e-02\\n  2.27646795e-01  8.26102386e-02  6.97558787e-01  2.85113189e-01\\n  1.12354472e-02  3.87155273e-02 -2.21183762e-01  5.23099305e-01\\n -4.02623117e-02  2.35646226e-01  3.45663932e-01  8.68888316e-01\\n -5.34058730e-01 -1.42235492e-02 -2.36579201e-01  6.37996016e-01\\n -1.06585205e-01 -3.73645597e-01  8.07945973e-02  3.53171029e-01\\n -1.14571409e-01  4.28883971e-01  3.51026855e-02  5.39869321e-01\\n  2.61245158e-01  1.64839604e-01 -2.19129692e-02 -6.95485166e-02\\n  4.42530488e-01 -1.36002791e-02 -7.90850027e-01  1.91858456e-01\\n  6.89306854e-01 -3.67292154e-02 -1.21654537e-01  2.84832847e-01\\n  2.10631444e-01 -5.72557870e-01  5.64914501e-02  6.82850362e-01\\n -3.61026257e-01  4.97355832e-01  1.01732822e+00  1.80186287e-02\\n -2.42127065e-01 -1.77345108e-01 -2.54821951e-02  1.60496511e-01\\n  6.73990358e-01 -7.60574185e-03 -2.81357796e-02  1.88811996e-01\\n -2.45007695e-01  6.06262001e-01 -5.31433802e-01 -6.83011084e-01\\n  7.25538949e-01  2.94051339e-01 -4.63092153e-01  2.05094421e-01\\n  5.17230146e-01 -2.32596472e-01  4.63322383e-01  3.08491127e-01\\n  4.29678614e-01 -5.57684451e-02  1.34775469e-01 -1.89360446e-01\\n  1.07907224e-02  2.32883239e-02 -5.54633230e-01  7.21813967e-01\\n  1.72797259e-01 -1.50120342e-01  2.32786151e-01  4.37408757e-01\\n  8.59528865e-02  8.45312084e-01  5.18695500e-01 -7.61276911e-01\\n  6.50098674e-01 -8.66753838e-02 -5.56733819e-02 -2.41736645e-02\\n -1.13948286e-01  5.18085564e-01  2.05952861e-01  1.22412353e-01\\n  8.81536391e-02  2.49135646e-01  2.67796292e-01 -3.07821404e-01\\n -2.80893347e-01  9.41181748e-01 -1.28195201e-01 -4.86513901e-02\\n  5.13404878e-01 -1.77656165e-01 -4.03104766e-01 -2.03864642e-01\\n -4.84932018e-01  1.41989445e-01  6.63528698e-01 -1.17254518e-01\\n  5.28960400e-03  1.93479872e-01 -2.47429760e-02 -1.60845948e-01\\n  3.84368446e-02 -1.65595993e-01 -4.04975714e-01 -3.40662288e-01\\n -7.21535418e-01 -2.27459614e-02 -1.78212349e-01 -2.25766289e-01\\n  1.55975488e-02  2.58335630e-01  1.49877790e-01 -2.76590191e-01\\n  7.38610897e-01 -5.68870763e-01  4.83486540e-01  1.49882994e-01\\n  5.77820291e-01 -9.78557443e-01 -4.42948487e-02 -2.04322663e-01]\",\n          \"[ 1.03209651e-01  5.61017826e-02 -1.79264177e-01 -3.98016031e-02\\n  2.45890072e-01  2.16156956e-01  2.41573959e-01 -3.40835798e-01\\n  1.23429644e+00  8.25156093e-02  1.24351430e-01 -6.76688065e-01\\n  3.36726520e-01 -6.45427462e-01 -2.50167026e-01  5.53613243e-02\\n -3.85361126e-03 -8.30419681e-01 -4.59100753e-02  6.79805220e-02\\n -1.66200063e-01  8.94631940e-01  6.20162770e-01  9.61388152e-01\\n -7.49491060e-01 -5.54752059e-02  6.28249446e-01 -3.58170519e-01\\n -3.54351054e-01 -7.89469555e-01 -8.51331919e-01 -7.85893421e-01\\n  5.59017372e-01 -7.57143845e-03 -7.28629881e-01 -2.83519447e-01\\n  4.62639134e-01 -1.03570454e-01 -6.84254224e-01 -5.70744096e-02\\n -2.98372146e-01  1.06859834e+00 -6.51704542e-01 -2.96291091e-01\\n  1.14126017e+00  9.46643837e-03  2.61803625e-01 -3.12084393e-01\\n  6.19179427e-01  4.33704982e-01  5.38907284e-01 -7.67032847e-02\\n  6.76404439e-01 -1.22409629e-01  1.36920235e-01 -6.49745784e-01\\n  1.92854079e-01  1.93807941e-01  2.35768982e-01 -3.48019277e-02\\n -9.44292788e-01  4.64897908e-02 -2.28149250e-01 -1.96254463e-01\\n -1.16056335e-01 -3.45255538e-02 -4.24384417e-01 -9.26488322e-01\\n  7.67598332e-01 -2.97824129e-02 -1.98438791e-01 -4.55223753e-01\\n  2.90672002e-01  4.24600568e-01  3.39560915e-01 -6.32613767e-02\\n -1.58778455e-01 -2.55007069e-01  7.78168021e-01  1.78869752e-03\\n -4.11197197e-02 -5.47252336e-01  4.30470744e-01 -4.44061104e-01\\n -5.03424714e-01 -4.77682552e-01 -2.23916890e-01 -6.52896555e-01\\n -8.12968930e-02  4.53260565e-01 -2.19151531e-01  4.22156026e-01\\n -6.93676449e-01 -4.77330595e-02 -5.05490730e-01  6.97691414e-01\\n  2.88755693e-01  7.50017541e-01  1.65276902e-01  1.83341916e-01\\n  1.09433554e+00 -3.22826299e-01 -5.35659562e-02 -2.59616842e-01\\n -1.19223925e-02 -1.02679684e-01  7.25868105e-01  2.83391363e-01\\n -4.38333582e-01  7.83462467e-01 -2.53536699e-01 -3.77685774e-01\\n -1.14691646e-01  2.71985466e-02 -1.25959295e-01 -1.97748436e-01\\n  9.68155738e-02  4.21703424e-01 -2.52895536e-01  1.72538449e-01\\n  2.74942368e-01  1.65421486e-01  2.51112583e-01  4.27152530e-01\\n -7.96271045e-01 -7.66283274e-03  1.40902040e-01 -1.93045560e-01\\n -5.44582700e-01  6.64374264e-01 -9.90372216e-03 -6.61669767e-01\\n  2.49220121e-01  7.00502102e-01 -5.76687161e-01 -4.76197716e-01\\n -5.74885656e-01 -5.97331067e-01  2.06152200e-01  4.94076306e-01\\n -4.68218161e-01  6.32668232e-02 -1.28902618e-01 -8.21164805e-01\\n  1.48306439e+00 -3.44221254e-01  1.37892562e-01 -6.29241731e-01\\n  1.04483177e-01 -1.13249302e-01  3.18343971e-01  4.08678629e-02\\n -4.98370285e-01  1.23809487e-01  6.50372813e-01  7.14199315e-01\\n  7.89113569e-01  1.37308942e+00  8.80549918e-02  2.15671223e-01\\n  7.54267891e-01  2.99665667e-01 -5.87840141e-01  5.82397660e-02\\n -8.46795149e-01 -7.43835060e-01 -8.16289554e-02 -3.56562123e-02\\n -4.11007990e-02  8.89709447e-01  2.16993542e-01  2.59613554e-01\\n -2.31462547e-01  4.11296026e-01 -3.83570756e-01 -1.36541225e-01\\n  4.10627409e-01 -5.78218382e-01 -1.57355369e-01 -3.69624386e-01\\n -1.69749484e-01  3.82866590e-01  4.78133134e-01  3.97547150e-01\\n -3.93096042e-01  4.02351082e-01 -2.63305050e-01  6.60953960e-01\\n  2.95610641e-01 -3.71103605e-02  7.09251838e-01  1.42293221e-01\\n -2.02117777e-01  5.65968965e-01 -5.87720474e-02 -2.17562073e-01\\n -3.98735825e-01  1.47481648e-01  3.05398375e-01  1.13212302e-01\\n  3.56470911e-01  1.17854117e+00 -1.81718382e-01 -2.08582666e-01\\n -2.60646791e-01 -3.88835318e-01 -9.92531870e-03  4.67222210e-01\\n -3.59174848e-01  5.75415986e-01  6.14450320e-01  4.04904484e-01\\n -8.33146185e-02  3.59248283e-01  8.59386857e-01 -5.46646426e-01\\n -4.17294413e-01  5.21518371e-01 -3.29489572e-01  7.97725916e-03\\n  6.03678809e-01  6.68213748e-01  1.79395753e-01 -7.55758961e-02\\n  2.16603688e-01  7.86918024e-01 -1.40540134e-01 -2.34248664e-01\\n  1.01602482e-01 -6.34030964e-01  3.55576362e-01 -7.09599265e-01\\n  1.45371767e-01 -4.07009367e-01  5.62624668e-01 -6.72402009e-01\\n -3.65865243e-01 -4.33728940e-01 -8.86754599e-01  2.02268754e-01\\n  2.42093544e-01  6.52544156e-01  2.30575893e-01  2.22847332e-01\\n -7.91766585e-02 -3.37267367e-01  7.39499308e-02 -4.59071847e-01\\n -6.91965650e-02  2.10912820e-01 -1.13117676e-01 -2.06394300e-01\\n -5.95814101e-01 -4.89413584e-01  7.13801755e-01  1.50151052e+00\\n -7.09606620e-01 -4.17691418e-01  5.97065663e-01  6.80450484e-01\\n  4.91695324e-01  1.59535185e-01  2.49506948e-01  2.89837279e-01\\n -3.81820600e-01 -5.30334374e-01 -1.05168430e+00  3.53668990e-01\\n -2.29716280e-01 -3.18855800e-01 -2.27146457e-02 -2.20736271e-01\\n  6.73319524e-03 -5.10317126e-01  3.86822212e-01 -3.00534619e-01\\n  4.00343351e-01  8.67217255e-01  7.42043875e-02 -7.87070791e-02\\n -9.85937043e-02  5.31595061e-02  4.42863524e-01  1.68204383e-01\\n -4.81779574e-01 -4.74821726e-01  8.55622595e-01  1.88366779e-02\\n -3.07903907e-01 -3.30101565e-02  2.81907254e-01  5.65221792e-01\\n -6.01600921e-01 -1.24035291e-01 -4.62859513e-01 -4.09199760e-01\\n -1.45580054e-01  1.27868302e-01  3.44626103e-02  1.77620892e-01\\n  4.87115172e-01  6.96386298e-01 -7.41849866e-01  4.83876402e-02\\n  4.97500048e-01 -7.04789267e-01 -2.93118568e-01  6.44057504e-01\\n  1.32124802e+00  8.84292533e-01 -2.88001267e-01 -6.56038137e-01\\n -3.70267166e-01  3.22740570e-01  7.07833381e-02 -7.75590733e-01\\n  7.94351617e-01  3.55770489e-01 -1.50942148e-01 -3.24204172e-01\\n -3.31851204e-01 -3.27489373e-01 -1.13567744e-02  1.36861061e-01\\n  4.26826288e-02 -2.78425071e-01  5.46987848e-01  7.91944041e-01\\n  4.78713552e-01  6.50543508e-01  7.72887782e-01 -3.93575696e-01\\n -1.04651064e-01  6.79353962e-01  1.29419616e-01 -3.39464632e-01\\n  5.90610879e-01  4.16072082e-01  1.09558814e+00  1.15172174e+00\\n -9.87423832e-02 -5.01098782e-01 -3.19258837e-01 -7.80132829e-01\\n  3.31843527e-01 -1.00243531e+00  5.48071361e-01  1.21697267e-01\\n  4.74398994e-02 -5.45858874e-01 -1.33877378e-01  4.34619880e-01\\n  1.88750281e+00  1.14800550e-01  2.76820630e-01  3.64000970e-01\\n -4.48522444e-02  1.80989246e-01  3.07955438e-03 -2.37038296e-01\\n  6.21209656e-01 -5.48754675e-01 -2.02268423e-01 -4.73011653e-02\\n -2.29608678e-01 -5.60492973e-01 -5.30465804e-01 -4.49296121e-01\\n -1.16297256e-01 -2.51669809e-01  5.94972485e-01 -4.11495479e-01\\n -3.19674829e-01 -2.67490681e-01 -5.12945944e-01  2.33818009e-01\\n  8.75972437e-01 -6.08420987e-01 -1.76378152e-01  5.51371013e-01\\n -2.30739198e-01 -3.34985700e-01  3.42745218e-01  5.62488119e-02\\n  5.72103527e-01 -1.29670159e+00  6.59749780e-01 -5.66333515e-01\\n -4.57194954e-01  3.45446329e-01 -8.32308412e-02 -3.20337028e-01\\n -6.28450871e-01 -4.04206103e-01  7.96864303e-01 -4.10075030e-01\\n -7.52104621e-01 -7.74523064e-02 -6.45610517e-01 -5.04646811e-01\\n -1.01646016e-01 -3.06690269e-01  2.47078450e-01  8.24074967e-01\\n  1.22669874e-01 -5.32947610e-01 -7.07701905e-01 -2.73326477e-01\\n -3.93336420e-01 -7.61392873e-01  7.44128724e-04  1.53092630e-01\\n  4.10955215e-01  2.64045982e-01  3.49290682e-01 -5.21190976e-01\\n  9.94071667e-02  1.49538699e-01  1.68507036e+00  1.01599372e+00\\n -3.13267945e-01  1.83594516e-01  3.48560781e-01  5.55694981e-01\\n -6.99843003e-01  2.94119587e-01  5.45109850e-01 -4.96103322e-01\\n -3.68984151e-01  3.91813387e-01  2.68305225e-01  6.75748552e-02\\n  5.40011591e-01 -1.92669936e-01 -2.30267882e-01 -1.63876310e-01\\n  5.28286545e-01  5.79962981e-01  6.69204290e-01  4.30643173e-01\\n -3.14811503e-01 -5.51877806e-01  1.63309947e-02 -4.72744052e-02\\n -1.04074547e+00 -1.75224934e-01 -3.66859656e-01  3.65335030e-01\\n  4.68192959e-01 -6.35165230e-01 -4.20533409e-02  4.41385179e-01\\n -3.44105244e-01  1.90902838e-01  6.56821774e-01  1.13123169e-01\\n  1.56879599e-01  5.15136667e-01 -3.74995006e-01 -1.04123900e+00\\n  3.38537043e-01 -6.11314840e-01  3.32560034e-01 -4.48905490e-01\\n -3.39139469e-01 -1.33774056e-01 -3.97707076e-01  6.60391678e-02\\n  4.89607528e-01 -4.73789153e-01 -3.21835850e-01  5.59522142e-02\\n -7.20006593e-01  3.12566588e-02 -7.71185128e-01 -1.29179715e-01\\n  4.42069073e-01 -6.47234770e-02 -7.22073935e-01 -8.14043986e-01\\n -1.52959791e-02 -2.91804517e-01  3.08275739e-01  6.54435104e-01\\n -1.21301796e-01  7.04221581e-01  3.86503393e-01  2.98563035e-01\\n  4.29881061e-01 -4.07642787e-01 -4.49764550e-01 -5.29847010e-01\\n  2.57146749e-01  5.37821873e-01 -5.21150804e-01  8.49992469e-02\\n  2.66762256e-01 -1.91594519e-02 -6.19806008e-01 -7.20926815e-01\\n -2.12386943e-01  9.57793878e-01  2.75047815e-01  5.14741466e-01\\n -3.47253373e-01 -4.64609964e-01 -5.12525157e-01  5.76860931e-01\\n  7.55238586e-01 -1.24424573e-02 -6.72341421e-01  3.94604788e-01\\n  1.21075435e+00  2.98558905e-01 -2.52068442e-01  9.19124260e-01\\n  3.12550745e-01 -8.47514307e-01  6.81613033e-02 -4.41336662e-01\\n  4.37009407e-01  4.65523556e-02  3.10297330e-01 -1.40871338e-01\\n -3.50085634e-01  3.58102447e-02  3.11188395e-01  4.15632520e-01\\n -4.45097917e-01  3.21778380e-01 -1.14418151e+00 -2.04283862e-01\\n  6.10195245e-01  5.66958677e-01 -7.83058469e-01  2.74939532e-01\\n  4.05446827e-02  9.40322678e-01 -3.75761077e-01  3.87818199e-01\\n -5.84399567e-01  6.40369477e-01  5.67963884e-01 -3.58606593e-01\\n -2.68349856e-01  1.24098019e+00 -8.80944085e-01 -2.10405282e-01\\n  3.53550594e-01 -4.79930805e-01 -1.54350601e-01  1.30279323e+00\\n  1.05168885e-01 -3.61862249e-01  5.16905301e-01 -1.50345231e-02\\n  5.98057627e-01 -2.70538853e-01  1.93706068e-01  3.24306115e-01\\n  5.24186887e-01 -6.96458610e-02  1.02681364e+00  3.28220397e-01\\n  5.43917900e-01  2.07231803e-01  1.90634018e-01  7.57848024e-03\\n  3.93105985e-01  2.41228961e-01  5.33135523e-02 -2.14414501e-01\\n -4.74551479e-01  1.03680259e+00  1.35689856e-01 -3.08435363e-01\\n  1.78983567e-01 -1.17757855e-01  2.07610572e-01 -1.89504724e-01\\n  4.18338737e-01 -2.91789391e-01 -5.58760839e-02 -5.67820388e-01\\n  5.62995791e-02 -2.70350660e-02  4.14373273e-01  4.42355352e-01\\n  1.49261781e+00  7.18867448e-02  9.46860987e-01 -1.21149523e-01\\n  5.52964795e-01  1.71873377e-01  4.64890368e-01  2.97234405e-01\\n  6.85347965e-01 -1.90569269e-01 -1.13276647e-01 -4.94531512e-02\\n  4.19539312e-01 -4.64854481e-01  2.76644535e-01  4.68204672e-01\\n -3.21196003e-01  4.26445906e-01 -1.62632099e-01 -2.67511260e-01\\n  4.62436457e-02  5.40983494e-01 -2.98383462e-01  4.38950028e-01\\n -5.81944678e-01 -1.49256239e-01  3.99931115e-01 -1.26181452e+00\\n  5.93758182e-02 -4.09375548e-01 -3.31988921e-02  8.03149669e-01\\n  5.32385853e-01  3.60371982e-01 -2.59126493e-03 -1.26115752e-01\\n -4.58191088e-01  3.14421846e-01  9.05073186e-04 -1.63870742e-02\\n -3.63335744e-01  2.86261545e-01  2.13494249e-01 -3.96682610e-02\\n  8.15167705e-02  3.70567250e-01  7.95966610e-01  2.19524164e-01\\n  3.24370040e-01 -3.92054496e-01  1.08693946e-01  3.15087557e-01\\n  3.35790435e-01  4.61370643e-01  5.18940703e-01  8.24324350e-01\\n -1.62491196e-01  1.22115339e-01  2.07985939e-01  7.16522958e-01\\n -2.84392909e-01  3.68107510e-01 -9.34144344e-02 -5.97320175e-01\\n -3.84114250e-01  1.02225458e-01  5.27168938e-01  6.36912746e-01\\n -5.94873387e-01 -5.87633788e-01  3.69661368e-01 -1.77210889e-01\\n  1.06539909e-01  1.74512411e-01  2.63801016e-01 -6.37983030e-01\\n  1.41787683e+00 -9.62659086e-01  2.42608406e-01 -8.55568580e-02\\n  8.02985231e-02 -5.51327474e-01 -3.75591138e-02 -2.70714780e-02\\n  7.95393026e-01  4.26891924e-01 -6.33122587e-01  3.87174725e-01\\n  6.56269525e-01  2.33344347e-01 -7.48007214e-01  1.17551299e+00\\n  4.32939629e-03  4.04817783e-01  9.01158021e-01 -3.88734915e-01\\n -1.66907189e-01 -4.28884287e-01  4.86189564e-01 -2.11971681e-01\\n  4.88118568e-01 -2.32621433e-01 -2.31470006e-02  3.65867865e-01\\n  1.49216521e-01 -3.66679628e-01 -1.83052096e-01  2.84551187e-01\\n  1.86352948e-01  5.86717543e-02  1.01437112e-01  7.46023905e-02\\n  4.74953910e-01 -1.17743008e-01  6.83647450e-01  2.62364493e-01\\n  6.04644128e-01 -5.76706367e-03  2.41484495e-01 -6.27069935e-01\\n -7.41139443e-01  3.48749712e-02 -4.92859783e-01  4.89354730e-01\\n  2.26527651e-01 -3.72573775e-01 -4.77544097e-02  2.15686851e-01\\n  6.41637546e-02 -2.02718926e-01  2.38307057e-01  2.06737698e-01\\n  4.80277151e-01  4.35905706e-01  7.86870682e-02 -3.96420105e-01\\n  3.93949886e-01  3.39221134e-01  1.95549349e-01  3.17362592e-01\\n -4.98643943e-01  8.09750316e-01 -1.04477664e-01  5.52955276e-02\\n  4.74600091e-01  9.65673029e-03 -1.68662387e-01 -6.95666813e-01\\n -2.65146297e-01  3.49091468e-01 -4.05893388e-01  4.97862828e-01\\n  5.98126088e-01  4.97311101e-02  4.75820462e-01 -5.28088858e-02\\n -7.52059991e-01  4.23390937e-01  1.03811810e-01 -5.40073150e-01\\n -4.50509883e-01  6.89405521e-01  5.33050457e-01 -5.50043411e-01\\n -1.57014245e-01 -1.89920708e-01  1.38491261e-01  2.66535799e-01\\n -1.74890839e-01 -2.51803885e-01  1.76957695e-01 -3.61685407e-01\\n  9.83185507e-02 -9.97247811e-01  3.83876313e-01  4.40599174e-01\\n  6.09397185e-01  5.82956070e-01 -1.08119693e-01 -2.86942649e-01]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"cluster\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 7,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          6,\n          2,\n          7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: drop column cluster user_features\n",
        "\n",
        "user_features = user_features.drop(columns=['cluster'])"
      ],
      "metadata": {
        "id": "i0ZTMKtplYdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(user_features.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "16-FnlFLE7zs",
        "outputId": "347eb3b4-febf-45d2-cf87-3d1403b0baf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  user_id                                      user_features\n",
              "0    U100  [-2.95864147e-01  3.26706147e-01 -4.03406552e-...\n",
              "1   U1000  [-1.44724359e-01 -2.47801140e-01  4.43223372e-...\n",
              "2  U10001  [ 1.03209651e-01  5.61017826e-02 -1.79264177e-...\n",
              "3  U10003  [-0.14111723  0.05412868 -0.23357573  0.089376...\n",
              "4  U10008  [-1.68924790e-01  1.38362664e-01 -5.09465554e-..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-209be881-8fcf-4240-960a-f12a0b9947d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>user_features</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>U100</td>\n",
              "      <td>[-2.95864147e-01  3.26706147e-01 -4.03406552e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>U1000</td>\n",
              "      <td>[-1.44724359e-01 -2.47801140e-01  4.43223372e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>U10001</td>\n",
              "      <td>[ 1.03209651e-01  5.61017826e-02 -1.79264177e-...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>U10003</td>\n",
              "      <td>[-0.14111723  0.05412868 -0.23357573  0.089376...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>U10008</td>\n",
              "      <td>[-1.68924790e-01  1.38362664e-01 -5.09465554e-...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-209be881-8fcf-4240-960a-f12a0b9947d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-209be881-8fcf-4240-960a-f12a0b9947d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-209be881-8fcf-4240-960a-f12a0b9947d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-3f7662b1-31a7-4fc3-b972-d19ca8e80edf\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f7662b1-31a7-4fc3-b972-d19ca8e80edf')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-3f7662b1-31a7-4fc3-b972-d19ca8e80edf button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"(user_features\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"U1000\",\n          \"U10008\",\n          \"U10001\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_features\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"[-1.44724359e-01 -2.47801140e-01  4.43223372e-01  9.02305844e-01\\n -5.52584529e-01  2.96707769e-01 -2.57632290e-01  2.99186364e-01\\n -6.93131695e-01  5.48656126e-01  6.10910685e-01 -1.68814262e-01\\n  2.74759003e-01 -3.72197441e-01  3.94753724e-01  9.59629933e-01\\n  1.72399128e-01 -4.19439015e-01  1.30333930e+00 -1.18846446e-01\\n -2.77210889e-01  7.10741679e-03 -4.95748132e-01  9.18521372e-01\\n  3.70428339e-01 -1.49492592e-01  4.46704328e-02  5.18772801e-02\\n  2.25055029e-01  1.10980844e+00 -2.12926269e-01 -1.71472083e-01\\n -4.33343523e-01 -1.86818356e-01 -5.45685490e-03 -2.41381238e-01\\n  6.27319376e-01  3.63636593e-01 -9.01628604e-01 -9.15256590e-02\\n -7.50440309e-01  4.21059787e-01 -6.54242595e-01  5.11666874e-01\\n  1.92297975e-01 -2.42850304e-01 -3.89878571e-01  1.01175189e-01\\n  3.08232029e-01  5.18765802e-01  1.29901635e-01  6.36467328e-01\\n -5.92617313e-01 -4.33393280e-01 -3.48744165e-01 -2.98071772e-01\\n -6.84237021e-02  4.07317032e-01  7.98698018e-02  7.94084415e-01\\n  7.10509549e-01 -5.71233501e-01 -5.25851607e-01 -1.81020535e-01\\n -4.21885396e-01 -8.30906828e-02 -8.08378160e-02  4.09337924e-01\\n -7.95854479e-02 -3.61612486e-01  2.98755515e-01 -5.65018207e-01\\n -1.11759156e-01 -8.81355405e-02 -1.24518404e+00 -1.82875806e-01\\n -1.25236930e-01 -3.59492447e-01 -9.34165120e-02 -6.71465213e-01\\n -2.80119419e-01 -6.15992645e-01  1.29634758e-01  3.76204252e-02\\n -7.37864584e-01  1.40304297e-01 -1.65294210e-01  1.24234080e-01\\n -3.17615330e-01  6.62968983e-01  6.86080158e-01  2.92946557e-01\\n  3.52136828e-02 -4.45934137e-01  3.10549655e-01 -6.95651571e-01\\n  4.13639493e-01  1.05377108e-01  3.30837334e-01 -4.21647593e-01\\n  2.47980840e-01  5.28196644e-01 -3.79859204e-01 -3.48619279e-01\\n -1.46739864e-01 -2.07734699e-01  7.27169598e-01 -1.54029171e-01\\n  2.83365856e-01  1.26023799e-01  6.20097597e-01  1.47661249e-01\\n  5.61984469e-01  9.82404525e-02 -6.42311980e-01 -9.36780413e-01\\n  1.79831296e-01  2.27908125e-01 -2.55971514e-01 -1.78602844e-01\\n  1.93420748e-01  2.76880960e-01  3.05013885e-01 -2.91880481e-01\\n  2.66226858e-01 -1.22866356e+00 -3.39700873e-01 -2.99043369e-01\\n  6.91966092e-03 -5.65452099e-01 -5.23979823e-01 -3.58261804e-01\\n  1.20358360e+00  8.61559232e-01  5.54283222e-01 -1.83255275e-02\\n  3.72999092e-01 -1.97470888e-01 -2.19874213e-01 -1.66297098e-01\\n  3.07336691e-01  7.70777067e-01  4.20856764e-01  9.17805719e-02\\n -9.58502231e-02 -3.87999415e-01  2.17559273e-01 -3.73052806e-01\\n -4.01869728e-01  7.79638290e-01  1.87777971e-01  2.06136306e-02\\n -1.08647058e-01 -2.58233994e-01 -1.05139546e+00  1.80776907e-01\\n  1.61830962e-01  4.56270168e-01  1.51795324e-01  1.11763349e+00\\n  2.45487707e-01  5.97945203e-01  9.53578949e-01 -6.17843893e-01\\n  3.48224397e-01 -5.59218327e-01  1.70550048e-01  6.65047646e-01\\n  2.96679000e-01  7.78256128e-01 -2.97763320e-01  3.54200284e-01\\n -9.15424476e-02 -1.70334041e-01  3.17982282e-01 -1.86787532e-01\\n -5.34840375e-01 -7.46637106e-01 -3.93534819e-01 -2.46437478e-01\\n -2.88312825e-01 -2.58845704e-01 -4.76900121e-01 -3.39658653e-01\\n  8.90027901e-01 -2.98183116e-01 -1.34497032e-01  3.10280278e-01\\n  4.03915084e-01 -1.35908594e+00 -4.89281481e-01  1.56492752e-01\\n  2.87774517e-01  3.59927495e-01 -9.11661009e-01 -2.02770546e-01\\n  1.89002375e-01  5.40619344e-02  4.87120022e-01 -4.88768555e-02\\n -5.02647062e-02  4.77439413e-02 -2.64153518e-01 -8.87576590e-02\\n  5.95700701e-01 -1.80710278e-01 -4.16305383e-01 -5.10740342e-03\\n -2.45475130e-02  1.08692545e-01  1.50044007e-01 -1.14355783e-01\\n -1.22317721e-02 -4.26051319e-02  7.30689471e-01 -5.48921997e-01\\n -1.70232276e-01  6.17056111e-01  7.39527186e-01  2.80885095e-01\\n -3.65129203e-01  5.17645970e-01 -1.80590852e-01  6.38778269e-01\\n  8.33306164e-02 -3.32458337e-01 -1.59321790e-01  1.23102399e-01\\n  1.04674938e+00 -6.72398292e-01 -4.52279838e-01  7.08655640e-02\\n  2.07424961e-01  1.37865782e-01 -3.63840794e-01  6.89008395e-01\\n -3.03549272e-01 -7.08338122e-01 -3.56610204e-01 -5.01602083e-01\\n -3.27488780e-02  4.87408568e-01 -3.67340863e-01  1.78964252e-01\\n -1.99884633e-01  1.13096305e+00  3.62157583e-01 -1.18346527e+00\\n  3.64354690e-01 -1.63361096e-01  4.74167208e-01  8.89364481e-02\\n -2.45647371e-01 -8.12931557e-01  5.58318471e-01  8.19710785e-02\\n -1.66635883e-01  3.18252350e-01 -9.49501892e-01 -5.84226107e-01\\n  7.91358600e-02 -5.44184645e-01  3.02050670e-01 -2.43681222e-01\\n  2.96929340e-01  2.82453697e-01  6.24556194e-02  1.51220682e-01\\n -1.80687996e-01  3.14233743e-01  5.16008469e-01  8.08614343e-01\\n  6.16118630e-01  1.17151908e+00 -1.20820642e-01 -2.57010251e-01\\n -6.20424946e-01  8.13265885e-01  1.99479918e-01  3.41269273e-01\\n  5.17682216e-01  2.45500589e-01  7.36205137e-02 -1.25668728e+00\\n -1.02769248e+00 -5.13830781e-03 -4.21427409e-01  2.86782324e-01\\n -2.46622192e-01  4.75429595e-01  1.90241777e-01  3.75277325e-01\\n  6.96052506e-02 -6.58730606e-01  5.15223065e-02 -5.88909388e-02\\n  4.09934620e-02  5.86964215e-02 -5.64601486e-01  4.05259093e-01\\n  8.92239332e-01 -2.40913918e-01 -1.09179549e+00  1.99247375e-02\\n  4.01650737e-01  2.98957864e-01  2.83696045e-01  3.38757137e-02\\n -4.77771193e-01 -1.99366093e-01  3.23252380e-01 -3.20516234e-01\\n  1.76065231e-01 -8.50603948e-01  5.76890960e-01  3.10745166e-01\\n  6.17058625e-02 -3.71157974e-01  1.67430490e-01 -5.56387365e-01\\n  3.88433958e-02  5.47758540e-02  2.11426991e-01 -8.56648261e-02\\n -4.28441132e-01  2.77817825e-01  5.45576110e-01  3.10903192e-01\\n -3.59141310e-01  1.00126932e-01 -5.59955796e-01  6.21287191e-01\\n  9.15075004e-01  3.39063565e-01 -1.06511335e-01  5.03954033e-01\\n -1.21011535e-02 -4.20403828e-01 -1.00257012e-01  3.31750697e-01\\n  3.32213819e-01  5.76329196e-01 -7.77995030e-01 -2.25394140e-01\\n -5.08957346e-01 -3.66119325e-01 -1.54771209e-02 -2.91426388e-01\\n  3.68184509e-02  3.06680918e-01 -1.28474007e-01  2.16101090e-01\\n -2.34288712e-01  2.22025235e-01  2.18069961e-01 -4.86761520e-01\\n  9.44116632e-01  6.83546593e-01  4.43133563e-02  6.01009861e-01\\n  8.31129154e-02 -4.96828735e-01  8.20800662e-04  3.91419480e-01\\n -4.60083336e-01  4.78023981e-01  3.84897391e-01 -4.05003458e-01\\n  6.02790932e-01 -7.13785907e-01  5.38428913e-01  6.28650824e-01\\n  8.37902953e-01 -3.17066868e-01 -1.86144814e-01  5.70959012e-01\\n  3.80221921e-01  4.37246710e-01  1.20022097e+00  1.13106730e+00\\n  4.09997508e-01  1.96514751e-01 -1.08595223e-02 -5.00787144e-01\\n -4.10462817e-01  3.12954187e-03  8.21369032e-01  9.13070043e-02\\n  9.35718815e-01 -1.18501728e-01  6.86593950e-01  2.48605291e-01\\n -4.79533213e-02 -6.12545460e-02 -4.25200542e-01  2.20371395e-01\\n  4.53108569e-01 -1.99323008e-01  7.23961753e-01  7.65452087e-01\\n  1.09545185e+00  2.62306770e-01 -5.02495229e-01  1.84953359e-01\\n  8.74033014e-01  7.00825453e-01 -2.01053401e-01  6.59931699e-03\\n -3.73117596e-01 -6.82147930e-01  2.79868171e-02 -2.17174162e-01\\n -2.07729574e-01  4.89671126e-01 -3.72516458e-01 -5.46474030e-01\\n  6.96561918e-01 -4.82057416e-01  1.23933112e-01 -2.26309280e-01\\n -1.47017136e-01  8.44947880e-01 -3.16485974e-01  6.39111772e-02\\n  1.20750038e+00  4.85407829e-01 -3.39372655e-01 -1.72464957e-01\\n -1.84911831e-01  2.92612607e-01  7.62212535e-01  3.61911149e-01\\n  6.82288955e-01  4.12944748e-01  1.14371984e+00  5.36164572e-01\\n  2.31092088e-01 -3.52719848e-01  2.17186311e-01 -4.65906143e-01\\n  6.66104396e-01  2.63354989e-02  5.88755101e-01 -8.92180314e-01\\n  6.61518375e-02 -1.20084137e-01  4.08734222e-01  8.62994174e-01\\n  5.07301807e-01  5.83453923e-01  4.87631967e-01  4.04200502e-01\\n -4.25547838e-01 -1.67251912e+00  6.68906748e-01  6.44501408e-01\\n -3.74294420e-01  3.00912321e-01  1.70595179e-01 -1.83947238e-01\\n -3.32318698e-01  3.31310252e-01 -1.42215768e-01 -2.29308565e-01\\n -8.26319059e-03  2.57243972e-01 -3.17891416e-01  1.26524043e+00\\n -2.15569566e-01 -4.64131435e-01 -3.32065364e-01 -1.69260323e-01\\n  1.38848447e-01  2.45120982e-01 -3.14355145e-03 -3.21804906e-02\\n -5.95698049e-01  5.15908023e-01 -3.39028715e-01 -4.89633029e-01\\n -5.05717125e-01  3.02832752e-01 -1.64957777e-01 -1.77575002e-01\\n  3.95046393e-01  2.33349130e-01 -1.19290221e+00  4.98457164e-01\\n -1.54876242e-01  1.83654149e-01 -2.01202162e-01 -8.32282980e-01\\n -3.55919600e-01 -1.23743763e-02 -5.24380565e-01  1.14801288e-01\\n -9.06204124e-01 -9.48461076e-01 -2.44500319e-01 -8.15626234e-03\\n  2.33456939e-01  4.85076865e-01 -7.48932590e-01 -5.45227664e-01\\n  4.79280328e-01 -5.54804961e-01 -2.03149679e-01 -3.81876528e-02\\n  1.24517481e-02 -1.54439380e-01 -2.92839249e-01  1.63963505e+00\\n  8.44728306e-01  3.85700576e-01 -1.15346710e-01  7.18427966e-01\\n  9.48504637e-01 -4.45949952e-01  2.33963872e-01 -1.47930776e-01\\n -5.96384366e-01  6.86565797e-01 -5.06622123e-01 -5.33466448e-01\\n  1.73276914e-01  1.23740941e-01  9.73108908e-02  7.30109115e-02\\n  3.75795906e-01 -1.81091885e-01  1.72095865e-01 -2.82088336e-01\\n  5.76548380e-01 -3.52981187e-01 -4.79559172e-02 -1.05426388e-01\\n  1.14054744e-01  4.15526489e-01  4.61807092e-01  1.02338936e+00\\n  1.14240201e+00  2.09059536e-01 -1.07594113e-01 -2.94547339e-01\\n -2.56121914e-01  2.07789396e-01 -3.06107322e-01  3.30866168e-01\\n -1.01269652e-01  7.12795367e-01 -2.24922995e-02  7.22598751e-01\\n -3.37336063e-01  1.93352858e-01 -7.82031417e-02 -2.39348964e-01\\n  5.21271798e-01 -2.69832959e-02 -2.58441597e-01 -3.84907782e-01\\n -4.11637311e-01  6.61468526e-01  5.24782793e-02  3.51913333e-01\\n -2.59688874e-01  4.58710760e-01  4.85310833e-01  9.37245339e-02\\n -5.91123720e-01 -6.93642795e-02 -6.47582104e-01  7.01563348e-01\\n  9.18030292e-02  1.63215152e+00 -8.78374398e-01 -6.13892823e-02\\n -2.89892557e-01 -6.16919259e-01  2.92813202e-01 -4.26312397e-01\\n  5.88137895e-01  6.45716925e-01 -1.30326784e+00 -1.37566896e+00\\n -1.09570734e-01  2.51349399e-01  9.80222325e-02  1.27375176e-01\\n  1.48987062e+00  8.74028474e-01 -1.76338842e-01  4.05211389e-01\\n  4.11846814e-01 -5.50088843e-01 -1.32714413e-01  2.33811928e-01\\n  7.91420639e-01  7.13176072e-01 -8.87137776e-02  1.18107200e-02\\n  3.47302953e-02  2.10225170e-01 -2.18273858e-01  5.11865377e-01\\n  3.64517219e-01  4.21742896e-01  4.83362039e-01 -3.81983627e-01\\n -1.04754555e+00  5.23887545e-02 -1.85647686e-01  7.51296004e-01\\n -9.11557058e-01  5.22788664e-01  1.01594046e-01 -9.54516691e-02\\n -7.58425766e-01  4.30226788e-01 -3.18324745e-01 -2.96824733e-01\\n  5.40048266e-01  2.27342188e-01  5.35622021e-01  2.00159661e-01\\n  7.34419271e-01 -3.75535885e-02 -2.24327614e-01  7.54439006e-01\\n -2.99058850e-01 -9.57760660e-01 -5.17979900e-01 -1.27519667e-01\\n  2.22506652e-01 -5.62758495e-01  1.11018022e-02 -8.69930387e-02\\n  2.70836572e-01  5.73233515e-01 -6.31641376e-02 -1.30572657e-01\\n -6.59486358e-01 -3.00516685e-01  3.35393177e-01  2.17061266e-02\\n  5.51080704e-02  3.68495941e-01 -3.80124559e-01  3.83686269e-01\\n  4.34126357e-02  1.11231810e+00 -8.83764712e-02  1.59395142e+00\\n -4.16886757e-01  5.67389548e-01  4.43355580e-01  8.63851964e-01\\n  1.04789388e+00 -1.20607267e-01  2.03709662e-01  1.09147058e+00\\n -1.96514726e-01  1.94531312e-01  1.07158901e+00  3.00890586e-02\\n -4.49850162e-03 -2.15100686e-01  1.29131731e-02  4.38387970e-01\\n -2.36646925e-01  8.50745315e-02  6.37663802e-02  4.90205521e-01\\n -5.96874952e-03 -5.87343956e-01  2.46475498e-01  2.23832155e-01\\n  3.47544059e-01 -2.61267836e-01 -1.95691695e-01  9.01341677e-01\\n  1.20344480e-01 -1.42830441e-01  7.36610542e-01 -6.12239619e-01\\n -4.79550328e-01 -6.28704776e-01 -9.74171956e-01  1.30132720e-01\\n -5.00261962e-01  6.96291526e-03  1.81782166e-01  4.18893596e-02\\n -6.46937658e-01 -9.91666118e-02  3.69161944e-01 -4.19284473e-01\\n -1.27777378e-01  1.70803407e-01  3.50021397e-01  1.89159562e-03\\n -9.44346339e-02  2.96542831e-02 -3.01355297e-01  3.39020987e-02\\n  4.11959171e-01 -7.90158461e-01  5.21485706e-02 -4.43098605e-01\\n  2.87753214e-01  2.38427202e-01 -2.09152435e-01  6.47825956e-01\\n -2.40977888e-01 -1.57462801e-01  4.24147993e-01 -7.73479740e-02\\n -6.74263239e-01  5.21242688e-01  3.28215698e-01 -2.87415246e-01\\n -1.61826645e-01  2.25165536e-01  3.23325319e-01  6.58879598e-01\\n -1.94337557e-01  1.65696152e-01  2.67021631e-01  5.58464363e-01\\n -3.39293381e-01 -1.28788421e-01 -2.20310291e-01 -4.68174626e-01\\n  3.33221450e-01 -3.19462309e-01  2.58921723e-01 -6.97990417e-01\\n -6.23643994e-01  1.19990011e-02 -4.99120981e-01 -2.25557158e-01\\n -5.02905011e-01  3.83436754e-01  5.49888223e-01  5.00953471e-02\\n -3.40120092e-01  4.32600001e-01  1.61848615e-01 -5.29980540e-01\\n  2.19750777e-03 -4.04964448e-01  1.03881671e+00  3.17266534e-01\\n  2.34106916e-01 -6.84383929e-01  2.58096139e-01  9.42942128e-03\\n  2.23782221e-01  1.57058204e-01 -6.67544603e-02 -3.20946376e-01\\n  9.60013012e-01 -6.63551042e-02  3.89221301e-01  1.64106473e-01\\n  5.66208502e-01 -8.36886138e-01 -3.58091120e-01 -7.77786622e-01]\",\n          \"[-1.68924790e-01  1.38362664e-01 -5.09465554e-01  1.02586479e-01\\n  1.16658584e+00  8.22645907e-01 -1.80581893e-01 -2.43267740e-01\\n -2.07901808e-01 -5.54319453e-01  2.69940741e-01 -8.19272952e-01\\n  2.33407506e-01 -1.06925012e-01 -3.35551079e-01 -4.22187863e-01\\n  2.08530825e-03  8.67354878e-02  1.07791338e-01  1.36223491e-01\\n -5.10751126e-01  1.48959413e-01 -5.81229643e-02  1.18541970e-01\\n  2.67765350e-01  4.49547496e-02 -3.63228875e-01 -8.42939271e-01\\n -4.85318451e-01 -4.43529884e-01 -4.91173878e-01  3.47536798e-01\\n  4.81337765e-01 -5.15022030e-01 -2.57894140e-01  3.56133383e-01\\n  7.30323957e-02  1.79827844e-01 -7.95019964e-01  2.66545813e-01\\n -2.10947008e-01  6.09900482e-01  1.34141114e-01 -8.18184548e-01\\n  5.92670072e-01 -6.31947405e-02  2.22491009e-01 -7.27942394e-01\\n -1.20589590e-02 -4.09787346e-02 -2.04914638e-02  4.51484565e-01\\n  1.36004383e-01  1.60333495e-02  3.02261721e-01 -1.17930619e-01\\n  1.21477246e-02 -4.23718461e-01  8.30565907e-01 -2.82270705e-02\\n  6.43678125e-03  2.09724763e-01 -3.80435942e-01  5.45975145e-03\\n  2.55493709e-01 -2.11667797e-01  6.27339275e-03 -1.35170710e-01\\n -1.56962450e-01  2.36458087e-01  1.99056709e-01 -6.54830652e-01\\n  2.33476963e-01 -2.04515526e-01  4.38300373e-01  5.98151658e-03\\n  7.54851841e-01 -1.15634091e+00  3.45200877e-01  4.34004200e-01\\n  5.14149242e-02 -9.85151479e-01  5.66543865e-01 -4.98904227e-01\\n -4.43566978e-03 -5.19769457e-01 -7.99861952e-02 -1.21635840e-01\\n  1.37166095e-01  4.02190398e-01 -2.88794162e-01  6.92674707e-02\\n -8.08843005e-01 -2.61567809e-01  6.39896994e-01 -2.39187796e-01\\n  1.06064204e-01 -1.85447999e-01  4.34093040e-01 -3.50959065e-01\\n  5.85527272e-01  2.95261276e-01 -6.07541067e-01 -1.31820886e+00\\n -4.72062988e-01 -1.59265887e-01  3.16756286e-01  3.13199587e-01\\n -7.42632664e-02  6.97028621e-01  1.00420931e+00  2.77669824e-01\\n  2.66226520e-01 -3.02239519e-01  1.11208050e-01 -5.19423675e-01\\n -4.74852234e-02 -2.58460914e-01  1.46440246e-01 -8.69330181e-02\\n -6.42909166e-01  3.39462388e-01  9.03232552e-01 -1.62346837e-01\\n -5.02233978e-01 -6.51392251e-01  4.68046563e-01 -2.42593636e-01\\n -6.63439637e-01  2.29508511e-01  2.04340283e-02 -1.34231025e+00\\n  3.23692169e-01  1.01882667e-01  1.00068736e-01  3.50775340e-02\\n  6.27881774e-03 -3.51919206e-01  1.30607793e-01  5.98835323e-01\\n -6.92963662e-01  6.45404020e-01 -2.43679136e-02 -3.53576293e-01\\n -1.68526422e-01 -5.41646470e-02 -5.80458977e-01  1.54432422e-01\\n -5.87375014e-01 -1.59540402e-01  5.77995096e-01  4.05033685e-01\\n -7.11468991e-01  2.72699246e-01 -3.72796513e-01  2.79962789e-01\\n  5.08510806e-01  6.54845118e-02 -4.09033560e-01  3.03221196e-02\\n  2.55867355e-01  3.43270194e-01  7.79694228e-02  2.02293262e-01\\n  1.90250536e-01  8.39931036e-02 -3.30372971e-01 -2.45515576e-01\\n -6.06737939e-01  2.83910672e-01 -4.08739078e-01  2.99056459e-01\\n  1.07440273e-01  4.52520280e-01 -5.62327389e-01 -5.33916817e-01\\n  7.07948425e-02 -1.16933319e-02  3.19010430e-01 -2.42521209e-01\\n  2.31351984e-01  2.46207927e-01 -1.38321259e-01 -1.41212739e-01\\n -6.54817279e-01 -5.45825134e-01  2.64636589e-03  2.86144292e-01\\n -6.46102236e-01 -5.50631650e-01  8.99845895e-02 -4.10372023e-01\\n -4.61964236e-01 -3.36098305e-01 -6.86899725e-01  4.21222023e-01\\n -8.00560998e-02 -1.45107512e-01  3.07830983e-01  2.90868481e-01\\n -1.21623083e-01  9.81538399e-02  2.97226294e-01 -6.74832606e-01\\n -5.27254295e-01  1.11828660e-02 -4.39899687e-01 -2.75515668e-01\\n -6.71034871e-02  5.65039315e-01  3.49585066e-01 -6.67082064e-01\\n  6.15507986e-01  1.75534658e-01  2.02427306e-01 -2.61636739e-01\\n  3.47649089e-01 -1.26423231e-02  5.27736719e-01  1.57164010e-01\\n  3.93852709e-01  4.81681278e-01 -9.22761083e-01  2.70805408e-01\\n  5.37762288e-01  1.37674433e-01 -4.95527978e-01  5.79756959e-01\\n  3.36979455e-01 -3.27865340e-01  1.19566932e-01  2.96204328e-01\\n  9.21823486e-02 -3.33206803e-02  1.13931182e-01  1.57970138e-01\\n -4.39920607e-01 -4.94228456e-01 -3.67042242e-02 -4.37397460e-01\\n  5.10452758e-01  7.35993245e-01 -1.46703687e-01 -1.47961972e-01\\n -3.30292335e-01  3.25009676e-01 -2.06853355e-01 -1.95919775e-01\\n -5.53989229e-02 -3.45839821e-01 -7.27907600e-02 -2.07162808e-01\\n -5.73140264e-01 -8.66023065e-01  5.64427938e-01  9.62598926e-01\\n -2.05443932e-01 -6.77952509e-01 -2.43257398e-01 -4.67142569e-01\\n -2.70324070e-02  2.62604058e-01 -3.19650419e-01 -2.26443533e-02\\n  6.83880302e-01 -4.84693127e-01 -4.12301922e-01 -1.94348685e-01\\n  1.67803371e-01 -6.39695087e-01 -4.62795694e-01 -4.53913158e-02\\n  8.90557047e-04  2.19651464e-01  8.31955665e-01 -1.92926758e-01\\n  6.00147057e-01  1.07479735e+00  9.14860660e-01 -5.05317067e-01\\n  4.67028201e-01  7.13305323e-02  1.17602023e+00  6.52028598e-02\\n  2.67773490e-01 -1.34506207e-01  3.91093632e-01  5.31929911e-01\\n  3.36674995e-01  4.74610997e-01  4.48572221e-01  5.57623052e-01\\n  3.10237314e-01  9.19954343e-02 -4.42123347e-01 -2.47877151e-01\\n  2.62539986e-02  5.82689858e-01 -3.45108868e-01  1.15998809e-01\\n  9.42945105e-02  9.38806642e-02 -8.64568813e-01  9.64955295e-02\\n -9.71259493e-02 -3.46220476e-01 -4.38084315e-01 -1.23741717e-01\\n  6.96039356e-01  9.83162218e-01 -6.05728584e-01 -1.34407246e-01\\n -3.44568383e-01 -7.99054263e-02  5.87849951e-01  1.70979687e-01\\n -4.64967322e-01 -5.32225442e-01 -6.99679945e-02 -2.71925188e-03\\n  6.03764342e-02 -1.23950320e-01 -5.33667331e-01  3.30511282e-01\\n -1.90032843e-01 -2.70269505e-01  3.21761576e-01  3.64643833e-01\\n  9.03038238e-02  4.03136559e-01  2.87779835e-01  3.57410205e-02\\n  3.27213402e-01  3.43628544e-01  2.57153296e-02  2.11426005e-01\\n  2.13124829e-01  7.34150276e-01  2.00839746e-01  5.61465354e-01\\n -1.28166569e-01 -1.61745546e-01 -2.06044232e-01  1.71660207e-01\\n  2.11632708e-01 -3.83650909e-01 -2.50588292e-01  6.28722748e-02\\n -2.75297144e-01  6.70846724e-01 -4.44351972e-02  8.77729447e-03\\n  7.96877634e-01 -3.44656202e-01  7.35598006e-01  2.53352499e-01\\n  3.92820554e-01  6.04343975e-01 -4.40607167e-01 -2.09091609e-01\\n  5.75150211e-01 -6.45929723e-01  2.17739142e-01  5.01489214e-02\\n  6.85905698e-02  8.81637056e-01  8.53261433e-02  5.26233323e-01\\n -2.98996731e-01 -3.01536170e-01  4.62144683e-01  3.35348420e-01\\n -8.66387366e-02  1.16124232e-01 -4.78731218e-01  1.01662455e-01\\n  1.09834115e+00 -1.80030224e-01  6.22680465e-01  2.09338173e-01\\n -3.07623165e-02  1.91801472e-01  1.34025502e-01 -2.56113116e-01\\n -2.38790056e-01 -4.03146303e-01  3.69349126e-01  1.95187810e-01\\n  2.74114325e-01 -2.54237651e-03  4.58603745e-01 -2.48344525e-01\\n -4.41833717e-01  2.32311063e-01  7.25136475e-01  6.49151509e-01\\n -5.91146599e-01 -2.23442929e-01 -7.32344399e-01 -4.55006130e-02\\n -1.40505859e-01  9.57996592e-02 -3.21181640e-01 -1.87832786e-01\\n  2.26674159e-01  9.10649563e-01 -4.05075675e-01 -1.62652173e-01\\n  4.15436070e-02 -6.37665338e-01  8.16949936e-01 -1.35269373e-01\\n  3.37601610e-01 -6.46355492e-02  4.55712917e-02 -4.97420398e-01\\n  6.99076650e-01  3.35681605e-01  8.62593322e-01 -9.58764730e-02\\n  5.73219034e-01  1.98821559e-01 -1.61981675e-01  8.84393898e-02\\n  2.84955399e-01  2.72627183e-03  3.25218703e-01 -2.97383815e-02\\n -3.94210971e-02 -2.90080876e-01  6.56450639e-01 -1.18104261e-01\\n  9.59875466e-01  3.10745305e-01 -1.50249483e-01  1.03193227e-01\\n  2.19205478e-01 -2.91383593e-01  1.01837965e-01 -5.25036283e-01\\n  2.19620243e-01  5.11053181e-01  9.28703537e-01  1.15368484e-01\\n -1.45657563e-01  2.44370792e-01 -4.28453502e-01  5.20643932e-01\\n  1.93902079e-01  2.39599884e-01 -1.49463912e-01  7.68263175e-01\\n  2.39699680e-01  5.73685409e-02  5.72545497e-01  4.05031936e-01\\n -1.91153509e-01  5.86303273e-02 -1.11411301e-01 -8.52278214e-01\\n  1.98767364e-01 -1.91432052e-01 -2.51736075e-01 -5.24197070e-01\\n -2.94102741e-01 -1.29896092e-01 -6.07861241e-01  1.15387274e-01\\n -4.29377516e-01 -5.06085799e-02  1.98136172e-01 -2.64787837e-01\\n -3.96258604e-01 -1.81215349e-01  5.63349931e-03 -4.00051812e-01\\n  6.01817049e-01 -2.93855011e-01  2.45172202e-02 -2.30696467e-01\\n -2.14314901e-02  1.83549161e-01 -2.58010814e-01 -3.67182282e-02\\n -5.42023416e-02  6.15415359e-01 -6.56509672e-01 -1.12823885e-02\\n  3.15434593e-01 -2.58968186e-01 -4.24285271e-01 -2.24199089e-01\\n  4.07257795e-01  8.96229113e-01 -5.36076459e-01  3.43766465e-01\\n -1.01249958e+00  1.57202050e-01 -5.50930586e-02 -7.91215748e-01\\n  4.52396431e-01  4.91182697e-01 -1.49811871e-01 -1.19192078e-01\\n  1.24030221e-01 -1.29715444e-01 -6.95313221e-02  2.62559364e-01\\n  2.23185145e-01 -1.63414440e-01 -1.52308048e-01  1.07444777e+00\\n  4.67172705e-01  2.35271096e-01  5.32481240e-02  3.66446951e-01\\n  5.90794264e-01 -6.46239956e-01  3.12480062e-01 -6.76011691e-01\\n  6.63688826e-01 -3.58056921e-01  1.89716174e-01  1.56439617e-01\\n  5.00253693e-02  5.91405001e-02  6.60797210e-01 -3.63685800e-01\\n  1.07636573e-01 -2.60689373e-01 -3.31373565e-01 -3.68056412e-01\\n -4.92435292e-02  1.01395810e-02  1.57823652e-01  4.15592314e-01\\n  3.13105016e-02  4.37507876e-01  9.99148565e-02  1.41611628e+00\\n  5.12289698e-01  3.77661029e-01  2.00671834e-01  5.30459531e-02\\n  4.90534999e-01 -7.15970353e-02  1.09019327e-01 -4.85265704e-01\\n  2.11395321e-01 -3.49882755e-01 -2.62958085e-01  2.00940511e+00\\n  2.62527162e-01 -1.99499972e-01  8.65489845e-02 -1.96690038e-01\\n  1.76759447e-01  3.09986904e-01  1.60952484e-01  5.80905303e-02\\n  6.81309897e-01  7.47903986e-01  3.86127155e-01  6.16323934e-01\\n -5.80121100e-01  2.14632885e-01  3.80175341e-01 -4.33966010e-02\\n -5.46483988e-01  5.17305433e-01  5.07421370e-01 -2.05708444e-01\\n -5.15641679e-01  3.60991463e-02  7.23670142e-01 -2.66160621e-01\\n  1.98315008e-01 -8.24464531e-02  2.63490985e-01 -1.08386055e-01\\n  1.63858059e-01 -4.50575850e-01 -4.51499323e-01 -3.97536923e-01\\n  1.82104504e-01 -9.00959828e-02 -1.01527245e+00 -2.56099567e-01\\n  1.70562175e+00  7.39646003e-01  4.07803664e-01  6.48105685e-01\\n  3.00248148e-01 -3.26238216e-01  3.18142025e-02 -7.75700404e-01\\n  4.61524166e-01  1.81347171e-01 -2.43081081e-02 -2.85960757e-01\\n -4.96825886e-01  2.54509228e-01  6.63814988e-02  4.18752491e-01\\n  1.13783147e-01  3.24727195e-01 -1.33724036e-01  1.53813923e-01\\n  3.93804292e-01 -8.06726433e-01 -5.01717762e-01  1.01674245e+00\\n -8.97716986e-01  5.35285768e-02  2.12535381e-01 -2.78028799e-01\\n  8.80367848e-02  2.40463606e-01 -2.96061215e-01  4.14204743e-01\\n -8.23399836e-02  1.88711510e-01 -5.14232254e-02 -3.77598069e-01\\n  1.49021324e-02  4.61523432e-01  1.72758280e-01  4.80126842e-01\\n  2.15929069e-01 -6.16321843e-01 -3.22045930e-01  6.40056162e-01\\n  7.58355380e-01  3.04249601e-01 -1.80839477e-01  5.81234259e-01\\n  8.46813065e-01  1.86629455e-01  2.94835822e-01  2.85048946e-02\\n  2.27646795e-01  8.26102386e-02  6.97558787e-01  2.85113189e-01\\n  1.12354472e-02  3.87155273e-02 -2.21183762e-01  5.23099305e-01\\n -4.02623117e-02  2.35646226e-01  3.45663932e-01  8.68888316e-01\\n -5.34058730e-01 -1.42235492e-02 -2.36579201e-01  6.37996016e-01\\n -1.06585205e-01 -3.73645597e-01  8.07945973e-02  3.53171029e-01\\n -1.14571409e-01  4.28883971e-01  3.51026855e-02  5.39869321e-01\\n  2.61245158e-01  1.64839604e-01 -2.19129692e-02 -6.95485166e-02\\n  4.42530488e-01 -1.36002791e-02 -7.90850027e-01  1.91858456e-01\\n  6.89306854e-01 -3.67292154e-02 -1.21654537e-01  2.84832847e-01\\n  2.10631444e-01 -5.72557870e-01  5.64914501e-02  6.82850362e-01\\n -3.61026257e-01  4.97355832e-01  1.01732822e+00  1.80186287e-02\\n -2.42127065e-01 -1.77345108e-01 -2.54821951e-02  1.60496511e-01\\n  6.73990358e-01 -7.60574185e-03 -2.81357796e-02  1.88811996e-01\\n -2.45007695e-01  6.06262001e-01 -5.31433802e-01 -6.83011084e-01\\n  7.25538949e-01  2.94051339e-01 -4.63092153e-01  2.05094421e-01\\n  5.17230146e-01 -2.32596472e-01  4.63322383e-01  3.08491127e-01\\n  4.29678614e-01 -5.57684451e-02  1.34775469e-01 -1.89360446e-01\\n  1.07907224e-02  2.32883239e-02 -5.54633230e-01  7.21813967e-01\\n  1.72797259e-01 -1.50120342e-01  2.32786151e-01  4.37408757e-01\\n  8.59528865e-02  8.45312084e-01  5.18695500e-01 -7.61276911e-01\\n  6.50098674e-01 -8.66753838e-02 -5.56733819e-02 -2.41736645e-02\\n -1.13948286e-01  5.18085564e-01  2.05952861e-01  1.22412353e-01\\n  8.81536391e-02  2.49135646e-01  2.67796292e-01 -3.07821404e-01\\n -2.80893347e-01  9.41181748e-01 -1.28195201e-01 -4.86513901e-02\\n  5.13404878e-01 -1.77656165e-01 -4.03104766e-01 -2.03864642e-01\\n -4.84932018e-01  1.41989445e-01  6.63528698e-01 -1.17254518e-01\\n  5.28960400e-03  1.93479872e-01 -2.47429760e-02 -1.60845948e-01\\n  3.84368446e-02 -1.65595993e-01 -4.04975714e-01 -3.40662288e-01\\n -7.21535418e-01 -2.27459614e-02 -1.78212349e-01 -2.25766289e-01\\n  1.55975488e-02  2.58335630e-01  1.49877790e-01 -2.76590191e-01\\n  7.38610897e-01 -5.68870763e-01  4.83486540e-01  1.49882994e-01\\n  5.77820291e-01 -9.78557443e-01 -4.42948487e-02 -2.04322663e-01]\",\n          \"[ 1.03209651e-01  5.61017826e-02 -1.79264177e-01 -3.98016031e-02\\n  2.45890072e-01  2.16156956e-01  2.41573959e-01 -3.40835798e-01\\n  1.23429644e+00  8.25156093e-02  1.24351430e-01 -6.76688065e-01\\n  3.36726520e-01 -6.45427462e-01 -2.50167026e-01  5.53613243e-02\\n -3.85361126e-03 -8.30419681e-01 -4.59100753e-02  6.79805220e-02\\n -1.66200063e-01  8.94631940e-01  6.20162770e-01  9.61388152e-01\\n -7.49491060e-01 -5.54752059e-02  6.28249446e-01 -3.58170519e-01\\n -3.54351054e-01 -7.89469555e-01 -8.51331919e-01 -7.85893421e-01\\n  5.59017372e-01 -7.57143845e-03 -7.28629881e-01 -2.83519447e-01\\n  4.62639134e-01 -1.03570454e-01 -6.84254224e-01 -5.70744096e-02\\n -2.98372146e-01  1.06859834e+00 -6.51704542e-01 -2.96291091e-01\\n  1.14126017e+00  9.46643837e-03  2.61803625e-01 -3.12084393e-01\\n  6.19179427e-01  4.33704982e-01  5.38907284e-01 -7.67032847e-02\\n  6.76404439e-01 -1.22409629e-01  1.36920235e-01 -6.49745784e-01\\n  1.92854079e-01  1.93807941e-01  2.35768982e-01 -3.48019277e-02\\n -9.44292788e-01  4.64897908e-02 -2.28149250e-01 -1.96254463e-01\\n -1.16056335e-01 -3.45255538e-02 -4.24384417e-01 -9.26488322e-01\\n  7.67598332e-01 -2.97824129e-02 -1.98438791e-01 -4.55223753e-01\\n  2.90672002e-01  4.24600568e-01  3.39560915e-01 -6.32613767e-02\\n -1.58778455e-01 -2.55007069e-01  7.78168021e-01  1.78869752e-03\\n -4.11197197e-02 -5.47252336e-01  4.30470744e-01 -4.44061104e-01\\n -5.03424714e-01 -4.77682552e-01 -2.23916890e-01 -6.52896555e-01\\n -8.12968930e-02  4.53260565e-01 -2.19151531e-01  4.22156026e-01\\n -6.93676449e-01 -4.77330595e-02 -5.05490730e-01  6.97691414e-01\\n  2.88755693e-01  7.50017541e-01  1.65276902e-01  1.83341916e-01\\n  1.09433554e+00 -3.22826299e-01 -5.35659562e-02 -2.59616842e-01\\n -1.19223925e-02 -1.02679684e-01  7.25868105e-01  2.83391363e-01\\n -4.38333582e-01  7.83462467e-01 -2.53536699e-01 -3.77685774e-01\\n -1.14691646e-01  2.71985466e-02 -1.25959295e-01 -1.97748436e-01\\n  9.68155738e-02  4.21703424e-01 -2.52895536e-01  1.72538449e-01\\n  2.74942368e-01  1.65421486e-01  2.51112583e-01  4.27152530e-01\\n -7.96271045e-01 -7.66283274e-03  1.40902040e-01 -1.93045560e-01\\n -5.44582700e-01  6.64374264e-01 -9.90372216e-03 -6.61669767e-01\\n  2.49220121e-01  7.00502102e-01 -5.76687161e-01 -4.76197716e-01\\n -5.74885656e-01 -5.97331067e-01  2.06152200e-01  4.94076306e-01\\n -4.68218161e-01  6.32668232e-02 -1.28902618e-01 -8.21164805e-01\\n  1.48306439e+00 -3.44221254e-01  1.37892562e-01 -6.29241731e-01\\n  1.04483177e-01 -1.13249302e-01  3.18343971e-01  4.08678629e-02\\n -4.98370285e-01  1.23809487e-01  6.50372813e-01  7.14199315e-01\\n  7.89113569e-01  1.37308942e+00  8.80549918e-02  2.15671223e-01\\n  7.54267891e-01  2.99665667e-01 -5.87840141e-01  5.82397660e-02\\n -8.46795149e-01 -7.43835060e-01 -8.16289554e-02 -3.56562123e-02\\n -4.11007990e-02  8.89709447e-01  2.16993542e-01  2.59613554e-01\\n -2.31462547e-01  4.11296026e-01 -3.83570756e-01 -1.36541225e-01\\n  4.10627409e-01 -5.78218382e-01 -1.57355369e-01 -3.69624386e-01\\n -1.69749484e-01  3.82866590e-01  4.78133134e-01  3.97547150e-01\\n -3.93096042e-01  4.02351082e-01 -2.63305050e-01  6.60953960e-01\\n  2.95610641e-01 -3.71103605e-02  7.09251838e-01  1.42293221e-01\\n -2.02117777e-01  5.65968965e-01 -5.87720474e-02 -2.17562073e-01\\n -3.98735825e-01  1.47481648e-01  3.05398375e-01  1.13212302e-01\\n  3.56470911e-01  1.17854117e+00 -1.81718382e-01 -2.08582666e-01\\n -2.60646791e-01 -3.88835318e-01 -9.92531870e-03  4.67222210e-01\\n -3.59174848e-01  5.75415986e-01  6.14450320e-01  4.04904484e-01\\n -8.33146185e-02  3.59248283e-01  8.59386857e-01 -5.46646426e-01\\n -4.17294413e-01  5.21518371e-01 -3.29489572e-01  7.97725916e-03\\n  6.03678809e-01  6.68213748e-01  1.79395753e-01 -7.55758961e-02\\n  2.16603688e-01  7.86918024e-01 -1.40540134e-01 -2.34248664e-01\\n  1.01602482e-01 -6.34030964e-01  3.55576362e-01 -7.09599265e-01\\n  1.45371767e-01 -4.07009367e-01  5.62624668e-01 -6.72402009e-01\\n -3.65865243e-01 -4.33728940e-01 -8.86754599e-01  2.02268754e-01\\n  2.42093544e-01  6.52544156e-01  2.30575893e-01  2.22847332e-01\\n -7.91766585e-02 -3.37267367e-01  7.39499308e-02 -4.59071847e-01\\n -6.91965650e-02  2.10912820e-01 -1.13117676e-01 -2.06394300e-01\\n -5.95814101e-01 -4.89413584e-01  7.13801755e-01  1.50151052e+00\\n -7.09606620e-01 -4.17691418e-01  5.97065663e-01  6.80450484e-01\\n  4.91695324e-01  1.59535185e-01  2.49506948e-01  2.89837279e-01\\n -3.81820600e-01 -5.30334374e-01 -1.05168430e+00  3.53668990e-01\\n -2.29716280e-01 -3.18855800e-01 -2.27146457e-02 -2.20736271e-01\\n  6.73319524e-03 -5.10317126e-01  3.86822212e-01 -3.00534619e-01\\n  4.00343351e-01  8.67217255e-01  7.42043875e-02 -7.87070791e-02\\n -9.85937043e-02  5.31595061e-02  4.42863524e-01  1.68204383e-01\\n -4.81779574e-01 -4.74821726e-01  8.55622595e-01  1.88366779e-02\\n -3.07903907e-01 -3.30101565e-02  2.81907254e-01  5.65221792e-01\\n -6.01600921e-01 -1.24035291e-01 -4.62859513e-01 -4.09199760e-01\\n -1.45580054e-01  1.27868302e-01  3.44626103e-02  1.77620892e-01\\n  4.87115172e-01  6.96386298e-01 -7.41849866e-01  4.83876402e-02\\n  4.97500048e-01 -7.04789267e-01 -2.93118568e-01  6.44057504e-01\\n  1.32124802e+00  8.84292533e-01 -2.88001267e-01 -6.56038137e-01\\n -3.70267166e-01  3.22740570e-01  7.07833381e-02 -7.75590733e-01\\n  7.94351617e-01  3.55770489e-01 -1.50942148e-01 -3.24204172e-01\\n -3.31851204e-01 -3.27489373e-01 -1.13567744e-02  1.36861061e-01\\n  4.26826288e-02 -2.78425071e-01  5.46987848e-01  7.91944041e-01\\n  4.78713552e-01  6.50543508e-01  7.72887782e-01 -3.93575696e-01\\n -1.04651064e-01  6.79353962e-01  1.29419616e-01 -3.39464632e-01\\n  5.90610879e-01  4.16072082e-01  1.09558814e+00  1.15172174e+00\\n -9.87423832e-02 -5.01098782e-01 -3.19258837e-01 -7.80132829e-01\\n  3.31843527e-01 -1.00243531e+00  5.48071361e-01  1.21697267e-01\\n  4.74398994e-02 -5.45858874e-01 -1.33877378e-01  4.34619880e-01\\n  1.88750281e+00  1.14800550e-01  2.76820630e-01  3.64000970e-01\\n -4.48522444e-02  1.80989246e-01  3.07955438e-03 -2.37038296e-01\\n  6.21209656e-01 -5.48754675e-01 -2.02268423e-01 -4.73011653e-02\\n -2.29608678e-01 -5.60492973e-01 -5.30465804e-01 -4.49296121e-01\\n -1.16297256e-01 -2.51669809e-01  5.94972485e-01 -4.11495479e-01\\n -3.19674829e-01 -2.67490681e-01 -5.12945944e-01  2.33818009e-01\\n  8.75972437e-01 -6.08420987e-01 -1.76378152e-01  5.51371013e-01\\n -2.30739198e-01 -3.34985700e-01  3.42745218e-01  5.62488119e-02\\n  5.72103527e-01 -1.29670159e+00  6.59749780e-01 -5.66333515e-01\\n -4.57194954e-01  3.45446329e-01 -8.32308412e-02 -3.20337028e-01\\n -6.28450871e-01 -4.04206103e-01  7.96864303e-01 -4.10075030e-01\\n -7.52104621e-01 -7.74523064e-02 -6.45610517e-01 -5.04646811e-01\\n -1.01646016e-01 -3.06690269e-01  2.47078450e-01  8.24074967e-01\\n  1.22669874e-01 -5.32947610e-01 -7.07701905e-01 -2.73326477e-01\\n -3.93336420e-01 -7.61392873e-01  7.44128724e-04  1.53092630e-01\\n  4.10955215e-01  2.64045982e-01  3.49290682e-01 -5.21190976e-01\\n  9.94071667e-02  1.49538699e-01  1.68507036e+00  1.01599372e+00\\n -3.13267945e-01  1.83594516e-01  3.48560781e-01  5.55694981e-01\\n -6.99843003e-01  2.94119587e-01  5.45109850e-01 -4.96103322e-01\\n -3.68984151e-01  3.91813387e-01  2.68305225e-01  6.75748552e-02\\n  5.40011591e-01 -1.92669936e-01 -2.30267882e-01 -1.63876310e-01\\n  5.28286545e-01  5.79962981e-01  6.69204290e-01  4.30643173e-01\\n -3.14811503e-01 -5.51877806e-01  1.63309947e-02 -4.72744052e-02\\n -1.04074547e+00 -1.75224934e-01 -3.66859656e-01  3.65335030e-01\\n  4.68192959e-01 -6.35165230e-01 -4.20533409e-02  4.41385179e-01\\n -3.44105244e-01  1.90902838e-01  6.56821774e-01  1.13123169e-01\\n  1.56879599e-01  5.15136667e-01 -3.74995006e-01 -1.04123900e+00\\n  3.38537043e-01 -6.11314840e-01  3.32560034e-01 -4.48905490e-01\\n -3.39139469e-01 -1.33774056e-01 -3.97707076e-01  6.60391678e-02\\n  4.89607528e-01 -4.73789153e-01 -3.21835850e-01  5.59522142e-02\\n -7.20006593e-01  3.12566588e-02 -7.71185128e-01 -1.29179715e-01\\n  4.42069073e-01 -6.47234770e-02 -7.22073935e-01 -8.14043986e-01\\n -1.52959791e-02 -2.91804517e-01  3.08275739e-01  6.54435104e-01\\n -1.21301796e-01  7.04221581e-01  3.86503393e-01  2.98563035e-01\\n  4.29881061e-01 -4.07642787e-01 -4.49764550e-01 -5.29847010e-01\\n  2.57146749e-01  5.37821873e-01 -5.21150804e-01  8.49992469e-02\\n  2.66762256e-01 -1.91594519e-02 -6.19806008e-01 -7.20926815e-01\\n -2.12386943e-01  9.57793878e-01  2.75047815e-01  5.14741466e-01\\n -3.47253373e-01 -4.64609964e-01 -5.12525157e-01  5.76860931e-01\\n  7.55238586e-01 -1.24424573e-02 -6.72341421e-01  3.94604788e-01\\n  1.21075435e+00  2.98558905e-01 -2.52068442e-01  9.19124260e-01\\n  3.12550745e-01 -8.47514307e-01  6.81613033e-02 -4.41336662e-01\\n  4.37009407e-01  4.65523556e-02  3.10297330e-01 -1.40871338e-01\\n -3.50085634e-01  3.58102447e-02  3.11188395e-01  4.15632520e-01\\n -4.45097917e-01  3.21778380e-01 -1.14418151e+00 -2.04283862e-01\\n  6.10195245e-01  5.66958677e-01 -7.83058469e-01  2.74939532e-01\\n  4.05446827e-02  9.40322678e-01 -3.75761077e-01  3.87818199e-01\\n -5.84399567e-01  6.40369477e-01  5.67963884e-01 -3.58606593e-01\\n -2.68349856e-01  1.24098019e+00 -8.80944085e-01 -2.10405282e-01\\n  3.53550594e-01 -4.79930805e-01 -1.54350601e-01  1.30279323e+00\\n  1.05168885e-01 -3.61862249e-01  5.16905301e-01 -1.50345231e-02\\n  5.98057627e-01 -2.70538853e-01  1.93706068e-01  3.24306115e-01\\n  5.24186887e-01 -6.96458610e-02  1.02681364e+00  3.28220397e-01\\n  5.43917900e-01  2.07231803e-01  1.90634018e-01  7.57848024e-03\\n  3.93105985e-01  2.41228961e-01  5.33135523e-02 -2.14414501e-01\\n -4.74551479e-01  1.03680259e+00  1.35689856e-01 -3.08435363e-01\\n  1.78983567e-01 -1.17757855e-01  2.07610572e-01 -1.89504724e-01\\n  4.18338737e-01 -2.91789391e-01 -5.58760839e-02 -5.67820388e-01\\n  5.62995791e-02 -2.70350660e-02  4.14373273e-01  4.42355352e-01\\n  1.49261781e+00  7.18867448e-02  9.46860987e-01 -1.21149523e-01\\n  5.52964795e-01  1.71873377e-01  4.64890368e-01  2.97234405e-01\\n  6.85347965e-01 -1.90569269e-01 -1.13276647e-01 -4.94531512e-02\\n  4.19539312e-01 -4.64854481e-01  2.76644535e-01  4.68204672e-01\\n -3.21196003e-01  4.26445906e-01 -1.62632099e-01 -2.67511260e-01\\n  4.62436457e-02  5.40983494e-01 -2.98383462e-01  4.38950028e-01\\n -5.81944678e-01 -1.49256239e-01  3.99931115e-01 -1.26181452e+00\\n  5.93758182e-02 -4.09375548e-01 -3.31988921e-02  8.03149669e-01\\n  5.32385853e-01  3.60371982e-01 -2.59126493e-03 -1.26115752e-01\\n -4.58191088e-01  3.14421846e-01  9.05073186e-04 -1.63870742e-02\\n -3.63335744e-01  2.86261545e-01  2.13494249e-01 -3.96682610e-02\\n  8.15167705e-02  3.70567250e-01  7.95966610e-01  2.19524164e-01\\n  3.24370040e-01 -3.92054496e-01  1.08693946e-01  3.15087557e-01\\n  3.35790435e-01  4.61370643e-01  5.18940703e-01  8.24324350e-01\\n -1.62491196e-01  1.22115339e-01  2.07985939e-01  7.16522958e-01\\n -2.84392909e-01  3.68107510e-01 -9.34144344e-02 -5.97320175e-01\\n -3.84114250e-01  1.02225458e-01  5.27168938e-01  6.36912746e-01\\n -5.94873387e-01 -5.87633788e-01  3.69661368e-01 -1.77210889e-01\\n  1.06539909e-01  1.74512411e-01  2.63801016e-01 -6.37983030e-01\\n  1.41787683e+00 -9.62659086e-01  2.42608406e-01 -8.55568580e-02\\n  8.02985231e-02 -5.51327474e-01 -3.75591138e-02 -2.70714780e-02\\n  7.95393026e-01  4.26891924e-01 -6.33122587e-01  3.87174725e-01\\n  6.56269525e-01  2.33344347e-01 -7.48007214e-01  1.17551299e+00\\n  4.32939629e-03  4.04817783e-01  9.01158021e-01 -3.88734915e-01\\n -1.66907189e-01 -4.28884287e-01  4.86189564e-01 -2.11971681e-01\\n  4.88118568e-01 -2.32621433e-01 -2.31470006e-02  3.65867865e-01\\n  1.49216521e-01 -3.66679628e-01 -1.83052096e-01  2.84551187e-01\\n  1.86352948e-01  5.86717543e-02  1.01437112e-01  7.46023905e-02\\n  4.74953910e-01 -1.17743008e-01  6.83647450e-01  2.62364493e-01\\n  6.04644128e-01 -5.76706367e-03  2.41484495e-01 -6.27069935e-01\\n -7.41139443e-01  3.48749712e-02 -4.92859783e-01  4.89354730e-01\\n  2.26527651e-01 -3.72573775e-01 -4.77544097e-02  2.15686851e-01\\n  6.41637546e-02 -2.02718926e-01  2.38307057e-01  2.06737698e-01\\n  4.80277151e-01  4.35905706e-01  7.86870682e-02 -3.96420105e-01\\n  3.93949886e-01  3.39221134e-01  1.95549349e-01  3.17362592e-01\\n -4.98643943e-01  8.09750316e-01 -1.04477664e-01  5.52955276e-02\\n  4.74600091e-01  9.65673029e-03 -1.68662387e-01 -6.95666813e-01\\n -2.65146297e-01  3.49091468e-01 -4.05893388e-01  4.97862828e-01\\n  5.98126088e-01  4.97311101e-02  4.75820462e-01 -5.28088858e-02\\n -7.52059991e-01  4.23390937e-01  1.03811810e-01 -5.40073150e-01\\n -4.50509883e-01  6.89405521e-01  5.33050457e-01 -5.50043411e-01\\n -1.57014245e-01 -1.89920708e-01  1.38491261e-01  2.66535799e-01\\n -1.74890839e-01 -2.51803885e-01  1.76957695e-01 -3.61685407e-01\\n  9.83185507e-02 -9.97247811e-01  3.83876313e-01  4.40599174e-01\\n  6.09397185e-01  5.82956070e-01 -1.08119693e-01 -2.86942649e-01]\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access the first row using .iloc\n",
        "first_row_user_features = user_features.iloc[0]['user_features']\n",
        "print(first_row_user_features[:10])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLitBUapHKwZ",
        "outputId": "f3ff5681-fa19-48fc-d581-cbd5e123c8d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-2.958641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(first_row_user_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tTQ6Bv_rH8t0",
        "outputId": "3f30a5f7-2787-476a-f6dd-9d4f5b241ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove the brackets and split the strings by space, then convert to list of numbers\n",
        "user_features['user_features'] = user_features['user_features'].apply(lambda x: list(map(float, x.strip('[]').split())))\n",
        "\n",
        "# Check the conversion by printing the first row's user_features as a list\n",
        "first_row_user_features = user_features.iloc[0]['user_features']\n",
        "print(first_row_user_features[:10])\n",
        "\n",
        "# Check the type to ensure it's now a list\n",
        "print(type(first_row_user_features))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT3ycdLPHJq8",
        "outputId": "9a085f98-1ee5-46a2-ea32-22588c2e1cf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.295864147, 0.326706147, -0.403406552, 0.0679986624, -0.12577619, 0.295073545, -0.0743949063, -0.202107017, 0.663737171, 0.377613263]\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(first_row_user_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "evNRMpo7O7s4",
        "outputId": "27f2e2be-fac5-4467-91b8-15a472ee3b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Simple Feedforward Neural Network for the Siamese sub-networks\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Cosine similarity function\n",
        "def cosine_similarity(x1, x2):\n",
        "    sim = torch.nn.functional.cosine_similarity(x1, x2)\n",
        "    return sim\n"
      ],
      "metadata": {
        "id": "YR53hsRVF_Cd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert user embeddings and news embeddings to tensors\n",
        "def prepare_data(user_features, news_dict):\n",
        "    # Assuming user_features is a pandas dataframe with 'user_features' column\n",
        "    user_tensors = torch.tensor(user_features['user_features'].to_list(), dtype=torch.float32)\n",
        "\n",
        "    # Create news tensor from the dictionary (news_id: embedding)\n",
        "    news_ids = list(news_dict.keys())\n",
        "    news_embeddings = list(news_dict.values())\n",
        "    news_tensors = torch.tensor(news_embeddings, dtype=torch.float32)\n",
        "\n",
        "    return user_tensors, news_tensors, news_ids\n"
      ],
      "metadata": {
        "id": "nRNtIVO9I-Kr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
        "        loss = torch.mean((label) * torch.pow(euclidean_distance, 2) +\n",
        "                          (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "2wDs3fb5JCSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rank_news(user_embedding, news_embeddings, model):\n",
        "    # Pass the user and news embeddings through the Siamese network\n",
        "    user_embedding = user_embedding.unsqueeze(0)  # Add batch dimension\n",
        "    news_embeddings = news_embeddings  # News embeddings are already in batch\n",
        "\n",
        "    user_out = model(user_embedding)\n",
        "    news_out = model(news_embeddings)\n",
        "\n",
        "    # Compute similarity scores (higher score = more relevant)\n",
        "    similarity_scores = cosine_similarity(user_out, news_out)\n",
        "\n",
        "    return similarity_scores\n"
      ],
      "metadata": {
        "id": "cWBatLjgJEU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm  # Import tqdm for progress bar\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Define the Siamese Network\n",
        "class SiameseNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SiameseNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.fc2 = nn.Linear(256, 128)\n",
        "        self.fc3 = nn.Linear(128, 64)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.relu(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Cosine similarity function\n",
        "def cosine_similarity(x1, x2):\n",
        "    sim = torch.nn.functional.cosine_similarity(x1, x2)\n",
        "\n",
        "    return sim\n",
        "\n",
        "# Prepare data and move tensors to the correct device (GPU or CPU)\n",
        "def prepare_data(user_features, news_dict, device):\n",
        "    user_tensors = torch.tensor(user_features['user_features'].to_list(), dtype=torch.float32).to(device)\n",
        "\n",
        "    news_ids = list(news_dict.keys())\n",
        "    news_embeddings = list(news_dict.values())\n",
        "    news_tensors = torch.tensor(news_embeddings, dtype=torch.float32).to(device)\n",
        "\n",
        "    return user_tensors, news_tensors, news_ids\n",
        "\n",
        "# Contrastive loss function\n",
        "class ContrastiveLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(ContrastiveLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label):\n",
        "        euclidean_distance = torch.nn.functional.pairwise_distance(output1, output2)\n",
        "        loss = torch.mean((label) * torch.pow(euclidean_distance, 2) +\n",
        "                          (1 - label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss\n",
        "\n",
        "# Rank news for a user using the trained Siamese model\n",
        "def rank_news(user_embedding, news_embeddings, model, device):\n",
        "    user_embedding = user_embedding.unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "    news_embeddings = news_embeddings.to(device)  # Move news embeddings to device\n",
        "\n",
        "    user_out = model(user_embedding)\n",
        "    news_out = model(news_embeddings)\n",
        "\n",
        "    # Compute similarity scores (higher score = more relevant)\n",
        "    similarity_scores = cosine_similarity(user_out, news_out)\n",
        "\n",
        "    return similarity_scores\n",
        "\n",
        "# Assuming user_features is a dataframe with user embeddings and news_dict contains the news embeddings\n",
        "\n",
        "# Step 1: Prepare Data\n",
        "user_tensors, news_tensors, news_ids = prepare_data(user_features, news_dict, device)\n",
        "\n",
        "# Step 2: Initialize the Siamese Network\n",
        "input_dim = len(user_tensors[0])  # Length of the embedding vector\n",
        "siamese_model = SiameseNetwork(input_dim).to(device)  # Move model to GPU/CPU\n",
        "loss_fn = ContrastiveLoss()\n",
        "optimizer = optim.Adam(siamese_model.parameters(), lr=0.001)\n",
        "\n",
        "# Step 3: Train the model with Progress Bar\n",
        "epochs = 3  # Number of epochs\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    # Wrap the data loader with tqdm for progress bar\n",
        "    for user_tensor in tqdm(user_tensors, desc=f'Epoch {epoch+1}/{epochs}', ncols=100):\n",
        "        # Use the first user and a random news article as a pair (positive)\n",
        "        random_news_idx = np.random.choice(len(news_tensors))\n",
        "        news_tensor = news_tensors[random_news_idx]\n",
        "\n",
        "        # Assume all pairs are positive for simplicity here\n",
        "        label = torch.tensor([1.0], dtype=torch.float32).to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass through the Siamese network\n",
        "        user_out = siamese_model(user_tensor)\n",
        "        news_out = siamese_model(news_tensor)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(user_out, news_out, label)\n",
        "\n",
        "        # Backpropagate and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss}\")\n",
        "\n",
        "# Step 4: Rank news for a user\n",
        "user_idx = 0  # Assume we're ranking for the first user\n",
        "user_embedding = user_tensors[user_idx]\n",
        "similarity_scores = rank_news(user_embedding, news_tensors, siamese_model, device)\n",
        "\n",
        "# Rank the news articles based on similarity score\n",
        "ranked_news = [(news_ids[i], similarity_scores[i].item()) for i in range(len(news_ids))]\n",
        "ranked_news.sort(key=lambda x: x[1], reverse=True)  # Sort by score, descending\n",
        "print(ranked_news[:10])  # Print top 10 recommended articles\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDtdIevcJFm0",
        "outputId": "72cd8780-47d7-4704-d415-27a268cb41b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|█████████████████████████████████████████████| 50000/50000 [02:15<00:00, 368.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3, Loss: 18.836634504546097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|█████████████████████████████████████████████| 50000/50000 [02:13<00:00, 373.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3, Loss: 3.199999987213431e-06\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|█████████████████████████████████████████████| 50000/50000 [02:15<00:00, 370.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3, Loss: 3.199999987213431e-06\n",
            "[('N55528', 0.0), ('N19639', 0.0), ('N61837', 0.0), ('N53526', 0.0), ('N38324', 0.0), ('N2073', 0.0), ('N49186', 0.0), ('N59295', 0.0), ('N24510', 0.0), ('N39237', 0.0)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "user U13740"
      ],
      "metadata": {
        "id": "c4jeHn9dLt28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ranked_news_for_user(user_id, user_features, news_dict, model, device):\n",
        "    \"\"\"\n",
        "    Ranks news articles for a given user based on their embedding.\n",
        "\n",
        "    Args:\n",
        "        user_id (str): The ID of the user.\n",
        "        user_features (pd.DataFrame): DataFrame containing user embeddings.\n",
        "        news_dict (dict): Dictionary containing news embeddings.\n",
        "        model (nn.Module): Trained Siamese model.\n",
        "        device (torch.device): The device (CPU/GPU) to run the model.\n",
        "\n",
        "    Returns:\n",
        "        list: Ranked list of news articles with similarity scores.\n",
        "    \"\"\"\n",
        "    # Find the user's embedding\n",
        "    user_row = user_features[user_features['user_id'] == user_id]\n",
        "    if user_row.empty:\n",
        "        print(f\"User ID {user_id} not found.\")\n",
        "        return None\n",
        "\n",
        "    user_embedding = torch.tensor(user_row.iloc[0]['user_features'], dtype=torch.float32).to(device)\n",
        "\n",
        "    # Prepare news embeddings and IDs\n",
        "    news_ids = list(news_dict.keys())\n",
        "    news_embeddings = torch.tensor(list(news_dict.values()), dtype=torch.float32).to(device)\n",
        "\n",
        "    # Rank news articles\n",
        "    similarity_scores = rank_news(user_embedding, news_embeddings, model, device)\n",
        "    ranked_news = [(news_ids[i], similarity_scores[i].item()) for i in range(len(news_ids))]\n",
        "    ranked_news.sort(key=lambda x: x[1], reverse=True)  # Sort by score, descending\n",
        "\n",
        "    return ranked_news\n",
        "\n",
        "# Example usage:\n",
        "# Assume you have a trained model, user_features DataFrame, and news_dict\n",
        "user_id_input = input(\"Enter User ID: \")  # Prompt the user to input a User ID\n",
        "ranked_news = get_ranked_news_for_user(user_id_input, user_features, news_dict, siamese_model, device)\n",
        "\n",
        "if ranked_news:\n",
        "    print(\"\\nTop 10 Recommended News Articles:\")\n",
        "    for i, (news_id, score) in enumerate(ranked_news[:10], start=1):\n",
        "        print(f\"{i}. News ID: {news_id}, Similarity Score: {score:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWRNmPTKJPSL",
        "outputId": "3b16d648-f257-44a2-d8cc-ae0600bcc2d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter User ID: U13740\n",
            "\n",
            "Top 10 Recommended News Articles:\n",
            "1. News ID: N55528, Similarity Score: 0.0000\n",
            "2. News ID: N19639, Similarity Score: 0.0000\n",
            "3. News ID: N61837, Similarity Score: 0.0000\n",
            "4. News ID: N53526, Similarity Score: 0.0000\n",
            "5. News ID: N38324, Similarity Score: 0.0000\n",
            "6. News ID: N2073, Similarity Score: 0.0000\n",
            "7. News ID: N49186, Similarity Score: 0.0000\n",
            "8. News ID: N59295, Similarity Score: 0.0000\n",
            "9. News ID: N24510, Similarity Score: 0.0000\n",
            "10. News ID: N39237, Similarity Score: 0.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(user_embedding[:10])  # First 10 values of user embedding\n",
        "print(news_tensors[:5, :10])  # First 5 news embeddings (10 dimensions each)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfj3AyNVPk2F",
        "outputId": "a2d43a62-3780-4b16-9cd7-a36e7d6e9095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.2959,  0.3267, -0.4034,  0.0680, -0.1258,  0.2951, -0.0744, -0.2021,\n",
            "         0.6637,  0.3776], device='cuda:0')\n",
            "tensor([[-0.0573,  1.0353, -0.1545,  0.3155, -0.4874,  0.5163, -0.2954,  0.2651,\n",
            "          0.3986,  1.0028],\n",
            "        [-0.2866, -0.5982,  0.3986,  0.0727, -1.3963, -0.3369,  0.2509, -0.1593,\n",
            "          0.6373, -0.6112],\n",
            "        [-0.4703,  0.2465, -0.3937,  0.1332,  1.6515,  0.7260, -0.4415, -0.5733,\n",
            "         -0.8544, -1.2381],\n",
            "        [-0.4324, -0.6027,  0.4488, -0.2676, -1.3491, -0.3164,  0.0878, -0.2596,\n",
            "          0.7159, -0.1914],\n",
            "        [-0.2090, -0.7007,  0.7428,  0.2520, -1.5601, -0.0816, -0.1625, -0.1804,\n",
            "          0.5317, -0.3336]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SiameseNewsRankingNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims=[128, 64]):\n",
        "        \"\"\"\n",
        "        Siamese Network for personalized news ranking\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Dimension of input user and news embeddings\n",
        "            hidden_dims (list): List of hidden layer dimensions\n",
        "        \"\"\"\n",
        "        super(SiameseNewsRankingNetwork, self).__init__()\n",
        "\n",
        "        # Create embedding networks for users and news\n",
        "        self.user_network = self._create_embedding_network(input_dim, hidden_dims)\n",
        "        self.news_network = self._create_embedding_network(input_dim, hidden_dims)\n",
        "\n",
        "        # Contrastive loss layer\n",
        "        self.contrastive_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def _create_embedding_network(self, input_dim, hidden_dims):\n",
        "        \"\"\"\n",
        "        Create a multi-layer embedding network\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Input dimension\n",
        "            hidden_dims (list): List of hidden layer dimensions\n",
        "\n",
        "        Returns:\n",
        "            nn.Sequential: Embedding network\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        current_dim = input_dim\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.extend([\n",
        "                nn.Linear(current_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3)\n",
        "            ])\n",
        "            current_dim = hidden_dim\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, user_embedding, news_embedding):\n",
        "        \"\"\"\n",
        "        Forward pass of the Siamese Network\n",
        "\n",
        "        Args:\n",
        "            user_embedding (torch.Tensor): User embedding vector\n",
        "            news_embedding (torch.Tensor): News embedding vector\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Similarity score between user and news\n",
        "        \"\"\"\n",
        "        # Embed user and news separately\n",
        "        user_embedded = self.user_network(user_embedding)\n",
        "        news_embedded = self.news_network(news_embedding)\n",
        "\n",
        "        # Compute similarity (dot product)\n",
        "        similarity = torch.sum(user_embedded * news_embedded, dim=1)\n",
        "        return similarity\n",
        "\n",
        "    def compute_loss(self, user_embedding, news_embedding, labels):\n",
        "        \"\"\"\n",
        "        Compute contrastive loss\n",
        "\n",
        "        Args:\n",
        "            user_embedding (torch.Tensor): User embedding tensor\n",
        "            news_embedding (torch.Tensor): News embedding tensor\n",
        "            labels (torch.Tensor): Binary labels (relevant/not relevant)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Computed loss\n",
        "        \"\"\"\n",
        "        similarity_scores = self.forward(user_embedding, news_embedding)\n",
        "        loss = self.contrastive_loss(similarity_scores, labels)\n",
        "        return loss\n",
        "\n",
        "class NewsRankingDataset(Dataset):\n",
        "    def __init__(self, user_features, news_dict, interactions_df):\n",
        "        \"\"\"\n",
        "        Custom Dataset for News Ranking\n",
        "\n",
        "        Args:\n",
        "            user_features (pd.DataFrame): DataFrame with user features\n",
        "            news_dict (dict): Dictionary of news embeddings\n",
        "            interactions_df (pd.DataFrame): User-news interaction data\n",
        "        \"\"\"\n",
        "        self.user_features = user_features\n",
        "        self.news_dict = news_dict\n",
        "        self.interactions_df = interactions_df\n",
        "\n",
        "        # Prepare data for training\n",
        "        self.prepare_dataset()\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        \"\"\"\n",
        "        Prepare training dataset by creating positive and negative pairs\n",
        "        \"\"\"\n",
        "        # Convert embeddings to tensors\n",
        "        self.user_embeddings = {\n",
        "            uid: torch.tensor(features, dtype=torch.float32)\n",
        "            for uid, features in zip(self.user_features['user_id'], self.user_features['user_features'])\n",
        "        }\n",
        "\n",
        "        self.news_embeddings = {\n",
        "            nid: torch.tensor(emb, dtype=torch.float32)\n",
        "            for nid, emb in self.news_dict.items()\n",
        "        }\n",
        "\n",
        "        # Prepare training pairs with labels\n",
        "        self.training_pairs = []\n",
        "        for _, row in self.interactions_df.iterrows():\n",
        "            user_id = row['user_id']\n",
        "            news_id = row['news_id']\n",
        "            label = row['interaction_label']  # Binary label (1 for relevant, 0 for not relevant)\n",
        "\n",
        "            if user_id in self.user_embeddings and news_id in self.news_embeddings:\n",
        "                self.training_pairs.append({\n",
        "                    'user_embedding': self.user_embeddings[user_id],\n",
        "                    'news_embedding': self.news_embeddings[news_id],\n",
        "                    'label': label\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.training_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.training_pairs[idx]\n",
        "        return (\n",
        "            pair['user_embedding'],\n",
        "            pair['news_embedding'],\n",
        "            torch.tensor(pair['label'], dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "def train_siamese_news_ranking(\n",
        "    user_features,\n",
        "    news_dict,\n",
        "    interactions_df,\n",
        "    input_dim,\n",
        "    epochs=20,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=32\n",
        "):\n",
        "    \"\"\"\n",
        "    Train Siamese Network for personalized news ranking\n",
        "\n",
        "    Args:\n",
        "        user_features (pd.DataFrame): User feature dataframe\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "        interactions_df (pd.DataFrame): User-news interaction data\n",
        "        input_dim (int): Dimension of input embeddings\n",
        "        epochs (int): Number of training epochs\n",
        "        learning_rate (float): Learning rate for optimizer\n",
        "        batch_size (int): Batch size for training\n",
        "\n",
        "    Returns:\n",
        "        SiameseNewsRankingNetwork: Trained model\n",
        "    \"\"\"\n",
        "    # Split data into train and validation sets\n",
        "    train_interactions, val_interactions = train_test_split(\n",
        "        interactions_df, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = NewsRankingDataset(user_features, news_dict, train_interactions)\n",
        "    val_dataset = NewsRankingDataset(user_features, news_dict, val_interactions)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = SiameseNewsRankingNetwork(input_dim)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for user_emb, news_emb, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Compute loss\n",
        "            loss = model.compute_loss(user_emb, news_emb, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for user_emb, news_emb, labels in val_loader:\n",
        "                val_loss += model.compute_loss(user_emb, news_emb, labels).item()\n",
        "\n",
        "        # Print epoch statistics\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Val Loss: {val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def rank_news_for_user(model, user_embedding, news_dict):\n",
        "    \"\"\"\n",
        "    Rank news items for a specific user\n",
        "\n",
        "    Args:\n",
        "        model (SiameseNewsRankingNetwork): Trained Siamese Network\n",
        "        user_embedding (torch.Tensor): Embedding of the user\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "\n",
        "    Returns:\n",
        "        list: Ranked news items with their similarity scores\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    news_rankings = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for news_id, news_embedding in news_dict.items():\n",
        "            # Convert to tensor if not already\n",
        "            if not isinstance(news_embedding, torch.Tensor):\n",
        "                news_embedding = torch.tensor(news_embedding, dtype=torch.float32)\n",
        "\n",
        "            # Compute similarity score\n",
        "            similarity = model.forward(\n",
        "                user_embedding.unsqueeze(0),\n",
        "                news_embedding.unsqueeze(0)\n",
        "            ).item()\n",
        "\n",
        "            news_rankings.append((news_id, similarity))\n",
        "\n",
        "    # Sort news by similarity score in descending order\n",
        "    ranked_news = sorted(news_rankings, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return ranked_news\n",
        "\n",
        "# Example usage\n",
        "def create_synthetic_interactions(user_features, news_dict, num_interactions=500):\n",
        "    \"\"\"\n",
        "    Create synthetic interaction data for training\n",
        "\n",
        "    Args:\n",
        "        user_features (pd.DataFrame): User features DataFrame\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "        num_interactions (int): Number of synthetic interactions to generate\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Synthetic interactions DataFrame\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Get list of user and news IDs\n",
        "    user_ids = user_features['user_id'].tolist()\n",
        "    news_ids = list(news_dict.keys())\n",
        "\n",
        "    # Create synthetic interactions\n",
        "    interactions_data = []\n",
        "    for _ in range(num_interactions):\n",
        "        # Randomly select user and news\n",
        "        user_id = np.random.choice(user_ids)\n",
        "        news_id = np.random.choice(news_ids)\n",
        "\n",
        "        # Create a synthetic interaction label\n",
        "        # This could be based on some similarity logic or random\n",
        "        user_embedding = np.array(user_features[user_features['user_id'] == user_id]['user_features'].iloc[0])\n",
        "        news_embedding = np.array(news_dict[news_id])\n",
        "\n",
        "        # Simple similarity-based labeling (cosine similarity)\n",
        "        similarity = np.dot(user_embedding, news_embedding) / (\n",
        "            np.linalg.norm(user_embedding) * np.linalg.norm(news_embedding)\n",
        "        )\n",
        "\n",
        "        # Label as relevant if similarity is above a threshold\n",
        "        interaction_label = 1 if similarity > 0.5 else 0\n",
        "\n",
        "        interactions_data.append({\n",
        "            'user_id': user_id,\n",
        "            'news_id': news_id,\n",
        "            'interaction_label': interaction_label\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(interactions_data)\n",
        "\n",
        "def main():\n",
        "    # Assume these are prepared beforehand\n",
        "    # user_features: DataFrame with user_id and user_features\n",
        "    # news_dict: Dictionary of news embeddings\n",
        "\n",
        "    # Create synthetic interactions\n",
        "    interactions_df = create_synthetic_interactions(user_features, news_dict)\n",
        "\n",
        "    # Determine input dimension from the embeddings\n",
        "    input_dim = len(user_features.iloc[0]['user_features'])\n",
        "\n",
        "    # Train the model\n",
        "    trained_model = train_siamese_news_ranking(\n",
        "        user_features,\n",
        "        news_dict,\n",
        "        interactions_df,\n",
        "        input_dim\n",
        "    )\n",
        "\n",
        "    # Example: Rank news for a specific user\n",
        "    user_id = 'U100'\n",
        "    user_embedding = torch.tensor(\n",
        "        user_features[user_features['user_id'] == user_id]['user_features'].iloc[0],\n",
        "        dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # Rank news for this user\n",
        "    ranked_news = rank_news_for_user(trained_model, user_embedding, news_dict)\n",
        "\n",
        "    # Print top 10 recommended news items\n",
        "    print(\"Top 10 News Recommendations:\")\n",
        "    for news_id, score in ranked_news[:10]:\n",
        "        print(f\"News ID: {news_id}, Similarity Score: {score}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "# Notes for implementation:\n",
        "# 1. Ensure interactions_df has columns: user_id, news_id, interaction_label\n",
        "# 2. interaction_label should be binary (1 for relevant, 0 for not relevant)\n",
        "# 3. Adjust hyperparameters as needed for your specific dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPiNFAt6PkzV",
        "outputId": "398095ec-ffd0-4c0d-b2fe-afc48b258ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-50-46268fa00d06>:282: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  similarity = np.dot(user_embedding, news_embedding) / (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "Train Loss: 7.6975\n",
            "Val Loss: 2.4806\n",
            "Epoch 2/20\n",
            "Train Loss: 6.1152\n",
            "Val Loss: 4.7153\n",
            "Epoch 3/20\n",
            "Train Loss: 5.3198\n",
            "Val Loss: 4.1129\n",
            "Epoch 4/20\n",
            "Train Loss: 4.4728\n",
            "Val Loss: 3.4159\n",
            "Epoch 5/20\n",
            "Train Loss: 3.6733\n",
            "Val Loss: 2.9050\n",
            "Epoch 6/20\n",
            "Train Loss: 2.8918\n",
            "Val Loss: 2.2104\n",
            "Epoch 7/20\n",
            "Train Loss: 2.3127\n",
            "Val Loss: 1.8457\n",
            "Epoch 8/20\n",
            "Train Loss: 1.8689\n",
            "Val Loss: 1.6152\n",
            "Epoch 9/20\n",
            "Train Loss: 2.0350\n",
            "Val Loss: 1.4331\n",
            "Epoch 10/20\n",
            "Train Loss: 1.5725\n",
            "Val Loss: 1.3390\n",
            "Epoch 11/20\n",
            "Train Loss: 1.3705\n",
            "Val Loss: 1.3096\n",
            "Epoch 12/20\n",
            "Train Loss: 1.2821\n",
            "Val Loss: 1.1744\n",
            "Epoch 13/20\n",
            "Train Loss: 1.1442\n",
            "Val Loss: 1.1295\n",
            "Epoch 14/20\n",
            "Train Loss: 0.9546\n",
            "Val Loss: 1.1139\n",
            "Epoch 15/20\n",
            "Train Loss: 0.8719\n",
            "Val Loss: 1.1058\n",
            "Epoch 16/20\n",
            "Train Loss: 1.0536\n",
            "Val Loss: 1.0479\n",
            "Epoch 17/20\n",
            "Train Loss: 0.8321\n",
            "Val Loss: 0.9197\n",
            "Epoch 18/20\n",
            "Train Loss: 0.7735\n",
            "Val Loss: 0.9136\n",
            "Epoch 19/20\n",
            "Train Loss: 0.8070\n",
            "Val Loss: 0.9064\n",
            "Epoch 20/20\n",
            "Train Loss: 0.7587\n",
            "Val Loss: 0.9034\n",
            "Top 10 News Recommendations:\n",
            "News ID: N20717, Similarity Score: 1.9652212858200073\n",
            "News ID: N55289, Similarity Score: 1.934753656387329\n",
            "News ID: N63291, Similarity Score: 1.9260973930358887\n",
            "News ID: N26712, Similarity Score: 1.9234721660614014\n",
            "News ID: N64330, Similarity Score: 1.9076671600341797\n",
            "News ID: N5394, Similarity Score: 1.8963924646377563\n",
            "News ID: N48830, Similarity Score: 1.8938210010528564\n",
            "News ID: N34996, Similarity Score: 1.8920609951019287\n",
            "News ID: N39576, Similarity Score: 1.8897066116333008\n",
            "News ID: N4731, Similarity Score: 1.889625072479248\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "class SiameseNewsRankingNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims=[256, 128, 64]):\n",
        "        \"\"\"\n",
        "        Improved Siamese Network for personalized news ranking\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Dimension of input user and news embeddings\n",
        "            hidden_dims (list): List of hidden layer dimensions\n",
        "        \"\"\"\n",
        "        super(SiameseNewsRankingNetwork, self).__init__()\n",
        "\n",
        "        # Create embedding networks for users and news with residual connections\n",
        "        self.user_network = self._create_embedding_network(input_dim, hidden_dims)\n",
        "        self.news_network = self._create_embedding_network(input_dim, hidden_dims)\n",
        "\n",
        "        # Final similarity layer\n",
        "        self.similarity_layer = nn.Sequential(\n",
        "            nn.Linear(hidden_dims[-1]*2, hidden_dims[-1]),\n",
        "            nn.BatchNorm1d(hidden_dims[-1]),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(hidden_dims[-1], 1)\n",
        "        )\n",
        "\n",
        "        # Weight initialization\n",
        "        self.apply(self._init_weights)\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        \"\"\"\n",
        "        Initialize weights using Xavier initialization\n",
        "        \"\"\"\n",
        "        if isinstance(module, nn.Linear):\n",
        "            nn.init.xavier_uniform_(module.weight)\n",
        "            if module.bias is not None:\n",
        "                nn.init.constant_(module.bias, 0)\n",
        "\n",
        "    def _create_embedding_network(self, input_dim, hidden_dims):\n",
        "        \"\"\"\n",
        "        Create a multi-layer embedding network with residual connections\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Input dimension\n",
        "            hidden_dims (list): List of hidden layer dimensions\n",
        "\n",
        "        Returns:\n",
        "            nn.Sequential: Embedding network\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        current_dim = input_dim\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            # Residual block\n",
        "            res_block = nn.Sequential(\n",
        "                nn.Linear(current_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3),\n",
        "                nn.Linear(hidden_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim)\n",
        "            )\n",
        "\n",
        "            # Residual connection\n",
        "            if current_dim == hidden_dim:\n",
        "                layers.append(lambda x: res_block(x) + x)\n",
        "            else:\n",
        "                layers.append(res_block)\n",
        "\n",
        "            current_dim = hidden_dim\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, user_embedding, news_embedding):\n",
        "        \"\"\"\n",
        "        Forward pass of the Siamese Network\n",
        "\n",
        "        Args:\n",
        "            user_embedding (torch.Tensor): User embedding vector\n",
        "            news_embedding (torch.Tensor): News embedding vector\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Similarity score between user and news\n",
        "        \"\"\"\n",
        "        # Embed user and news separately\n",
        "        user_embedded = self.user_network(user_embedding)\n",
        "        news_embedded = self.news_network(news_embedding)\n",
        "\n",
        "        # Concatenate embeddings\n",
        "        combined = torch.cat([user_embedded, news_embedded], dim=1)\n",
        "\n",
        "        # Compute final similarity score\n",
        "        similarity = self.similarity_layer(combined)\n",
        "        return similarity.squeeze()\n",
        "\n",
        "    def compute_loss(self, user_embedding, news_embedding, labels):\n",
        "        \"\"\"\n",
        "        Compute contrastive loss with label smoothing\n",
        "\n",
        "        Args:\n",
        "            user_embedding (torch.Tensor): User embedding tensor\n",
        "            news_embedding (torch.Tensor): News embedding tensor\n",
        "            labels (torch.Tensor): Binary labels (relevant/not relevant)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Computed loss\n",
        "        \"\"\"\n",
        "        # Apply label smoothing\n",
        "        smoothed_labels = labels * 0.9 + 0.1 * (1 - labels)\n",
        "\n",
        "        # Compute similarity scores\n",
        "        similarity_scores = self.forward(user_embedding, news_embedding)\n",
        "\n",
        "        # Binary Cross Entropy Loss\n",
        "        loss = nn.functional.binary_cross_entropy_with_logits(\n",
        "            similarity_scores,\n",
        "            smoothed_labels\n",
        "        )\n",
        "        return loss\n",
        "\n",
        "class NewsRankingDataset(Dataset):\n",
        "    def __init__(self, user_features, news_dict, interactions_df, user_scaler=None, news_scaler=None):\n",
        "        \"\"\"\n",
        "        Custom Dataset for News Ranking with optional scaling\n",
        "\n",
        "        Args:\n",
        "            user_features (pd.DataFrame): DataFrame with user features\n",
        "            news_dict (dict): Dictionary of news embeddings\n",
        "            interactions_df (pd.DataFrame): User-news interaction data\n",
        "            user_scaler (StandardScaler, optional): Scaler for user features\n",
        "            news_scaler (StandardScaler, optional): Scaler for news features\n",
        "        \"\"\"\n",
        "        self.user_features = user_features\n",
        "        self.news_dict = news_dict\n",
        "        self.interactions_df = interactions_df\n",
        "\n",
        "        # Prepare scalers if not provided\n",
        "        self.user_scaler = user_scaler if user_scaler else StandardScaler()\n",
        "        self.news_scaler = news_scaler if news_scaler else StandardScaler()\n",
        "\n",
        "        # Prepare data for training\n",
        "        self.prepare_dataset()\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        \"\"\"\n",
        "        Prepare training dataset with feature scaling\n",
        "        \"\"\"\n",
        "        # Prepare user embeddings with scaling\n",
        "        user_emb_array = np.array(self.user_features['user_features'].tolist())\n",
        "        user_emb_scaled = self.user_scaler.fit_transform(user_emb_array)\n",
        "\n",
        "        # Prepare news embeddings with scaling\n",
        "        news_emb_array = np.array(list(self.news_dict.values()))\n",
        "        news_emb_scaled = self.news_scaler.fit_transform(news_emb_array)\n",
        "\n",
        "        # Convert to dictionaries\n",
        "        self.user_embeddings = {\n",
        "            uid: torch.tensor(features, dtype=torch.float32)\n",
        "            for uid, features in zip(self.user_features['user_id'], user_emb_scaled)\n",
        "        }\n",
        "\n",
        "        self.news_embeddings = {\n",
        "            nid: torch.tensor(emb, dtype=torch.float32)\n",
        "            for nid, emb in zip(self.news_dict.keys(), news_emb_scaled)\n",
        "        }\n",
        "\n",
        "        # Prepare training pairs with labels\n",
        "        self.training_pairs = []\n",
        "        for _, row in self.interactions_df.iterrows():\n",
        "            user_id = row['user_id']\n",
        "            news_id = row['news_id']\n",
        "            label = row['interaction_label']\n",
        "\n",
        "            if user_id in self.user_embeddings and news_id in self.news_embeddings:\n",
        "                self.training_pairs.append({\n",
        "                    'user_embedding': self.user_embeddings[user_id],\n",
        "                    'news_embedding': self.news_embeddings[news_id],\n",
        "                    'label': label\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.training_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.training_pairs[idx]\n",
        "        return (\n",
        "            pair['user_embedding'],\n",
        "            pair['news_embedding'],\n",
        "            torch.tensor(pair['label'], dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "def train_siamese_news_ranking(\n",
        "    user_features,\n",
        "    news_dict,\n",
        "    interactions_df,\n",
        "    input_dim,\n",
        "    epochs=100,\n",
        "    learning_rate=0.0005,\n",
        "    batch_size=32,\n",
        "    early_stopping_patience=10\n",
        "):\n",
        "    \"\"\"\n",
        "    Train Siamese Network for personalized news ranking with early stopping\n",
        "\n",
        "    Args:\n",
        "        user_features (pd.DataFrame): User feature dataframe\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "        interactions_df (pd.DataFrame): User-news interaction data\n",
        "        input_dim (int): Dimension of input embeddings\n",
        "        epochs (int): Maximum number of training epochs\n",
        "        learning_rate (float): Learning rate for optimizer\n",
        "        batch_size (int): Batch size for training\n",
        "        early_stopping_patience (int): Epochs to wait for improvement\n",
        "\n",
        "    Returns:\n",
        "        SiameseNewsRankingNetwork: Trained model\n",
        "    \"\"\"\n",
        "    # Split data into train and validation sets\n",
        "    train_interactions, val_interactions = train_test_split(\n",
        "        interactions_df, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create scalers\n",
        "    user_scaler = StandardScaler()\n",
        "    news_scaler = StandardScaler()\n",
        "\n",
        "    # Create datasets with scaling\n",
        "    train_dataset = NewsRankingDataset(\n",
        "        user_features, news_dict, train_interactions,\n",
        "        user_scaler, news_scaler\n",
        "    )\n",
        "    val_dataset = NewsRankingDataset(\n",
        "        user_features, news_dict, val_interactions,\n",
        "        user_scaler, news_scaler\n",
        "    )\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = SiameseNewsRankingNetwork(input_dim)\n",
        "\n",
        "    # Optimizer with weight decay (L2 regularization)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
        "\n",
        "    # Learning rate scheduler\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        factor=0.5,\n",
        "        patience=5,\n",
        "        verbose=True\n",
        "    )\n",
        "\n",
        "    # Early stopping\n",
        "    best_val_loss = float('inf')\n",
        "    patience_counter = 0\n",
        "    best_model_state = None\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for user_emb, news_emb, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Compute loss\n",
        "            loss = model.compute_loss(user_emb, news_emb, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            # Gradient clipping\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for user_emb, news_emb, labels in val_loader:\n",
        "                val_loss += model.compute_loss(user_emb, news_emb, labels).item()\n",
        "\n",
        "        # Average losses\n",
        "        train_loss /= len(train_loader)\n",
        "        val_loss /= len(val_loader)\n",
        "\n",
        "        # Learning rate scheduling\n",
        "        scheduler.step(val_loss)\n",
        "\n",
        "        # Early stopping and model checkpointing\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            patience_counter = 0\n",
        "            best_model_state = model.state_dict().copy()\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "\n",
        "        # Print epoch statistics\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Train Loss: {train_loss:.4f}\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}\")\n",
        "\n",
        "        # Early stopping\n",
        "        if patience_counter >= early_stopping_patience:\n",
        "            print(f\"Early stopping triggered after {epoch+1} epochs\")\n",
        "            break\n",
        "\n",
        "    # Load best model state\n",
        "    if best_model_state:\n",
        "        model.load_state_dict(best_model_state)\n",
        "\n",
        "    return model, user_scaler, news_scaler\n",
        "\n",
        "def rank_news_for_user(\n",
        "    model,\n",
        "    user_embedding,\n",
        "    news_dict,\n",
        "    user_scaler=None,\n",
        "    news_scaler=None\n",
        "):\n",
        "    \"\"\"\n",
        "    Rank news items for a specific user\n",
        "\n",
        "    Args:\n",
        "        model (SiameseNewsRankingNetwork): Trained Siamese Network\n",
        "        user_embedding (torch.Tensor): Embedding of the user\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "        user_scaler (StandardScaler, optional): User feature scaler\n",
        "        news_scaler (StandardScaler, optional): News feature scaler\n",
        "\n",
        "    Returns:\n",
        "        list: Ranked news items with their similarity scores\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    news_rankings = []\n",
        "\n",
        "    # Scale user embedding if scaler is provided\n",
        "    if user_scaler:\n",
        "        user_embedding = torch.tensor(\n",
        "            user_scaler.transform([user_embedding])[0],\n",
        "            dtype=torch.float32\n",
        "        )\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for news_id, news_embedding in news_dict.items():\n",
        "            # Scale news embedding if scaler is provided\n",
        "            if news_scaler:\n",
        "                news_embedding = torch.tensor(\n",
        "                    news_scaler.transform([news_embedding])[0],\n",
        "                    dtype=torch.float32\n",
        "                )\n",
        "\n",
        "            # Compute similarity score\n",
        "            similarity = torch.sigmoid(\n",
        "                model.forward(\n",
        "                    user_embedding.unsqueeze(0),\n",
        "                    news_embedding.unsqueeze(0)\n",
        "                )\n",
        "            ).item()\n",
        "\n",
        "            news_rankings.append((news_id, similarity))\n",
        "\n",
        "    # Sort news by similarity score in descending order\n",
        "    ranked_news = sorted(news_rankings, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return ranked_news\n",
        "\n",
        "def create_synthetic_interactions(user_features, news_dict, num_interactions=500):\n",
        "    \"\"\"\n",
        "    Create synthetic interaction data for training\n",
        "\n",
        "    Args:\n",
        "        user_features (pd.DataFrame): User features DataFrame\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "        num_interactions (int): Number of synthetic interactions to generate\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Synthetic interactions DataFrame\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Get list of user and news IDs\n",
        "    user_ids = user_features['user_id'].tolist()\n",
        "    news_ids = list(news_dict.keys())\n",
        "\n",
        "    # Create synthetic interactions\n",
        "    interactions_data = []\n",
        "    for _ in range(num_interactions):\n",
        "        # Randomly select user and news\n",
        "        user_id = np.random.choice(user_ids)\n",
        "        news_id = np.random.choice(news_ids)\n",
        "\n",
        "        # Create a synthetic interaction label\n",
        "        user_embedding = np.array(user_features[user_features['user_id'] == user_id]['user_features'].iloc[0])\n",
        "        news_embedding = np.array(news_dict[news_id])\n",
        "\n",
        "        # Simple similarity-based labeling (cosine similarity)\n",
        "        similarity = np.dot(user_embedding, news_embedding) / (\n",
        "            np.linalg.norm(user_embedding) * np.linalg.norm(news_embedding)\n",
        "        )\n",
        "\n",
        "        # Label as relevant if similarity is above a threshold\n",
        "        interaction_label = 1 if similarity > 0.5 else 0\n",
        "\n",
        "        interactions_data.append({\n",
        "            'user_id': user_id,\n",
        "            'news_id': news_id,\n",
        "            'interaction_label': interaction_label\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(interactions_data)\n",
        "\n",
        "def main():\n",
        "    # Assume these are prepared beforehand\n",
        "    # user_features: DataFrame with user_id and user_features\n",
        "    # news_dict: Dictionary of news embeddings\n",
        "\n",
        "    # Create synthetic interactions\n",
        "    interactions_df = create_synthetic_interactions(user_features, news_dict)\n",
        "\n",
        "    # Determine input dimension from the embeddings\n",
        "    input_dim = len(user_features.iloc[0])\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class SiameseNewsRankingNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dims=[128, 64]):\n",
        "        \"\"\"\n",
        "        Siamese Network for personalized news ranking\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Dimension of input user and news embeddings\n",
        "            hidden_dims (list): List of hidden layer dimensions\n",
        "        \"\"\"\n",
        "        super(SiameseNewsRankingNetwork, self).__init__()\n",
        "\n",
        "        # Create embedding networks for users and news\n",
        "        self.user_network = self._create_embedding_network(input_dim, hidden_dims)\n",
        "        self.news_network = self._create_embedding_network(input_dim, hidden_dims)\n",
        "\n",
        "        # Contrastive loss layer\n",
        "        self.contrastive_loss = nn.BCEWithLogitsLoss()\n",
        "\n",
        "    def _create_embedding_network(self, input_dim, hidden_dims):\n",
        "        \"\"\"\n",
        "        Create a multi-layer embedding network\n",
        "\n",
        "        Args:\n",
        "            input_dim (int): Input dimension\n",
        "            hidden_dims (list): List of hidden layer dimensions\n",
        "\n",
        "        Returns:\n",
        "            nn.Sequential: Embedding network\n",
        "        \"\"\"\n",
        "        layers = []\n",
        "        current_dim = input_dim\n",
        "\n",
        "        for hidden_dim in hidden_dims:\n",
        "            layers.extend([\n",
        "                nn.Linear(current_dim, hidden_dim),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Dropout(0.3)\n",
        "            ])\n",
        "            current_dim = hidden_dim\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, user_embedding, news_embedding):\n",
        "        \"\"\"\n",
        "        Forward pass of the Siamese Network\n",
        "\n",
        "        Args:\n",
        "            user_embedding (torch.Tensor): User embedding vector\n",
        "            news_embedding (torch.Tensor): News embedding vector\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Similarity score between user and news\n",
        "        \"\"\"\n",
        "        # Embed user and news separately\n",
        "        user_embedded = self.user_network(user_embedding)\n",
        "        news_embedded = self.news_network(news_embedding)\n",
        "\n",
        "        # Compute similarity (dot product)\n",
        "        similarity = torch.sum(user_embedded * news_embedded, dim=1)\n",
        "        return similarity\n",
        "\n",
        "    def compute_loss(self, user_embedding, news_embedding, labels):\n",
        "        \"\"\"\n",
        "        Compute contrastive loss\n",
        "\n",
        "        Args:\n",
        "            user_embedding (torch.Tensor): User embedding tensor\n",
        "            news_embedding (torch.Tensor): News embedding tensor\n",
        "            labels (torch.Tensor): Binary labels (relevant/not relevant)\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Computed loss\n",
        "        \"\"\"\n",
        "        similarity_scores = self.forward(user_embedding, news_embedding)\n",
        "        loss = self.contrastive_loss(similarity_scores, labels)\n",
        "        return loss\n",
        "\n",
        "class NewsRankingDataset(Dataset):\n",
        "    def __init__(self, user_features, news_dict, interactions_df):\n",
        "        \"\"\"\n",
        "        Custom Dataset for News Ranking\n",
        "\n",
        "        Args:\n",
        "            user_features (pd.DataFrame): DataFrame with user features\n",
        "            news_dict (dict): Dictionary of news embeddings\n",
        "            interactions_df (pd.DataFrame): User-news interaction data\n",
        "        \"\"\"\n",
        "        self.user_features = user_features\n",
        "        self.news_dict = news_dict\n",
        "        self.interactions_df = interactions_df\n",
        "\n",
        "        # Prepare data for training\n",
        "        self.prepare_dataset()\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        \"\"\"\n",
        "        Prepare training dataset by creating positive and negative pairs\n",
        "        \"\"\"\n",
        "        # Convert embeddings to tensors\n",
        "        self.user_embeddings = {\n",
        "            uid: torch.tensor(features, dtype=torch.float32)\n",
        "            for uid, features in zip(self.user_features['user_id'], self.user_features['user_features'])\n",
        "        }\n",
        "\n",
        "        self.news_embeddings = {\n",
        "            nid: torch.tensor(emb, dtype=torch.float32)\n",
        "            for nid, emb in self.news_dict.items()\n",
        "        }\n",
        "\n",
        "        # Prepare training pairs with labels\n",
        "        self.training_pairs = []\n",
        "        for _, row in self.interactions_df.iterrows():\n",
        "            user_id = row['user_id']\n",
        "            news_id = row['news_id']\n",
        "            label = row['interaction_label']  # Binary label (1 for relevant, 0 for not relevant)\n",
        "\n",
        "            if user_id in self.user_embeddings and news_id in self.news_embeddings:\n",
        "                self.training_pairs.append({\n",
        "                    'user_embedding': self.user_embeddings[user_id],\n",
        "                    'news_embedding': self.news_embeddings[news_id],\n",
        "                    'label': label\n",
        "                })\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.training_pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pair = self.training_pairs[idx]\n",
        "        return (\n",
        "            pair['user_embedding'],\n",
        "            pair['news_embedding'],\n",
        "            torch.tensor(pair['label'], dtype=torch.float32)\n",
        "        )\n",
        "\n",
        "def train_siamese_news_ranking(\n",
        "    user_features,\n",
        "    news_dict,\n",
        "    interactions_df,\n",
        "    input_dim,\n",
        "    epochs=20,\n",
        "    learning_rate=0.001,\n",
        "    batch_size=32\n",
        "):\n",
        "    \"\"\"\n",
        "    Train Siamese Network for personalized news ranking\n",
        "\n",
        "    Args:\n",
        "        user_features (pd.DataFrame): User feature dataframe\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "        interactions_df (pd.DataFrame): User-news interaction data\n",
        "        input_dim (int): Dimension of input embeddings\n",
        "        epochs (int): Number of training epochs\n",
        "        learning_rate (float): Learning rate for optimizer\n",
        "        batch_size (int): Batch size for training\n",
        "\n",
        "    Returns:\n",
        "        SiameseNewsRankingNetwork: Trained model\n",
        "    \"\"\"\n",
        "    # Split data into train and validation sets\n",
        "    train_interactions, val_interactions = train_test_split(\n",
        "        interactions_df, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = NewsRankingDataset(user_features, news_dict, train_interactions)\n",
        "    val_dataset = NewsRankingDataset(user_features, news_dict, val_interactions)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Initialize model\n",
        "    model = SiameseNewsRankingNetwork(input_dim)\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for user_emb, news_emb, labels in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Compute loss\n",
        "            loss = model.compute_loss(user_emb, news_emb, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for user_emb, news_emb, labels in val_loader:\n",
        "                val_loss += model.compute_loss(user_emb, news_emb, labels).item()\n",
        "\n",
        "        # Print epoch statistics\n",
        "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
        "        print(f\"Val Loss: {val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def rank_news_for_user(model, user_embedding, news_dict):\n",
        "    \"\"\"\n",
        "    Rank news items for a specific user\n",
        "\n",
        "    Args:\n",
        "        model (SiameseNewsRankingNetwork): Trained Siamese Network\n",
        "        user_embedding (torch.Tensor): Embedding of the user\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "\n",
        "    Returns:\n",
        "        list: Ranked news items with their similarity scores\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    news_rankings = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for news_id, news_embedding in news_dict.items():\n",
        "            # Convert to tensor if not already\n",
        "            if not isinstance(news_embedding, torch.Tensor):\n",
        "                news_embedding = torch.tensor(news_embedding, dtype=torch.float32)\n",
        "\n",
        "            # Compute similarity score\n",
        "            similarity = model.forward(\n",
        "                user_embedding.unsqueeze(0),\n",
        "                news_embedding.unsqueeze(0)\n",
        "            ).item()\n",
        "\n",
        "            news_rankings.append((news_id, similarity))\n",
        "\n",
        "    # Sort news by similarity score in descending order\n",
        "    ranked_news = sorted(news_rankings, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    return ranked_news\n",
        "\n",
        "# Example usage\n",
        "def create_synthetic_interactions(user_features, news_dict, num_interactions=500):\n",
        "    \"\"\"\n",
        "    Create synthetic interaction data for training\n",
        "\n",
        "    Args:\n",
        "        user_features (pd.DataFrame): User features DataFrame\n",
        "        news_dict (dict): Dictionary of news embeddings\n",
        "        num_interactions (int): Number of synthetic interactions to generate\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: Synthetic interactions DataFrame\n",
        "    \"\"\"\n",
        "    import numpy as np\n",
        "\n",
        "    # Get list of user and news IDs\n",
        "    user_ids = user_features['user_id'].tolist()\n",
        "    news_ids = list(news_dict.keys())\n",
        "\n",
        "    # Create synthetic interactions\n",
        "    interactions_data = []\n",
        "    for _ in range(num_interactions):\n",
        "        # Randomly select user and news\n",
        "        user_id = np.random.choice(user_ids)\n",
        "        news_id = np.random.choice(news_ids)\n",
        "\n",
        "        # Create a synthetic interaction label\n",
        "        # This could be based on some similarity logic or random\n",
        "        user_embedding = np.array(user_features[user_features['user_id'] == user_id]['user_features'].iloc[0])\n",
        "        news_embedding = np.array(news_dict[news_id])\n",
        "\n",
        "        # Simple similarity-based labeling (cosine similarity)\n",
        "        similarity = np.dot(user_embedding, news_embedding) / (\n",
        "            np.linalg.norm(user_embedding) * np.linalg.norm(news_embedding)\n",
        "        )\n",
        "\n",
        "        # Label as relevant if similarity is above a threshold\n",
        "        interaction_label = 1 if similarity > 0.5 else 0\n",
        "\n",
        "        interactions_data.append({\n",
        "            'user_id': user_id,\n",
        "            'news_id': news_id,\n",
        "            'interaction_label': interaction_label\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(interactions_data)\n",
        "\n",
        "def main():\n",
        "    # Assume these are prepared beforehand\n",
        "    # user_features: DataFrame with user_id and user_features\n",
        "    # news_dict: Dictionary of news embeddings\n",
        "\n",
        "    # Create synthetic interactions\n",
        "    interactions_df = create_synthetic_interactions(user_features, news_dict)\n",
        "\n",
        "    # Determine input dimension from the embeddings\n",
        "    input_dim = len(user_features.iloc[0]['user_features'])\n",
        "\n",
        "    # Train the model\n",
        "    trained_model = train_siamese_news_ranking(\n",
        "        user_features,\n",
        "        news_dict,\n",
        "        interactions_df,\n",
        "        input_dim\n",
        "    )\n",
        "\n",
        "    # Example: Rank news for a specific user\n",
        "    user_id = 'U100'\n",
        "    user_embedding = torch.tensor(\n",
        "        user_features[user_features['user_id'] == user_id]['user_features'].iloc[0],\n",
        "        dtype=torch.float32\n",
        "    )\n",
        "\n",
        "    # Rank news for this user\n",
        "    ranked_news = rank_news_for_user(trained_model, user_embedding, news_dict)\n",
        "\n",
        "    # Print top 10 recommended news items\n",
        "    print(\"Top 10 News Recommendations:\")\n",
        "    for news_id, score in ranked_news[:10]:\n",
        "        print(f\"News ID: {news_id}, Similarity Score: {score}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "# Notes for implementation:\n",
        "# 1. Ensure interactions_df has columns: user_id, news_id, interaction_label\n",
        "# 2. interaction_label should be binary (1 for relevant, 0 for not relevant)\n",
        "# 3. Adjust hyperparameters as needed for your specific dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uzNqgn3Pkw-",
        "outputId": "ce468e8e-1924-4f65-fcca-9096df7a6457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-53-f6d3a1691967>:715: RuntimeWarning: invalid value encountered in scalar divide\n",
            "  similarity = np.dot(user_embedding, news_embedding) / (\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "Train Loss: 7.0606\n",
            "Val Loss: 2.3886\n",
            "Epoch 2/20\n",
            "Train Loss: 5.3667\n",
            "Val Loss: 4.1817\n",
            "Epoch 3/20\n",
            "Train Loss: 4.4333\n",
            "Val Loss: 3.5449\n",
            "Epoch 4/20\n",
            "Train Loss: 3.5404\n",
            "Val Loss: 2.7373\n",
            "Epoch 5/20\n",
            "Train Loss: 2.5501\n",
            "Val Loss: 2.0081\n",
            "Epoch 6/20\n",
            "Train Loss: 2.0219\n",
            "Val Loss: 1.6772\n",
            "Epoch 7/20\n",
            "Train Loss: 1.9323\n",
            "Val Loss: 1.4336\n",
            "Epoch 8/20\n",
            "Train Loss: 1.7711\n",
            "Val Loss: 1.2994\n",
            "Epoch 9/20\n",
            "Train Loss: 1.4163\n",
            "Val Loss: 1.2180\n",
            "Epoch 10/20\n",
            "Train Loss: 1.2299\n",
            "Val Loss: 1.0497\n",
            "Epoch 11/20\n",
            "Train Loss: 1.0363\n",
            "Val Loss: 0.9061\n",
            "Epoch 12/20\n",
            "Train Loss: 1.0659\n",
            "Val Loss: 0.9366\n",
            "Epoch 13/20\n",
            "Train Loss: 1.0162\n",
            "Val Loss: 0.9849\n",
            "Epoch 14/20\n",
            "Train Loss: 0.9342\n",
            "Val Loss: 0.9335\n",
            "Epoch 15/20\n",
            "Train Loss: 0.8352\n",
            "Val Loss: 0.9002\n",
            "Epoch 16/20\n",
            "Train Loss: 0.7509\n",
            "Val Loss: 0.8750\n",
            "Epoch 17/20\n",
            "Train Loss: 0.7880\n",
            "Val Loss: 0.8197\n",
            "Epoch 18/20\n",
            "Train Loss: 0.7166\n",
            "Val Loss: 0.8085\n",
            "Epoch 19/20\n",
            "Train Loss: 0.7181\n",
            "Val Loss: 0.7818\n",
            "Epoch 20/20\n",
            "Train Loss: 0.7462\n",
            "Val Loss: 0.7695\n",
            "Top 10 News Recommendations:\n",
            "News ID: N41744, Similarity Score: 6.0716657638549805\n",
            "News ID: N8439, Similarity Score: 6.062225341796875\n",
            "News ID: N7412, Similarity Score: 6.056185245513916\n",
            "News ID: N2411, Similarity Score: 6.044996738433838\n",
            "News ID: N11661, Similarity Score: 6.043170928955078\n",
            "News ID: N61437, Similarity Score: 6.034322261810303\n",
            "News ID: N61707, Similarity Score: 6.033061981201172\n",
            "News ID: N7097, Similarity Score: 6.0329461097717285\n",
            "News ID: N355, Similarity Score: 6.031594753265381\n",
            "News ID: N22274, Similarity Score: 6.031309127807617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# colaborative"
      ],
      "metadata": {
        "id": "R6gBahfiUbvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from typing import Dict, List, Tuple\n",
        "\n",
        "class CollaborativeFilteringRecommender:\n",
        "    def __init__(self, user_features: pd.DataFrame, news_dict: Dict[str, List[float]]):\n",
        "        \"\"\"\n",
        "        Initialize the recommender with user features and news embeddings.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        user_features : pd.DataFrame\n",
        "            DataFrame containing user IDs and their feature embeddings\n",
        "        news_dict : Dict[str, List[float]]\n",
        "            Dictionary of news article IDs and their embeddings\n",
        "        \"\"\"\n",
        "        self.user_features = user_features\n",
        "        self.news_dict = news_dict\n",
        "\n",
        "        # Convert user features to a numpy array for easier computation\n",
        "        self.user_embeddings = np.array(user_features['user_features'].tolist())\n",
        "\n",
        "        # Convert news embeddings to a numpy array\n",
        "        self.news_embeddings = np.array(list(news_dict.values()))\n",
        "        self.news_ids = list(news_dict.keys())\n",
        "\n",
        "    def find_similar_users(self, user_id: str, top_k: int = 5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Find the most similar users to a given user based on cosine similarity.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        user_id : str\n",
        "            The ID of the user for whom to find similar users\n",
        "        top_k : int, optional\n",
        "            Number of similar users to return (default is 5)\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        List of tuples containing similar user IDs and their similarity scores\n",
        "        \"\"\"\n",
        "        # Find the index of the given user\n",
        "        user_index = self.user_features[self.user_features['user_id'] == user_id].index[0]\n",
        "\n",
        "        # Get the user's embedding\n",
        "        user_embedding = self.user_embeddings[user_index]\n",
        "\n",
        "        # Compute cosine similarity with all other users\n",
        "        similarities = cosine_similarity([user_embedding], self.user_embeddings)[0]\n",
        "\n",
        "        # Remove the user's similarity to themselves\n",
        "        similarities[user_index] = -1  # Ensure it's not selected\n",
        "\n",
        "        # Get top K similar users\n",
        "        top_similar_indices = np.argsort(similarities)[-top_k:][::-1]\n",
        "\n",
        "        # Return similar users with their similarity scores\n",
        "        similar_users = [\n",
        "            (self.user_features.iloc[idx]['user_id'], similarities[idx])\n",
        "            for idx in top_similar_indices\n",
        "        ]\n",
        "\n",
        "        return similar_users\n",
        "\n",
        "    def recommend_news(self, user_id: str, top_k: int = 5) -> List[Tuple[str, float]]:\n",
        "        \"\"\"\n",
        "        Recommend news articles for a given user based on similar users' interactions.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        user_id : str\n",
        "            The ID of the user to generate recommendations for\n",
        "        top_k : int, optional\n",
        "            Number of news recommendations to return (default is 5)\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        List of tuples containing recommended news IDs and their relevance scores\n",
        "        \"\"\"\n",
        "        # Find similar users\n",
        "        similar_users = self.find_similar_users(user_id, top_k)\n",
        "\n",
        "        # Compute news recommendations based on similar users\n",
        "        # This is a simple implementation that averages embeddings of similar users\n",
        "        similar_user_embeddings = [\n",
        "            self.user_embeddings[self.user_features[self.user_features['user_id'] == u_id].index[0]]\n",
        "            for u_id, _ in similar_users\n",
        "        ]\n",
        "\n",
        "        # Compute average embedding of similar users\n",
        "        avg_similar_user_embedding = np.mean(similar_user_embeddings, axis=0)\n",
        "\n",
        "        # Compute similarity between average user embedding and news embeddings\n",
        "        news_similarities = cosine_similarity([avg_similar_user_embedding], self.news_embeddings)[0]\n",
        "\n",
        "        # Get top K news recommendations\n",
        "        top_news_indices = np.argsort(news_similarities)[-top_k:][::-1]\n",
        "\n",
        "        # Return recommended news with their similarity scores\n",
        "        recommended_news = [\n",
        "            (self.news_ids[idx], news_similarities[idx])\n",
        "            for idx in top_news_indices\n",
        "        ]\n",
        "\n",
        "        return recommended_news\n",
        "\n",
        "    def evaluate_recommendations(self, ground_truth: Dict[str, List[str]], top_k: int = 5) -> Dict[str, float]:\n",
        "        \"\"\"\n",
        "        Evaluate the recommendation system using precision@k.\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        ground_truth : Dict[str, List[str]]\n",
        "            A dictionary with user IDs as keys and lists of actual read news as values\n",
        "        top_k : int, optional\n",
        "            Number of recommendations to consider (default is 5)\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        Dictionary with user IDs and their precision@k scores\n",
        "        \"\"\"\n",
        "        precision_scores = {}\n",
        "\n",
        "        for user_id, actual_news in ground_truth.items():\n",
        "            # Get recommended news\n",
        "            recommended_news = self.recommend_news(user_id, top_k)\n",
        "            recommended_news_ids = [news_id for news_id, _ in recommended_news]\n",
        "\n",
        "            # Compute precision@k\n",
        "            hit_count = len(set(recommended_news_ids) & set(actual_news))\n",
        "            precision = hit_count / top_k\n",
        "\n",
        "            precision_scores[user_id] = precision\n",
        "\n",
        "        return precision_scores\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    # Assuming you have prepared user_features and news_dict\n",
        "    # user_features = pd.read_csv('user_features.csv')\n",
        "    # news_dict = load_news_embeddings()\n",
        "\n",
        "    # Initialize the recommender\n",
        "    recommender = CollaborativeFilteringRecommender(user_features, news_dict)\n",
        "\n",
        "    # Example: Recommend news for a specific user\n",
        "    user_id = 'U100'  # Replace with an actual user ID\n",
        "    recommended_news = recommender.recommend_news(user_id)\n",
        "\n",
        "    print(f\"Recommended News for User {user_id}:\")\n",
        "    for news_id, score in recommended_news:\n",
        "        print(f\"News ID: {news_id}, Relevance Score: {score}\")\n",
        "\n",
        "    # Optional: Evaluate recommendations if you have ground truth data\n",
        "    # ground_truth = {\n",
        "    #     'U100': ['N55528', 'N12345', ...],\n",
        "    #     # ... other users and their actually read news\n",
        "    # }\n",
        "    # precision_scores = recommender.evaluate_recommendations(ground_truth)\n",
        "    # print(\"Precision Scores:\", precision_scores)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n",
        "\n",
        "# Additional helper functions you might need\n",
        "def preprocess_user_features(user_features_df):\n",
        "    \"\"\"\n",
        "    Preprocess user features by converting string representations to lists of floats.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    user_features_df : pd.DataFrame\n",
        "        DataFrame with user features as string representations\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    pd.DataFrame with processed user features\n",
        "    \"\"\"\n",
        "    user_features_df['user_features'] = user_features_df['user_features'].apply(\n",
        "        lambda x: list(map(float, x.strip('[]').split()))\n",
        "    )\n",
        "    return user_features_df\n",
        "\n",
        "def load_news_embeddings(file_path=None):\n",
        "    \"\"\"\n",
        "    Load news embeddings from a file or use a provided dictionary.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    file_path : str, optional\n",
        "        Path to the file containing news embeddings\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    Dictionary of news IDs and their embeddings\n",
        "    \"\"\"\n",
        "    # If file_path is provided, implement loading logic\n",
        "    # For now, we'll assume news_dict is already available\n",
        "    return news_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f5ckZrJRkmU",
        "outputId": "4547b971-df7d-40bc-e7b5-51e12dc4f816"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended News for User U100:\n",
            "News ID: N31151, Relevance Score: 0.8751485347825297\n",
            "News ID: N2910, Relevance Score: 0.870604293299934\n",
            "News ID: N16417, Relevance Score: 0.8675791107650362\n",
            "News ID: N7754, Relevance Score: 0.8663904980613362\n",
            "News ID: N1202, Relevance Score: 0.8594246995013237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# NCF"
      ],
      "metadata": {
        "id": "bWuqA0ejbB-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load and preprocess the data\n",
        "def load_and_preprocess_data(behaviors_path, news_path):\n",
        "    # Load behaviors data\n",
        "    behaviors = pd.read_csv(behaviors_path, sep='\\t', names=['index', 'user_id', 'timestamp', 'news_explored', 'news_suggested_and_action'], header=None)\n",
        "\n",
        "    # Load news data\n",
        "    news = pd.read_csv(news_path, sep='\\t', names=['news_id', 'category', 'subcategory', 'title', 'abstract', 'address', 'title_entities', 'abstract_entities'], header=None)\n",
        "\n",
        "    # Process impressions (news interactions)\n",
        "    def process_impressions(impression_str):\n",
        "        if pd.isna(impression_str):\n",
        "            return []\n",
        "        impressions = []\n",
        "        for item in impression_str.split():\n",
        "            # Split into news_id and click_label (assuming format like N55689-1)\n",
        "            news_id, click_label = item.split('-') if '-' in item else (item, 1)\n",
        "            impressions.append((news_id, int(click_label)))\n",
        "        return impressions\n",
        "\n",
        "    behaviors['impressions_processed'] = behaviors['news_suggested_and_action'].apply(process_impressions)\n",
        "\n",
        "    # Create user-item interactions\n",
        "    user_item_interactions = []\n",
        "    for _, row in behaviors.iterrows():\n",
        "        for impression in row['impressions_processed']:\n",
        "            news_id, click_label = impression\n",
        "            user_item_interactions.append([row['user_id'], news_id, click_label])\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    interaction_df = pd.DataFrame(user_item_interactions, columns=['user_id', 'news_id', 'click_label'])\n",
        "\n",
        "    return interaction_df, behaviors, news\n",
        "\n",
        "# Create mappings and encode user and news IDs\n",
        "def create_id_mappings(interaction_df):\n",
        "    user_id_mapping = {id: idx for idx, id in enumerate(interaction_df['user_id'].unique())}\n",
        "    news_id_mapping = {id: idx for idx, id in enumerate(interaction_df['news_id'].unique())}\n",
        "\n",
        "    interaction_df['user_index'] = interaction_df['user_id'].map(user_id_mapping)\n",
        "    interaction_df['news_index'] = interaction_df['news_id'].map(news_id_mapping)\n",
        "\n",
        "    return interaction_df, user_id_mapping, news_id_mapping\n",
        "\n",
        "# Create NCF Model\n",
        "def create_ncf_model(num_users, num_items, embedding_size=64):\n",
        "    # Inputs\n",
        "    user_input = Input(shape=(1,), name='user_input')\n",
        "    news_input = Input(shape=(1,), name='news_input')\n",
        "\n",
        "    # Embedding layers\n",
        "    user_embedding = Embedding(input_dim=num_users, output_dim=embedding_size, name='user_embedding')(user_input)\n",
        "    news_embedding = Embedding(input_dim=num_items, output_dim=embedding_size, name='news_embedding')(news_input)\n",
        "\n",
        "    # Flatten embeddings\n",
        "    user_vecs = Flatten()(user_embedding)\n",
        "    news_vecs = Flatten()(news_embedding)\n",
        "\n",
        "    # Concatenate user and item embeddings\n",
        "    input_vecs = Concatenate()([user_vecs, news_vecs])\n",
        "\n",
        "    # Dense layers\n",
        "    x = Dense(128, activation='relu')(input_vecs)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(1, activation='sigmoid')(x)  # For click label prediction\n",
        "\n",
        "    model = Model(inputs=[user_input, news_input], outputs=output)\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Function to recommend news for a specific user\n",
        "def recommend_for_user(user_id, ncf_model, user_id_mapping, news_id_mapping, behaviors, top_n=10):\n",
        "    # Get the index for the user_id\n",
        "    user_idx = user_id_mapping.get(user_id)\n",
        "\n",
        "    if user_idx is None:\n",
        "        raise ValueError(f\"User ID {user_id} not found in mapping.\")\n",
        "\n",
        "    # Get news IDs that the user hasn't interacted with\n",
        "    interacted_news = set()\n",
        "    for _, row in behaviors[behaviors['user_id'] == user_id].iterrows():\n",
        "        for news, _ in row['impressions_processed']:\n",
        "            interacted_news.add(news)\n",
        "\n",
        "    # Get all unique news IDs\n",
        "    all_news_ids = list(news_id_mapping.keys())\n",
        "\n",
        "    # Filter out already interacted news\n",
        "    candidate_news_ids = [news_id for news_id in all_news_ids if news_id not in interacted_news]\n",
        "\n",
        "    # Map news IDs to indices\n",
        "    news_indices = np.array([news_id_mapping[news_id] for news_id in candidate_news_ids])\n",
        "\n",
        "    # Predict probabilities\n",
        "    user_indices = np.full(len(news_indices), user_idx)\n",
        "    predicted_probs = ncf_model.predict([user_indices, news_indices])\n",
        "\n",
        "    # Create recommendations DataFrame\n",
        "    recommendations = pd.DataFrame({\n",
        "        'news_id': candidate_news_ids,\n",
        "        'predicted_prob': predicted_probs.flatten()\n",
        "    })\n",
        "\n",
        "    # Return top_n recommendations\n",
        "    return recommendations.sort_values(by='predicted_prob', ascending=False).head(top_n)\n",
        "\n",
        "# Main execution function\n",
        "def main():\n",
        "    # Paths to your data files (update these to your actual file paths)\n",
        "    behaviors_path = '/content/drive/MyDrive/behaviors.tsv'\n",
        "    news_path = '/content/drive/MyDrive/news.tsv'\n",
        "\n",
        "    # Load and preprocess data\n",
        "    interaction_df, behaviors, news = load_and_preprocess_data(behaviors_path, news_path)\n",
        "\n",
        "    # Create ID mappings\n",
        "    interaction_df, user_id_mapping, news_id_mapping = create_id_mappings(interaction_df)\n",
        "\n",
        "    # Split the data into train and test sets\n",
        "    train_df, test_df = train_test_split(interaction_df, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Prepare inputs for training\n",
        "    train_user_input = train_df['user_index'].values\n",
        "    train_news_input = train_df['news_index'].values\n",
        "    train_labels = train_df['click_label'].values\n",
        "\n",
        "    # Create and train the NCF model\n",
        "    num_users = len(user_id_mapping)\n",
        "    num_items = len(news_id_mapping)\n",
        "    embedding_size = 64\n",
        "\n",
        "    ncf_model = create_ncf_model(num_users, num_items, embedding_size)\n",
        "\n",
        "    # Train the model\n",
        "    history = ncf_model.fit(\n",
        "        [train_user_input, train_news_input],\n",
        "        train_labels,\n",
        "        epochs=10,\n",
        "        batch_size=256,\n",
        "        validation_split=0.1,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate the model on test data\n",
        "    test_user_input = test_df['user_index'].values\n",
        "    test_news_input = test_df['news_index'].values\n",
        "    test_labels = test_df['click_label'].values\n",
        "\n",
        "    loss, accuracy = ncf_model.evaluate([test_user_input, test_news_input], test_labels)\n",
        "    print(f\"\\nTest Loss: {loss:.4f}\")\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # Example: Recommend news for a specific user\n",
        "    try:\n",
        "        example_user = 'U13740'\n",
        "        recommended_news = recommend_for_user(\n",
        "            example_user,\n",
        "            ncf_model,\n",
        "            user_id_mapping,\n",
        "            news_id_mapping,\n",
        "            behaviors\n",
        "        )\n",
        "        print(f\"\\nRecommended News for User {example_user}:\")\n",
        "        print(recommended_news)\n",
        "\n",
        "        # Optionally, merge with news details\n",
        "        recommended_with_details = recommended_news.merge(\n",
        "            news[['news_id', 'title', 'category']],\n",
        "            on='news_id',\n",
        "            how='left'\n",
        "        )\n",
        "        print(\"\\nRecommendations with Details:\")\n",
        "        print(recommended_with_details)\n",
        "    except ValueError as e:\n",
        "        print(e)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXtaD675ULVr",
        "outputId": "7d70adcc-63ce-4882-970a-f6df719d7e96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 3ms/step - accuracy: 0.9597 - loss: 0.1678 - val_accuracy: 0.9593 - val_loss: 0.1560\n",
            "Epoch 2/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9595 - loss: 0.1524 - val_accuracy: 0.9593 - val_loss: 0.1567\n",
            "Epoch 3/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - accuracy: 0.9599 - loss: 0.1495 - val_accuracy: 0.9593 - val_loss: 0.1562\n",
            "Epoch 4/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9602 - loss: 0.1475 - val_accuracy: 0.9590 - val_loss: 0.1571\n",
            "Epoch 5/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - accuracy: 0.9604 - loss: 0.1463 - val_accuracy: 0.9587 - val_loss: 0.1589\n",
            "Epoch 6/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9607 - loss: 0.1446 - val_accuracy: 0.9585 - val_loss: 0.1595\n",
            "Epoch 7/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 2ms/step - accuracy: 0.9611 - loss: 0.1427 - val_accuracy: 0.9587 - val_loss: 0.1598\n",
            "Epoch 8/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9613 - loss: 0.1413 - val_accuracy: 0.9583 - val_loss: 0.1607\n",
            "Epoch 9/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9616 - loss: 0.1395 - val_accuracy: 0.9584 - val_loss: 0.1609\n",
            "Epoch 10/10\n",
            "\u001b[1m16435/16435\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2ms/step - accuracy: 0.9620 - loss: 0.1376 - val_accuracy: 0.9578 - val_loss: 0.1622\n",
            "\u001b[1m36522/36522\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 1ms/step - accuracy: 0.9581 - loss: 0.1611\n",
            "\n",
            "Test Loss: 0.1612\n",
            "Test Accuracy: 0.9581\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step\n",
            "\n",
            "Recommended News for User U13740:\n",
            "      news_id  predicted_prob\n",
            "16077  N22916        0.110786\n",
            "15698   N5038        0.109955\n",
            "17817  N23086        0.107030\n",
            "12373  N52512        0.103268\n",
            "5590   N58728        0.097450\n",
            "7168    N5007        0.096016\n",
            "17192  N22116        0.095849\n",
            "8488   N29848        0.094457\n",
            "15753  N63080        0.093931\n",
            "17479  N63629        0.092426\n",
            "\n",
            "Recommendations with Details:\n",
            "  news_id  predicted_prob                                              title  \\\n",
            "0  N22916        0.110786  Penn State's James Franklin vows recovery vs. ...   \n",
            "1   N5038        0.109955  Ryan Clark makes a lofty comparison for the 20...   \n",
            "2  N23086        0.107030  Josh Donaldson, as expected, declines the Brav...   \n",
            "3  N52512        0.103268  Two of 10 players accept $17.8 million qualify...   \n",
            "4  N58728        0.097450  How Patriots had good Sunday despite being on ...   \n",
            "5   N5007        0.096016   Bethel Park Police Arrest CoGo's Robbery Suspect   \n",
            "6  N22116        0.095849  Lewis helps No. 15 Florida to tight win over T...   \n",
            "7  N29848        0.094457  Kareem Hunt helps ignite 19-16 victory over Bi...   \n",
            "8  N63080        0.093931  Remember the Bucks County guy with the $1.6 mi...   \n",
            "9  N63629        0.092426  Breaking down one of the best throws of Patric...   \n",
            "\n",
            "  category  \n",
            "0       tv  \n",
            "1   sports  \n",
            "2   sports  \n",
            "3   sports  \n",
            "4   sports  \n",
            "5     news  \n",
            "6   sports  \n",
            "7   sports  \n",
            "8  finance  \n",
            "9   sports  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Input, Dense, Dropout, Concatenate, Lambda\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# import tensorflow.keras.backend as K\n",
        "\n",
        "# # Preprocess user features\n",
        "# def preprocess_user_features(user_features):\n",
        "#     # Remove the brackets and split the strings by space, then convert to list of numbers\n",
        "#     user_features['user_features'] = user_features['user_features'].apply(lambda x: list(map(float, x.strip('[]').split())))\n",
        "#     return user_features\n",
        "\n",
        "# # Preprocess news embeddings\n",
        "# def preprocess_news_embeddings(news_dict):\n",
        "#     # Convert dictionary to DataFrame\n",
        "#     news_embeddings_df = pd.DataFrame.from_dict(news_dict, orient='index', columns=[f'dim_{i}' for i in range(len(next(iter(news_dict.values()))))])\n",
        "#     news_embeddings_df.index.name = 'news_id'\n",
        "#     news_embeddings_df.reset_index(inplace=True)\n",
        "#     return news_embeddings_df\n",
        "\n",
        "# # Load and preprocess the data\n",
        "# def load_and_preprocess_data(behaviors_path, news_path, user_features, news_embeddings_df):\n",
        "#     # Load behaviors data\n",
        "#     behaviors = pd.read_csv(behaviors_path, sep='\\t', names=['index', 'user_id', 'timestamp', 'news_explored', 'news_suggested_and_action'], header=None)\n",
        "\n",
        "#     # Load news data\n",
        "#     news = pd.read_csv(news_path, sep='\\t', names=['news_id', 'category', 'subcategory', 'title', 'abstract', 'address', 'title_entities', 'abstract_entities'], header=None)\n",
        "\n",
        "#     # Process impressions (news interactions)\n",
        "#     def process_impressions(impression_str):\n",
        "#         if pd.isna(impression_str):\n",
        "#             return []\n",
        "#         impressions = []\n",
        "#         for item in impression_str.split():\n",
        "#             # Split into news_id and click_label (assuming format like N55689-1)\n",
        "#             news_id, click_label = item.split('-') if '-' in item else (item, 1)\n",
        "#             impressions.append((news_id, int(click_label)))\n",
        "#         return impressions\n",
        "\n",
        "#     behaviors['impressions_processed'] = behaviors['news_suggested_and_action'].apply(process_impressions)\n",
        "\n",
        "#     # Create user-item interactions\n",
        "#     user_item_interactions = []\n",
        "#     for _, row in behaviors.iterrows():\n",
        "#         for impression in row['impressions_processed']:\n",
        "#             news_id, click_label = impression\n",
        "#             user_item_interactions.append([row['user_id'], news_id, click_label])\n",
        "\n",
        "#     # Convert to DataFrame\n",
        "#     interaction_df = pd.DataFrame(user_item_interactions, columns=['user_id', 'news_id', 'click_label'])\n",
        "\n",
        "#     # Merge with user features and news embeddings\n",
        "#     interaction_df = interaction_df.merge(user_features[['user_id', 'user_features']], on='user_id', how='left')\n",
        "#     interaction_df = interaction_df.merge(news_embeddings_df, on='news_id', how='left')\n",
        "\n",
        "#     return interaction_df, behaviors, news\n",
        "\n",
        "# # Create NCF Model with Embedding Input\n",
        "# def create_ncf_model(embedding_dim):\n",
        "#     # User embedding input\n",
        "#     user_embedding_input = Input(shape=(embedding_dim,), name='user_embedding_input')\n",
        "\n",
        "#     # News embedding input\n",
        "#     news_embedding_input = Input(shape=(embedding_dim,), name='news_embedding_input')\n",
        "\n",
        "#     # Concatenate embeddings\n",
        "#     input_vecs = Concatenate()([user_embedding_input, news_embedding_input])\n",
        "\n",
        "#     # Dense layers\n",
        "#     x = Dense(128, activation='relu')(input_vecs)\n",
        "#     x = Dropout(0.5)(x)\n",
        "#     x = Dense(64, activation='relu')(x)\n",
        "#     x = Dropout(0.5)(x)\n",
        "#     output = Dense(1, activation='sigmoid')(x)  # For click label prediction\n",
        "\n",
        "#     model = Model(inputs=[user_embedding_input, news_embedding_input], outputs=output)\n",
        "#     model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "#                   loss='binary_crossentropy',\n",
        "#                   metrics=['accuracy'])\n",
        "#     return model\n",
        "\n",
        "# # Function to recommend news for a specific user\n",
        "# def recommend_for_user(user_id, ncf_model, user_features, news_embeddings_df, behaviors, top_n=10):\n",
        "#     # Find the user's embedding\n",
        "#     user_embedding = user_features[user_features['user_id'] == user_id]['user_features'].values[0]\n",
        "\n",
        "#     # Get news IDs that the user hasn't interacted with\n",
        "#     interacted_news = set()\n",
        "#     for _, row in behaviors[behaviors['user_id'] == user_id].iterrows():\n",
        "#         for news, _ in row['impressions_processed']:\n",
        "#             interacted_news.add(news)\n",
        "\n",
        "#     # Filter candidate news\n",
        "#     candidate_news = news_embeddings_df[~news_embeddings_df['news_id'].isin(interacted_news)]\n",
        "\n",
        "#     # Prepare inputs for prediction\n",
        "#     user_emb_repeated = np.tile(user_embedding, (len(candidate_news), 1))\n",
        "#     news_emb_array = candidate_news.drop('news_id', axis=1).values\n",
        "\n",
        "#     # Predict probabilities\n",
        "#     predicted_probs = ncf_model.predict([user_emb_repeated, news_emb_array])\n",
        "\n",
        "#     # Create recommendations DataFrame\n",
        "#     recommendations = pd.DataFrame({\n",
        "#         'news_id': candidate_news['news_id'],\n",
        "#         'predicted_prob': predicted_probs.flatten()\n",
        "#     })\n",
        "\n",
        "#     # Return top_n recommendations\n",
        "#     return recommendations.sort_values(by='predicted_prob', ascending=False).head(top_n)\n",
        "\n",
        "# # Main execution function\n",
        "# def main():\n",
        "#     # Paths to your data files (update these to your actual file paths)\n",
        "#     behaviors_path = '/content/drive/MyDrive/behaviors.tsv'\n",
        "#     news_path = '/content/drive/MyDrive/news.tsv'\n",
        "\n",
        "#     # Preprocess user features and news embeddings\n",
        "#     # Assuming you have these from previous preprocessing\n",
        "#     user_features = preprocess_user_features(user_features)\n",
        "#     news_embeddings_df = preprocess_news_embeddings(news_dict)\n",
        "\n",
        "#     # Determine embedding dimension\n",
        "#     embedding_dim = len(user_features.iloc[0]['user_features'])\n",
        "\n",
        "#     # Load and preprocess data\n",
        "#     interaction_df, behaviors, news = load_and_preprocess_data(\n",
        "#         behaviors_path,\n",
        "#         news_path,\n",
        "#         user_features,\n",
        "#         news_embeddings_df\n",
        "#     )\n",
        "\n",
        "#     # Split the data into train and test sets\n",
        "#     train_df, test_df = train_test_split(interaction_df, test_size=0.2, random_state=42)\n",
        "\n",
        "#     # Prepare inputs for training\n",
        "#     train_user_embeddings = np.stack(train_df['user_features'].values)\n",
        "#     train_news_embeddings = train_df.drop(['user_id', 'news_id', 'click_label', 'user_features'], axis=1).values\n",
        "#     train_labels = train_df['click_label'].values\n",
        "\n",
        "#     # Create and train the NCF model\n",
        "#     ncf_model = create_ncf_model(embedding_dim)\n",
        "\n",
        "#     # Train the model\n",
        "#     history = ncf_model.fit(\n",
        "#         [train_user_embeddings, train_news_embeddings],\n",
        "#         train_labels,\n",
        "#         epochs=10,\n",
        "#         batch_size=256,\n",
        "#         validation_split=0.1,\n",
        "#         verbose=1\n",
        "#     )\n",
        "\n",
        "#     # Evaluate the model on test data\n",
        "#     test_user_embeddings = np.stack(test_df['user_features'].values)\n",
        "#     test_news_embeddings = test_df.drop(['user_id', 'news_id', 'click_label', 'user_features'], axis=1).values\n",
        "#     test_labels = test_df['click_label'].values\n",
        "\n",
        "#     loss, accuracy = ncf_model.evaluate([test_user_embeddings, test_news_embeddings], test_labels)\n",
        "#     print(f\"\\nTest Loss: {loss:.4f}\")\n",
        "#     print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "#     # Example: Recommend news for a specific user\n",
        "#     try:\n",
        "#         example_user = 'U13740'\n",
        "#         recommended_news = recommend_for_user(\n",
        "#             example_user,\n",
        "#             ncf_model,\n",
        "#             user_features,\n",
        "#             news_embeddings_df,\n",
        "#             behaviors\n",
        "#         )\n",
        "#         print(f\"\\nRecommended News for User {example_user}:\")\n",
        "#         print(recommended_news)\n",
        "\n",
        "#         # Optionally, merge with news details\n",
        "#         recommended_with_details = recommended_news.merge(\n",
        "#             news[['news_id', 'title', 'category']],\n",
        "#             on='news_id',\n",
        "#             how='left'\n",
        "#         )\n",
        "#         print(\"\\nRecommendations with Details:\")\n",
        "#         print(recommended_with_details)\n",
        "#     except ValueError as e:\n",
        "#         print(e)\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "#     main()"
      ],
      "metadata": {
        "id": "gIJF5inDbQBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class NewsRecommendationDataset(Dataset):\n",
        "    def __init__(self, user_indices, news_indices, labels, device):\n",
        "        \"\"\"\n",
        "        Custom dataset for news recommendation with GPU support\n",
        "\n",
        "        Args:\n",
        "        - user_indices (numpy array): Encoded user indices\n",
        "        - news_indices (numpy array): Encoded news indices\n",
        "        - labels (numpy array): Click labels\n",
        "        - device (torch.device): GPU or CPU device\n",
        "        \"\"\"\n",
        "        self.user_indices = torch.LongTensor(user_indices).to(device)\n",
        "        self.news_indices = torch.LongTensor(news_indices).to(device)\n",
        "        self.labels = torch.FloatTensor(labels).to(device)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (\n",
        "            self.user_indices[idx],\n",
        "            self.news_indices[idx],\n",
        "            self.labels[idx]\n",
        "        )\n",
        "\n",
        "class NeuralCollaborativeFiltering(nn.Module):\n",
        "    def __init__(self, num_users, num_news, user_embedding_dim, news_embedding_dim,\n",
        "                 user_features_dim=768, news_features_dim=768):\n",
        "        \"\"\"\n",
        "        Neural Collaborative Filtering Model with custom embeddings\n",
        "\n",
        "        Args:\n",
        "        - num_users (int): Total number of unique users\n",
        "        - num_news (int): Total number of unique news articles\n",
        "        - user_embedding_dim (int): Dimension of user embedding layer\n",
        "        - news_embedding_dim (int): Dimension of news embedding layer\n",
        "        - user_features_dim (int): Dimension of user feature embedding\n",
        "        - news_features_dim (int): Dimension of news feature embedding\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        # User embedding layers\n",
        "        self.user_embedding = nn.Embedding(num_users, user_embedding_dim)\n",
        "        self.user_feature_fc = nn.Linear(user_features_dim, user_embedding_dim)\n",
        "\n",
        "        # News embedding layers\n",
        "        self.news_embedding = nn.Embedding(num_news, news_embedding_dim)\n",
        "        self.news_feature_fc = nn.Linear(news_features_dim, news_embedding_dim)\n",
        "\n",
        "        # MLP layers for interaction\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(user_embedding_dim + news_embedding_dim, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(64, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, user_indices, news_indices, user_features=None, news_features=None):\n",
        "        \"\"\"\n",
        "        Forward pass of the model with GPU support\n",
        "\n",
        "        Args:\n",
        "        - user_indices (tensor): Encoded user indices\n",
        "        - news_indices (tensor): Encoded news indices\n",
        "        - user_features (tensor, optional): User feature embeddings\n",
        "        - news_features (tensor, optional): News feature embeddings\n",
        "\n",
        "        Returns:\n",
        "        - Click probability prediction\n",
        "        \"\"\"\n",
        "        # Get initial embeddings\n",
        "        user_emb = self.user_embedding(user_indices)\n",
        "        news_emb = self.news_embedding(news_indices)\n",
        "\n",
        "        # Incorporate additional features if provided\n",
        "        if user_features is not None:\n",
        "            user_feature_emb = self.user_feature_fc(user_features)\n",
        "            user_emb = user_emb + user_feature_emb\n",
        "\n",
        "        if news_features is not None:\n",
        "            news_feature_emb = self.news_feature_fc(news_features)\n",
        "            news_emb = news_emb + news_feature_emb\n",
        "\n",
        "        # Concatenate user and news embeddings\n",
        "        combined = torch.cat([user_emb, news_emb], dim=1)\n",
        "\n",
        "        # Pass through MLP\n",
        "        output = self.mlp(combined)\n",
        "\n",
        "        return output.squeeze()\n",
        "\n",
        "class NewsRecommendationTrainer:\n",
        "    def __init__(self, num_users, num_news, user_features_dict, news_features_dict, device=None):\n",
        "        \"\"\"\n",
        "        Trainer class for News Recommendation Model with GPU support\n",
        "\n",
        "        Args:\n",
        "        - num_users (int): Total number of unique users\n",
        "        - num_news (int): Total number of unique news articles\n",
        "        - user_features_dict (dict): Dictionary of user features\n",
        "        - news_features_dict (dict): Dictionary of news features\n",
        "        - device (torch.device, optional): GPU or CPU device\n",
        "        \"\"\"\n",
        "        # Set up device\n",
        "        if device is None:\n",
        "            self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        else:\n",
        "            self.device = device\n",
        "\n",
        "        self.num_users = num_users\n",
        "        self.num_news = num_news\n",
        "        self.user_features_dict = user_features_dict\n",
        "        self.news_features_dict = news_features_dict\n",
        "\n",
        "        # Hyperparameters\n",
        "        self.user_embedding_dim = 64\n",
        "        self.news_embedding_dim = 64\n",
        "        self.user_features_dim = len(next(iter(user_features_dict.values())))\n",
        "        self.news_features_dim = len(next(iter(news_features_dict.values())))\n",
        "\n",
        "        # Model initialization\n",
        "        self.model = NeuralCollaborativeFiltering(\n",
        "            num_users,\n",
        "            num_news,\n",
        "            self.user_embedding_dim,\n",
        "            self.news_embedding_dim,\n",
        "            self.user_features_dim,\n",
        "            self.news_features_dim\n",
        "        ).to(self.device)\n",
        "\n",
        "        # Loss and optimizer\n",
        "        self.criterion = nn.BCELoss()\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)\n",
        "\n",
        "        print(f\"Model is using device: {self.device}\")\n",
        "\n",
        "    def prepare_data(self, behaviors_df):\n",
        "        \"\"\"\n",
        "        Prepare interaction data from behaviors dataframe\n",
        "\n",
        "        Args:\n",
        "        - behaviors_df (pd.DataFrame): Behaviors dataframe\n",
        "\n",
        "        Returns:\n",
        "        - Processed interaction dataframe\n",
        "        \"\"\"\n",
        "        # Create user-item interactions\n",
        "        user_item_interactions = []\n",
        "        for _, row in behaviors_df.iterrows():\n",
        "            # Parse news_suggested_and_action\n",
        "            news_actions = row['news_suggested_and_action'].split()\n",
        "            for news_action in news_actions:\n",
        "                news_id, action = news_action.split('-')\n",
        "                user_item_interactions.append([\n",
        "                    row['user_id'],\n",
        "                    news_id,\n",
        "                    int(action)\n",
        "                ])\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        interaction_df = pd.DataFrame(\n",
        "            user_item_interactions,\n",
        "            columns=['user_id', 'news_id', 'click_label']\n",
        "        )\n",
        "\n",
        "        return interaction_df\n",
        "\n",
        "    def encode_ids(self, interaction_df):\n",
        "        \"\"\"\n",
        "        Encode user and news IDs\n",
        "\n",
        "        Args:\n",
        "        - interaction_df (pd.DataFrame): Interaction dataframe\n",
        "\n",
        "        Returns:\n",
        "        - Encoded interaction dataframe\n",
        "        - User ID mapping\n",
        "        - News ID mapping\n",
        "        \"\"\"\n",
        "        # Create mappings\n",
        "        user_id_mapping = {id: idx for idx, id in enumerate(interaction_df['user_id'].unique())}\n",
        "        news_id_mapping = {id: idx for idx, id in enumerate(interaction_df['news_id'].unique())}\n",
        "\n",
        "        # Map IDs to indices\n",
        "        interaction_df['user_index'] = interaction_df['user_id'].map(user_id_mapping)\n",
        "        interaction_df['news_index'] = interaction_df['news_id'].map(news_id_mapping)\n",
        "\n",
        "        return interaction_df, user_id_mapping, news_id_mapping\n",
        "\n",
        "    def train(self, interaction_df, epochs=10, batch_size=256, validation_split=0.2):\n",
        "        \"\"\"\n",
        "        Train the NCF model with GPU support\n",
        "\n",
        "        Args:\n",
        "        - interaction_df (pd.DataFrame): Interaction dataframe\n",
        "        - epochs (int): Number of training epochs\n",
        "        - batch_size (int): Batch size for training\n",
        "        - validation_split (float): Proportion of data for validation\n",
        "\n",
        "        Returns:\n",
        "        - Trained model\n",
        "        \"\"\"\n",
        "        # Split data\n",
        "        train_df, val_df = train_test_split(\n",
        "            interaction_df,\n",
        "            test_size=validation_split,\n",
        "            random_state=42\n",
        "        )\n",
        "\n",
        "        # Prepare DataLoaders\n",
        "        train_dataset = NewsRecommendationDataset(\n",
        "            train_df['user_index'].values,\n",
        "            train_df['news_index'].values,\n",
        "            train_df['click_label'].values,\n",
        "            self.device\n",
        "        )\n",
        "        val_dataset = NewsRecommendationDataset(\n",
        "            val_df['user_index'].values,\n",
        "            val_df['news_index'].values,\n",
        "            val_df['click_label'].values,\n",
        "            self.device\n",
        "        )\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "        # Training loop\n",
        "        for epoch in range(epochs):\n",
        "            self.model.train()\n",
        "            total_train_loss = 0\n",
        "\n",
        "            # Wrap the training loop with tqdm for progress bar\n",
        "            with tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs}\", unit=\"batch\") as tepoch:\n",
        "              for user_idx, news_idx, labels in tepoch:\n",
        "                # Get features\n",
        "                # Find the original user_id from the mapping using user_idx[0]\n",
        "                user_id = interaction_df.loc[interaction_df['user_index'] == user_idx[0].item(), 'user_id'].values[0]\n",
        "\n",
        "                # Use the retrieved user_id to get user features\n",
        "                user_features = torch.tensor([self.user_features_dict[user_id]]).float().to(self.device)\n",
        "\n",
        "                # Similarly for news features\n",
        "                news_id = interaction_df.loc[interaction_df['news_index'] == news_idx[0].item(), 'news_id'].values[0]\n",
        "                news_features = torch.tensor([self.news_features_dict[news_id]]).float().to(self.device)\n",
        "\n",
        "                # Zero gradients\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = self.model(user_idx, news_idx, user_features, news_features)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimize\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                total_train_loss += loss.item()\n",
        "\n",
        "            # Validation\n",
        "            self.model.eval()\n",
        "            total_val_loss = 0\n",
        "            with torch.no_grad():\n",
        "                for user_idx, news_idx, labels in val_loader:\n",
        "                  # Convert user_idx and news_idx to CPU and then to NumPy\n",
        "                  user_idx_cpu = user_idx[0].cpu().numpy()\n",
        "                  news_idx_cpu = news_idx[0].cpu().numpy()\n",
        "\n",
        "                  user_features = torch.tensor([\n",
        "                      self.user_features_dict[interaction_df.loc[user_idx_cpu, 'user_id']]  # Index with user_idx_cpu\n",
        "                  ]).float().to(self.device)\n",
        "                  news_features = torch.tensor([\n",
        "                      self.news_features_dict[interaction_df.loc[news_idx_cpu, 'news_id']]  # Index with news_idx_cpu\n",
        "                  ]).float().to(self.device)\n",
        "\n",
        "                  outputs = self.model(user_idx, news_idx, user_features, news_features)\n",
        "                  val_loss = self.criterion(outputs, labels)\n",
        "                  total_val_loss += val_loss.item()\n",
        "\n",
        "            # Print epoch statistics\n",
        "            print(f\"Epoch {epoch+1}/{epochs}\")\n",
        "            print(f\"Train Loss: {total_train_loss/len(train_loader):.4f}\")\n",
        "            print(f\"Validation Loss: {total_val_loss/len(val_loader):.4f}\")\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def recommend_for_user(self, user_id, top_n=10, user_id_mapping=None, news_id_mapping=None):\n",
        "        \"\"\"\n",
        "        Generate recommendations for a specific user with GPU support\n",
        "\n",
        "        Args:\n",
        "        - user_id (str): User ID to generate recommendations for\n",
        "        - top_n (int): Number of recommendations to generate\n",
        "        - user_id_mapping (dict, optional): Mapping of user IDs to indices\n",
        "        - news_id_mapping (dict, optional): Mapping of news IDs to indices\n",
        "\n",
        "        Returns:\n",
        "        - DataFrame of recommended news with probabilities\n",
        "        \"\"\"\n",
        "        # Get user index\n",
        "        if user_id_mapping is None:\n",
        "            raise ValueError(\"User ID mapping is required\")\n",
        "\n",
        "        user_idx = user_id_mapping.get(user_id)\n",
        "        if user_idx is None:\n",
        "            raise ValueError(f\"User ID {user_id} not found in mapping\")\n",
        "\n",
        "        # Get user features\n",
        "        user_features = torch.tensor([\n",
        "            self.user_features_dict[user_id]\n",
        "        ]).float().to(self.device)\n",
        "\n",
        "        # Predict for all news\n",
        "        all_news_indices = torch.arange(self.num_news).to(self.device)\n",
        "        user_indices = torch.full_like(all_news_indices, user_idx)\n",
        "\n",
        "        # Predict probabilities\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Get features for all news\n",
        "            all_news_features = torch.tensor([\n",
        "                self.news_features_dict[news_id]\n",
        "                for news_id in news_id_mapping.keys()\n",
        "            ]).float().to(self.device)\n",
        "\n",
        "            predicted_probs = self.model(\n",
        "                user_indices,\n",
        "                all_news_indices,\n",
        "                user_features.repeat(len(all_news_indices), 1),\n",
        "                all_news_features\n",
        "            ).cpu().numpy()\n",
        "\n",
        "        # Create recommendations DataFrame\n",
        "        recommendations = pd.DataFrame({\n",
        "            'news_id': list(news_id_mapping.keys()),\n",
        "            'predicted_prob': predicted_probs\n",
        "        })\n",
        "\n",
        "        # Sort and return top recommendations\n",
        "        return recommendations.sort_values(\n",
        "            'predicted_prob',\n",
        "            ascending=False\n",
        "        ).head(top_n)\n",
        "\n",
        "# Example usage (commented out, you'll need to replace with your actual data)\n",
        "\n",
        "# Optional: Manually select GPU if multiple are available\n",
        "# torch.cuda.set_device(0)  # Use the first GPU\n",
        "\n",
        "# Prepare data\n",
        "behaviors_df = pd.read_csv('/content/drive/MyDrive/behaviors.tsv', sep='\\t',\n",
        "                            names=['index','user_id','timestamp','news_explored','news_suggested_and_action'],\n",
        "                            header=None)\n",
        "\n",
        "# Prepare user and news features dictionaries\n",
        "# With the following code snippet to correctly initialize your dictionaries:\n",
        "user_features_dict = user_features.set_index('user_id')['user_features'].to_dict()\n",
        "news_features_dict = news_dict  # Assuming news_dict already has news_id as key and embeddings as values\n",
        "\n",
        "# Explicitly create a device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize trainer with explicit device\n",
        "trainer = NewsRecommendationTrainer(\n",
        "    num_users=len(user_features_dict),\n",
        "    num_news=len(news_features_dict),\n",
        "    user_features_dict=user_features_dict,\n",
        "    news_features_dict=news_features_dict,\n",
        "    device=device  # Pass the device explicitly\n",
        ")\n",
        "\n",
        "# Prepare interaction data\n",
        "interaction_df = trainer.prepare_data(behaviors_df)\n",
        "interaction_df, user_id_mapping, news_id_mapping = trainer.encode_ids(interaction_df)\n",
        "\n",
        "\n",
        "# Train the model\n",
        "trained_model = trainer.train(interaction_df,  epochs=3)\n",
        "\n",
        "# Get recommendations for a user\n",
        "recommendations = trainer.recommend_for_user(\n",
        "    'U13740',\n",
        "    top_n=10,\n",
        "    user_id_mapping=user_id_mapping,\n",
        "    news_id_mapping=news_id_mapping\n",
        ")\n",
        "print(recommendations)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "id": "gQzLJI9CdpkK",
        "outputId": "891d0b5d-c04e-4fc8-ffb7-bc5bd2cfce49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is using device: cuda\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/3: 100%|██████████| 18261/18261 [04:33<00:00, 66.68batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "Train Loss: 0.1677\n",
            "Validation Loss: 0.1628\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/3: 100%|██████████| 18261/18261 [04:52<00:00, 62.36batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/3\n",
            "Train Loss: 0.1601\n",
            "Validation Loss: 0.1576\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/3: 100%|██████████| 18261/18261 [04:41<00:00, 64.77batch/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/3\n",
            "Train Loss: 0.1580\n",
            "Validation Loss: 0.1586\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (51282) must match the size of tensor b (20288) at non-singleton dimension 0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-5a4490cbb858>\u001b[0m in \u001b[0;36m<cell line: 392>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[0;31m# Get recommendations for a user\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m recommendations = trainer.recommend_for_user(\n\u001b[0m\u001b[1;32m    393\u001b[0m     \u001b[0;34m'U13740'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0mtop_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-5a4490cbb858>\u001b[0m in \u001b[0;36mrecommend_for_user\u001b[0;34m(self, user_id, top_n, user_id_mapping, news_id_mapping)\u001b[0m\n\u001b[1;32m    335\u001b[0m             ]).float().to(self.device)\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m             predicted_probs = self.model(\n\u001b[0m\u001b[1;32m    338\u001b[0m                 \u001b[0muser_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0mall_news_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-5a4490cbb858>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, user_indices, news_indices, user_features, news_features)\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnews_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mnews_feature_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnews_feature_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnews_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mnews_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnews_emb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnews_feature_emb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;31m# Concatenate user and news embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (51282) must match the size of tensor b (20288) at non-singleton dimension 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_for_user(self, user_id, top_n=10, user_id_mapping=None, news_id_mapping=None):\n",
        "    \"\"\"\n",
        "    Recommend top-N news articles for a given user\n",
        "\n",
        "    Args:\n",
        "    - user_id (str): User ID for which recommendations are to be generated\n",
        "    - top_n (int): Number of top recommendations to generate\n",
        "    - user_id_mapping (dict): Mapping from user ID to index\n",
        "    - news_id_mapping (dict): Mapping from news ID to index\n",
        "\n",
        "    Returns:\n",
        "    - List of top N recommended news articles with their predicted click probabilities\n",
        "    \"\"\"\n",
        "    # Ensure the model is in evaluation mode\n",
        "    self.model.eval()\n",
        "\n",
        "    # Check if mappings are provided\n",
        "    if user_id_mapping is None or news_id_mapping is None:\n",
        "        raise ValueError(\"Both user_id_mapping and news_id_mapping must be provided\")\n",
        "\n",
        "    # Get user index from the mapping\n",
        "    user_idx = user_id_mapping.get(user_id)\n",
        "    if user_idx is None:\n",
        "        raise ValueError(f\"User ID '{user_id}' not found in user_id_mapping.\")\n",
        "\n",
        "    # Create a tensor for the user\n",
        "    user_idx_tensor = torch.LongTensor([user_idx]).to(self.device)\n",
        "\n",
        "    # Prepare user features (if applicable)\n",
        "    user_features = torch.tensor([self.user_features_dict[user_id]]).float().to(self.device)\n",
        "\n",
        "    # Generate predictions for all news articles for this user\n",
        "    news_ids = list(news_id_mapping.keys())\n",
        "    news_indices = [news_id_mapping[news_id] for news_id in news_ids]\n",
        "\n",
        "    # Prepare news features (if applicable)\n",
        "    news_features = [torch.tensor([self.news_features_dict[news_id]]).float().to(self.device) for news_id in news_ids]\n",
        "\n",
        "    click_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for news_idx, news_feature in zip(news_indices, news_features):\n",
        "            # Get prediction for each news item\n",
        "            click_prob = self.model(user_idx_tensor, torch.LongTensor([news_idx]).to(self.device), user_features, news_feature)\n",
        "            click_probs.append(click_prob.item())\n",
        "\n",
        "    # Pair news_id with the predicted click probabilities\n",
        "    recommendations = list(zip(news_ids, click_probs))\n",
        "\n",
        "    # Sort recommendations by predicted click probability in descending order\n",
        "    recommendations = sorted(recommendations, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return top N recommendations\n",
        "    return recommendations[:top_n]\n"
      ],
      "metadata": {
        "id": "CxxX7LZkhuUp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the model is already trained and the following mappings are available\n",
        "user_id_mapping = {user_id: idx for idx, user_id in enumerate(user_features_dict.keys())}\n",
        "news_id_mapping = {news_id: idx for idx, news_id in enumerate(news_features_dict.keys())}\n",
        "\n",
        "# Get recommendations for a user after training\n",
        "user_id = 'U13740'\n",
        "top_n = 10\n",
        "recommendations = trainer.recommend_for_user(user_id, top_n, user_id_mapping, news_id_mapping)\n",
        "\n",
        "recommendations"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "qjj2k8gl2CTe",
        "outputId": "022f02c8-19fa-48b1-b4fc-43b1b65a914f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     news_id  predicted_prob\n",
              "1073  N57257        0.138367\n",
              "50    N20139        0.114740\n",
              "1     N19639        0.107018\n",
              "300   N17286        0.105381\n",
              "0     N55528        0.100706\n",
              "515   N32202        0.098222\n",
              "119   N33874        0.098100\n",
              "11    N60905        0.095458\n",
              "1077  N20681        0.092500\n",
              "110   N16556        0.091730"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6f93e7a8-378c-4627-b6f5-093a64b7bec2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>news_id</th>\n",
              "      <th>predicted_prob</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1073</th>\n",
              "      <td>N57257</td>\n",
              "      <td>0.138367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>N20139</td>\n",
              "      <td>0.114740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>N19639</td>\n",
              "      <td>0.107018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>N17286</td>\n",
              "      <td>0.105381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>N55528</td>\n",
              "      <td>0.100706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>N32202</td>\n",
              "      <td>0.098222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>N33874</td>\n",
              "      <td>0.098100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>N60905</td>\n",
              "      <td>0.095458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1077</th>\n",
              "      <td>N20681</td>\n",
              "      <td>0.092500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>N16556</td>\n",
              "      <td>0.091730</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6f93e7a8-378c-4627-b6f5-093a64b7bec2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6f93e7a8-378c-4627-b6f5-093a64b7bec2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6f93e7a8-378c-4627-b6f5-093a64b7bec2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-bcc67a1e-7de9-4aab-ab43-7c6ceb0d4a89\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bcc67a1e-7de9-4aab-ab43-7c6ceb0d4a89')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-bcc67a1e-7de9-4aab-ab43-7c6ceb0d4a89 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_9cb4ffb1-e000-47d7-9d72-13eeba4ce991\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('recommendations')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_9cb4ffb1-e000-47d7-9d72-13eeba4ce991 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('recommendations');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "recommendations",
              "summary": "{\n  \"name\": \"recommendations\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"news_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"N20681\",\n          \"N20139\",\n          \"N32202\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_prob\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          0.0924999788403511,\n          0.11473987251520157,\n          0.09822186082601547\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    }
  ]
}